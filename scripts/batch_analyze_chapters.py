"""
æ‰¹é‡åˆ†æç« èŠ‚ - ä½¿ç”¨ä¼˜åŒ–åçš„ Prompt
"""

import sys
from pathlib import Path
from datetime import datetime
import json

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.tools.novel_chapter_analyzer import NovelChapterAnalyzer


def extract_all_chapters(novel_file: Path):
    """æå–æ‰€æœ‰ç« èŠ‚"""
    with open(novel_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    import re
    chapter_pattern = r'===\s*ç¬¬\s*(\d+)\s*ç« \s*(.*)===\s*\n'
    matches = list(re.finditer(chapter_pattern, content))
    
    chapters = []
    for i, match in enumerate(matches):
        chapter_number = int(match.group(1))
        chapter_title = match.group(2).strip()
        
        start_pos = match.end()
        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(content)
        chapter_content = content[start_pos:end_pos].strip()
        
        chapters.append({
            'number': chapter_number,
            'title': chapter_title,
            'content': chapter_content
        })
    
    return chapters


def main():
    """æ‰¹é‡åˆ†æç« èŠ‚"""
    print("\n" + "ğŸ“š" * 40)
    print("  æ‰¹é‡ç« èŠ‚åˆ†æ - ä¼˜åŒ–åçš„ Prompt")
    print("ğŸ“š" * 40)
    print("\nâš™ï¸ é…ç½®ï¼šDeepSeek + ä¼˜åŒ–åçš„ Prompt")
    print("ğŸ“Š ç›®æ ‡ï¼šç¬¬1-10ç« åŠŸèƒ½æ®µåˆ†æ\n")
    
    # è¯»å–åŸå§‹å°è¯´æ–‡ä»¶
    project_dir = Path(__file__).parent.parent / "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯"
    novel_file = project_dir / "raw/novel.txt"
    output_dir = project_dir / "novel/functional_analysis"
    
    print(f"ğŸ“– è¯»å–å°è¯´æ–‡ä»¶: {novel_file.name}")
    chapters = extract_all_chapters(novel_file)
    
    # åªåˆ†æå‰10ç« 
    chapters_to_analyze = [c for c in chapters if 1 <= c['number'] <= 10]
    
    print(f"âœ… æˆåŠŸæå– {len(chapters)} ç« ")
    print(f"ğŸ¯ æœ¬æ¬¡åˆ†æï¼šç¬¬1-10ç« ï¼ˆå…± {len(chapters_to_analyze)} ç« ï¼‰\n")
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
    print("="*80)
    print("  å¼€å§‹æ‰¹é‡åˆ†æ")
    print("="*80)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = NovelChapterAnalyzer()
    
    results_summary = []
    
    for i, chapter in enumerate(chapters_to_analyze, 1):
        print(f"\n{'â”€'*80}")
        print(f"  [{i}/{len(chapters_to_analyze)}] ç¬¬{chapter['number']}ç«  - {chapter['title']}")
        print(f"{'â”€'*80}\n")
        
        print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(chapter['content'])} å­—ç¬¦")
        print(f"ğŸ”„ æ­£åœ¨åˆ†æ...\n")
        
        try:
            # æ‰§è¡Œåˆ†æ
            result = analyzer.execute(
                chapter_content=chapter['content'],
                chapter_number=chapter['number'],
                chapter_title=chapter['title'],
                novel_title="åºåˆ—å…¬è·¯æ±‚ç”Ÿï¼šæˆ‘åœ¨æœ«æ—¥å‡çº§ç‰©èµ„"
            )
            
            # ä¿å­˜æ–‡ä»¶
            # Markdown
            md_file = output_dir / f"ç¬¬{chapter['number']}ç« å®Œæ•´åˆ†æ®µåˆ†æ.md"
            analyzer.save_markdown(result, md_file)
            
            # JSON
            json_file = output_dir / f"chpt_{chapter['number']:04d}_functional_analysis.json"
            analyzer.save_json(result, json_file)
            
            # ç»Ÿè®¡ä¿¡æ¯
            segment_1 = result.segments[0] if result.segments else None
            summary = {
                'chapter': chapter['number'],
                'title': chapter['title'],
                'total_segments': result.chapter_summary.total_segments,
                'p0_count': result.chapter_summary.p0_count,
                'p1_count': result.chapter_summary.p1_count,
                'p2_count': result.chapter_summary.p2_count,
                'segment_1_word_count': segment_1.metadata.word_count if segment_1 else 0,
                'md_file': md_file.name,
                'json_file': json_file.name
            }
            
            results_summary.append(summary)
            
            print(f"âœ… åˆ†æå®Œæˆï¼")
            print(f"\nğŸ“Š ç»Ÿè®¡ï¼š")
            print(f"  - åŠŸèƒ½æ®µæ€»æ•°: {result.chapter_summary.total_segments}")
            print(f"  - P0-éª¨æ¶: {result.chapter_summary.p0_count}")
            print(f"  - P1-è¡€è‚‰: {result.chapter_summary.p1_count}")
            print(f"  - P2-çš®è‚¤: {result.chapter_summary.p2_count}")
            if segment_1:
                print(f"  - æ®µè½1å­—æ•°: {segment_1.metadata.word_count}")
            print(f"\nğŸ’¾ å·²ä¿å­˜:")
            print(f"  - {md_file.name}")
            print(f"  - {json_file.name}")
            
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results_summary.append({
                'chapter': chapter['number'],
                'title': chapter['title'],
                'error': str(e)
            })
        
        # è¿›åº¦æç¤º
        if i < len(chapters_to_analyze):
            print(f"\nâ³ ç­‰å¾…3ç§’åç»§ç»­...")
            import time
            time.sleep(3)
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "="*80)
    print("  ğŸ“Š æ‰¹é‡åˆ†æå®Œæˆ")
    print("="*80)
    
    success_count = len([r for r in results_summary if 'error' not in r])
    
    print(f"\nâœ… æˆåŠŸ: {success_count}/{len(chapters_to_analyze)}")
    
    if success_count > 0:
        print(f"\n### ğŸ“‹ ç« èŠ‚ç»Ÿè®¡\n")
        print("| ç« èŠ‚ | æ ‡é¢˜ | åŠŸèƒ½æ®µ | P0 | P1 | P2 | æ®µè½1å­—æ•° |")
        print("|-----|------|--------|----|----|----|---------| ")
        for r in results_summary:
            if 'error' not in r:
                print(f"| ç¬¬{r['chapter']}ç«  | {r['title'][:10]}... | {r['total_segments']} | {r['p0_count']} | {r['p1_count']} | {r['p2_count']} | {r['segment_1_word_count']} |")
    
    # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    report_file = output_dir / f"batch_analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'total_chapters': len(chapters_to_analyze),
            'success_count': success_count,
            'results': results_summary
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file.name}")
    print("\n" + "="*80)


if __name__ == "__main__":
    main()
