"""
æµ‹è¯• Prompt ä¼˜åŒ–æ•ˆæœ - å¯¹æ¯”ä¼˜åŒ–å‰åçš„ DeepSeek è¾“å‡º
"""

import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.tools.novel_chapter_analyzer import NovelChapterAnalyzer


def extract_chapter_content(novel_file: Path, chapter_num: int):
    """æå–æŒ‡å®šç« èŠ‚å†…å®¹"""
    with open(novel_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    import re
    chapter_pattern = r'===\s*ç¬¬\s*(\d+)\s*ç« \s*(.*)===\s*\n'
    matches = list(re.finditer(chapter_pattern, content))
    
    if len(matches) < chapter_num:
        return None, None
    
    start_match = matches[chapter_num - 1]
    chapter_number = int(start_match.group(1))
    chapter_title = start_match.group(2).strip()
    
    start_pos = start_match.end()
    end_pos = matches[chapter_num].start() if len(matches) > chapter_num else len(content)
    chapter_content = content[start_pos:end_pos].strip()
    
    return chapter_title, chapter_content


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "ğŸ¯" * 40)
    print("  Prompt ä¼˜åŒ–æ•ˆæœæµ‹è¯• - DeepSeek")
    print("ğŸ¯" * 40)
    print("\nğŸ“ æœ¬æ¬¡æµ‹è¯•ä½¿ç”¨ä¼˜åŒ–åçš„ prompt")
    print("ğŸ“Š å°†ä¸ä¹‹å‰çš„ç¨³å®šæ€§æµ‹è¯•ç»“æœå¯¹æ¯”\n")
    
    # è¯»å–åŸå§‹å°è¯´æ–‡ä»¶
    project_dir = Path(__file__).parent.parent / "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯"
    novel_file = project_dir / "raw/novel.txt"
    
    chapter_title, chapter_content = extract_chapter_content(novel_file, 1)
    
    if not chapter_content:
        print("âŒ æ— æ³•æå–ç« èŠ‚å†…å®¹")
        return
    
    print(f"ğŸ“– ç« èŠ‚: ç¬¬1ç«  - {chapter_title}")
    print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(chapter_content)} å­—ç¬¦\n")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = project_dir / "novel/functional_analysis/prompt_optimization_test"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¿è¡Œ3æ¬¡æµ‹è¯•
    print("="*80)
    print("  å¼€å§‹è¿è¡Œ3æ¬¡æµ‹è¯•ï¼ˆä¼˜åŒ–åçš„ Promptï¼‰")
    print("="*80)
    
    results = []
    for i in range(1, 4):
        print(f"\n{'â”€'*80}")
        print(f"  ç¬¬ {i} æ¬¡è¿è¡Œï¼ˆä¼˜åŒ–åï¼‰")
        print(f"{'â”€'*80}\n")
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = NovelChapterAnalyzer()
        
        print("ğŸ”„ æ­£åœ¨è°ƒç”¨ DeepSeek...\n")
        
        try:
            # æ‰§è¡Œåˆ†æ
            result = analyzer.execute(
                chapter_content=chapter_content,
                chapter_number=1,
                chapter_title=chapter_title,
                novel_title="åºåˆ—å…¬è·¯æ±‚ç”Ÿï¼šæˆ‘åœ¨æœ«æ—¥å‡çº§ç‰©èµ„"
            )
            
            # ä¿å­˜Markdown
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            md_file = output_dir / f"optimized_run_{i}_{timestamp}.md"
            analyzer.save_markdown(result, md_file)
            
            # æå–æ®µè½1ä¿¡æ¯
            segment_1 = result.segments[0] if result.segments else None
            
            if segment_1:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é™ˆé‡ååº”
                has_chenye_reaction = "é™ˆé‡" in segment_1.content
                has_convoy_emotion = "è½¦é˜Ÿ" in segment_1.content or "ç»æœ›" in segment_1.content
                
                print(f"âœ… åˆ†æå®Œæˆï¼")
                print(f"\nã€æ®µè½1 æ ¸å¿ƒä¿¡æ¯ã€‘")
                print(f"  æ ‡é¢˜: {segment_1.title}")
                print(f"  å­—æ•°: {segment_1.metadata.word_count}")
                print(f"  åŒ…å«é™ˆé‡ååº”: {'âœ…' if has_chenye_reaction else 'âŒ'}")
                print(f"  åŒ…å«è½¦é˜Ÿæƒ…ç»ª: {'âœ…' if has_convoy_emotion else 'âŒ'}")
                print(f"  ä¼˜å…ˆçº§: {segment_1.tags.priority}")
                print(f"\n  å†…å®¹é¢„è§ˆ:")
                preview = segment_1.content[:200]
                print(f"  {preview}...")
                
                # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
                is_correct = (
                    segment_1.metadata.word_count >= 150 and
                    has_chenye_reaction and
                    has_convoy_emotion
                )
                
                if is_correct:
                    print(f"\n  âœ… åˆ¤å®šï¼šæ­£ç¡®ï¼ˆåŒ…å«å®Œæ•´æƒ…ç»ªå•å…ƒï¼‰")
                else:
                    print(f"\n  âŒ åˆ¤å®šï¼šé”™è¯¯ï¼ˆç¼ºå°‘æƒ…ç»ªå•å…ƒï¼‰")
                    if segment_1.metadata.word_count < 150:
                        print(f"     åŸå› ï¼šå­—æ•°ä¸è¶³ï¼ˆ{segment_1.metadata.word_count} < 150ï¼‰")
                    if not has_chenye_reaction:
                        print(f"     åŸå› ï¼šç¼ºå°‘é™ˆé‡ååº”")
                    if not has_convoy_emotion:
                        print(f"     åŸå› ï¼šç¼ºå°‘è½¦é˜Ÿæƒ…ç»ª")
                
                print(f"\nğŸ’¾ å·²ä¿å­˜: {md_file.name}")
                
                results.append({
                    "run": i,
                    "timestamp": timestamp,
                    "title": segment_1.title,
                    "word_count": segment_1.metadata.word_count,
                    "has_chenye": has_chenye_reaction,
                    "has_convoy": has_convoy_emotion,
                    "is_correct": is_correct,
                    "total_segments": result.chapter_summary.total_segments
                })
            else:
                print("âŒ æ²¡æœ‰æ®µè½ç»“æœ")
                
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        if i < 3:
            print(f"\nâ³ ç­‰å¾…5ç§’...\n")
            import time
            time.sleep(5)
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "="*80)
    print("  ğŸ“Š ä¼˜åŒ–æ•ˆæœå¯¹æ¯”")
    print("="*80)
    
    if len(results) == 3:
        print(f"\nâœ… æˆåŠŸå®Œæˆ3æ¬¡æµ‹è¯•\n")
        
        # ç»Ÿè®¡æ­£ç¡®ç‡
        correct_count = sum(1 for r in results if r['is_correct'])
        accuracy = correct_count / 3 * 100
        
        print("### ğŸ“ˆ æ€»ä½“ç»Ÿè®¡\n")
        print(f"âœ… æ­£ç¡®æ¬¡æ•°: {correct_count}/3")
        print(f"ğŸ“Š å‡†ç¡®ç‡: {accuracy:.1f}%")
        
        print("\n### ğŸ“‹ è¯¦ç»†ç»“æœ\n")
        print("| è¿è¡Œ | æ ‡é¢˜ | å­—æ•° | é™ˆé‡ååº” | è½¦é˜Ÿæƒ…ç»ª | åˆ¤å®š |")
        print("|-----|------|------|---------|---------|------|")
        for r in results:
            chenye_mark = "âœ…" if r['has_chenye'] else "âŒ"
            convoy_mark = "âœ…" if r['has_convoy'] else "âŒ"
            result_mark = "âœ… æ­£ç¡®" if r['is_correct'] else "âŒ é”™è¯¯"
            print(f"| ç¬¬{r['run']}æ¬¡ | {r['title'][:20]}... | {r['word_count']} | {chenye_mark} | {convoy_mark} | {result_mark} |")
        
        print("\n### ğŸ” ä¸ä¼˜åŒ–å‰å¯¹æ¯”\n")
        print("**ä¼˜åŒ–å‰**ï¼ˆä¹‹å‰çš„ç¨³å®šæ€§æµ‹è¯•ï¼‰ï¼š")
        print("  - æ­£ç¡®æ¬¡æ•°: 1/3")
        print("  - å‡†ç¡®ç‡: 33.3%")
        print("  - é—®é¢˜: 2æ¬¡å°†å¹¿æ’­å’Œååº”æ‹†åˆ†")
        
        print(f"\n**ä¼˜åŒ–å**ï¼ˆæœ¬æ¬¡æµ‹è¯•ï¼‰ï¼š")
        print(f"  - æ­£ç¡®æ¬¡æ•°: {correct_count}/3")
        print(f"  - å‡†ç¡®ç‡: {accuracy:.1f}%")
        
        improvement = accuracy - 33.3
        if improvement > 0:
            print(f"  - ğŸ“ˆ æå‡: +{improvement:.1f}%")
            if accuracy == 100:
                print(f"  - ğŸ‰ å®Œç¾ï¼3æ¬¡å…¨éƒ¨æ­£ç¡®ï¼")
            elif accuracy >= 66.7:
                print(f"  - âœ… æ˜¾è‘—æ”¹å–„")
            else:
                print(f"  - ğŸ“Š æœ‰æ”¹å–„ä½†ä»ä¸ç¨³å®š")
        elif improvement == 0:
            print(f"  - âš ï¸ æ— æ˜æ˜¾æ”¹å–„")
        else:
            print(f"  - âš ï¸ åè€Œä¸‹é™äº†")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = output_dir / f"optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# Prompt ä¼˜åŒ–æ•ˆæœæŠ¥å‘Š\n\n")
            f.write(f"**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            f.write("## ä¼˜åŒ–å†…å®¹\n\n")
            f.write("1. æ·»åŠ è¯¦ç»†çš„ã€Œåˆ†æ®µç¦å¿Œã€è¯´æ˜ï¼ˆé”™è¯¯ç¤ºä¾‹+æ­£ç¡®ç¤ºä¾‹ï¼‰\n")
            f.write("2. å¼ºåŒ–ã€Œé»„é‡‘è§„åˆ™ã€ï¼ˆæƒ…ç»ªè¿è´¯æ€§ > å†…å®¹å½¢å¼ï¼‰\n")
            f.write("3. æä¾›æ­£ç¡®çš„æ®µè½1ç¤ºä¾‹ï¼ˆ165å­—ï¼ŒåŒ…å«å®Œæ•´æƒ…ç»ªå•å…ƒï¼‰\n")
            f.write("4. æ·»åŠ åˆ†æ®µå†³ç­–æµç¨‹å›¾\n")
            f.write("5. æ·»åŠ åˆ†æ®µå‰è‡ªæ£€æ¸…å•\n")
            f.write("6. æ·»åŠ è¾“å‡ºå‰æœ€åæ£€æŸ¥æ¸…å•\n\n")
            f.write("---\n\n")
            f.write("## æµ‹è¯•ç»“æœ\n\n")
            f.write(f"**æ­£ç¡®ç‡**: {accuracy:.1f}% ({correct_count}/3)\n\n")
            f.write("| è¿è¡Œ | å­—æ•° | é™ˆé‡ååº” | è½¦é˜Ÿæƒ…ç»ª | åˆ¤å®š |\n")
            f.write("|-----|------|---------|---------|------|\n")
            for r in results:
                chenye_mark = "âœ…" if r['has_chenye'] else "âŒ"
                convoy_mark = "âœ…" if r['has_convoy'] else "âŒ"
                result_mark = "âœ…" if r['is_correct'] else "âŒ"
                f.write(f"| ç¬¬{r['run']}æ¬¡ | {r['word_count']} | {chenye_mark} | {convoy_mark} | {result_mark} |\n")
            
            f.write("\n## å¯¹æ¯”åˆ†æ\n\n")
            f.write(f"- **ä¼˜åŒ–å‰å‡†ç¡®ç‡**: 33.3% (1/3)\n")
            f.write(f"- **ä¼˜åŒ–åå‡†ç¡®ç‡**: {accuracy:.1f}% ({correct_count}/3)\n")
            f.write(f"- **æå‡å¹…åº¦**: {improvement:+.1f}%\n\n")
            
            if accuracy == 100:
                f.write("## ç»“è®º\n\n")
                f.write("âœ… **Prompt ä¼˜åŒ–éå¸¸æˆåŠŸï¼** DeepSeek åœ¨æ–° prompt ä¸‹è¡¨ç°ç¨³å®šï¼Œ3æ¬¡æµ‹è¯•å…¨éƒ¨æ­£ç¡®ã€‚\n\n")
                f.write("**å»ºè®®**ï¼šå¯ä»¥ä½¿ç”¨ä¼˜åŒ–åçš„ DeepSeek è¿›è¡Œæ‰¹é‡åˆ†æã€‚\n")
            elif accuracy >= 66.7:
                f.write("## ç»“è®º\n\n")
                f.write("âœ… **Prompt ä¼˜åŒ–æ•ˆæœæ˜¾è‘—**ï¼ŒDeepSeek çš„å‡†ç¡®ç‡æœ‰æ˜æ˜¾æå‡ã€‚\n\n")
                f.write("**å»ºè®®**ï¼šå¯ä»¥è°¨æ…ä½¿ç”¨ï¼Œä½†å»ºè®®æ·»åŠ åå¤„ç†æ ¡éªŒæœºåˆ¶ã€‚\n")
            else:
                f.write("## ç»“è®º\n\n")
                f.write("âš ï¸ **Prompt ä¼˜åŒ–æ•ˆæœæœ‰é™**ï¼ŒDeepSeek ä»ä¸å¤Ÿç¨³å®šã€‚\n\n")
                f.write("**å»ºè®®**ï¼šè€ƒè™‘åˆ‡æ¢åˆ° Claude API æˆ–ä½¿ç”¨å¤šæ¬¡è¿è¡Œ+æŠ•ç¥¨æœºåˆ¶ã€‚\n")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file.name}")
    
    print("\n" + "="*80)


if __name__ == "__main__":
    main()
