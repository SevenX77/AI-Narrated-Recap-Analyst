#!/usr/bin/env python3
"""
æ‰¹é‡çˆ¬å–æ‰€æœ‰ç•ªèŒ„å°è¯´æ¦œå•

ä½¿ç”¨æ–¹æ³•:
    python3 scripts/batch_crawl_all_rankings.py
    
åŠŸèƒ½:
    - è‡ªåŠ¨éå†æ‰€æœ‰37ä¸ªæ¦œå•
    - ä½¿ç”¨Playwright MCPæå–æ•°æ®
    - ä¿å­˜ä¸ºJSONæ–‡ä»¶
    - ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.core.config import config

# JavaScriptæå–è„šæœ¬ï¼ˆé€šç”¨æ¨¡æ¿ï¼‰
EXTRACT_JS_TEMPLATE = """() => {
  const novels = [];
  const processedUrls = new Set();
  
  const novelLinks = document.querySelectorAll('a[href*="/page/7"]');
  
  novelLinks.forEach((link) => {
    try {
      const url = link.href;
      if (processedUrls.has(url)) return;
      processedUrls.add(url);
      
      const title = link.textContent.trim();
      if (!title || title.length < 2) return;
      
      let container = link;
      for (let i = 0; i < 10; i++) {
        container = container.parentElement;
        if (!container) break;
        
        const hasAuthor = container.querySelector('a[href*="/author-page/"]');
        const hasImage = container.querySelector('img');
        if (hasAuthor || hasImage) break;
      }
      
      if (!container) return;
      
      const authorLink = container.querySelector('a[href*="/author-page/"]');
      const author = authorLink ? authorLink.textContent.trim() : '';
      
      const rankElem = container.querySelector('h1');
      let rank = novels.length + 1;
      if (rankElem) {
        const rankText = rankElem.textContent.trim();
        const rankMatch = rankText.match(/\\d+/);
        if (rankMatch) rank = parseInt(rankMatch[0]);
      }
      
      const allText = container.textContent;
      
      let status = '';
      if (allText.includes('å·²å®Œç»“')) status = 'å·²å®Œç»“';
      else if (allText.includes('è¿è½½ä¸­')) status = 'è¿è½½ä¸­';
      
      const readersMatch = allText.match(/åœ¨è¯»[ï¼š:]\\s*([\\d.]+ä¸‡?)/);
      const readers = readersMatch ? readersMatch[1] : '';
      
      const chapterMatch = allText.match(/æœ€è¿‘æ›´æ–°[ï¼š:]\\s*([^\\n]+)/);
      const latestChapter = chapterMatch ? chapterMatch[1].substring(0, 50) : '';
      
      const dateMatch = allText.match(/(\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2})/);
      const lastUpdated = dateMatch ? dateMatch[1] : '';
      
      novels.push({
        rank: rank,
        title: title,
        author: author,
        url: url,
        status: status,
        readers: readers,
        latest_chapter: latestChapter,
        last_updated: lastUpdated
      });
      
    } catch (e) {
      console.error('å¤„ç†å¤±è´¥:', e);
    }
  });
  
  novels.sort((a, b) => a.rank - b.rank);
  
  return {
    success: true,
    ranking_name: 'RANKING_NAME',
    category: 'CATEGORY',
    url: window.location.href,
    total: novels.length,
    novels: novels
  };
}"""

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ å¼€å§‹æ‰¹é‡çˆ¬å–æ‰€æœ‰ç•ªèŒ„å°è¯´æ¦œå•")
    print("=" * 80)
    
    rankings = config.fanqie.rankings
    output_dir = Path("data/fanqie/rankings")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“Š æ€»æ¦œå•æ•°: {len(rankings)}")
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {output_dir}")
    
    # è¯»å–å·²çˆ¬å–çš„æ¦œå•
    crawled_rankings = set()
    for json_file in output_dir.glob("*.json"):
        if "_test" in json_file.name or "_202" in json_file.name:
            continue
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if 'ranking_name' in data:
                    crawled_rankings.add(data['ranking_name'])
        except:
            pass
    
    print(f"âœ… å·²çˆ¬å–: {len(crawled_rankings)} ä¸ªæ¦œå•")
    print(f"â³ å‰©ä½™: {len(rankings) - len(crawled_rankings)} ä¸ªæ¦œå•")
    
    # å‡†å¤‡å¾…çˆ¬å–åˆ—è¡¨
    todo_rankings = []
    for name, info in rankings.items():
        if name not in crawled_rankings:
            todo_rankings.append((name, info))
    
    if not todo_rankings:
        print("\nâœ¨ æ‰€æœ‰æ¦œå•å·²çˆ¬å–å®Œæˆï¼")
        return
    
    print(f"\nğŸ“ å¾…çˆ¬å–æ¦œå•:")
    for i, (name, _) in enumerate(todo_rankings[:10], 1):
        print(f"  {i:2d}. {name}")
    if len(todo_rankings) > 10:
        print(f"  ... è¿˜æœ‰ {len(todo_rankings) - 10} ä¸ªæ¦œå•")
    
    print("\n" + "=" * 80)
    print("âš ï¸  æ³¨æ„: æ­¤è„šæœ¬éœ€è¦æ‰‹åŠ¨é…åˆPlaywright MCPå·¥å…·ä½¿ç”¨")
    print("=" * 80)
    print("\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œ:")
    print("  1. ç¡®ä¿Playwrightæµè§ˆå™¨å·²å¯åŠ¨")
    print("  2. ä½¿ç”¨mcp_playwright_browser_navigateå¯¼èˆªåˆ°æ¯ä¸ªæ¦œå•URL")
    print("  3. ä½¿ç”¨mcp_playwright_browser_evaluateæ‰§è¡Œæå–è„šæœ¬")
    print("  4. å°†è¿”å›çš„JSONæ•°æ®ä¿å­˜åˆ°å¯¹åº”æ–‡ä»¶")
    
    print("\nå¾…çˆ¬å–æ¦œå•URLåˆ—è¡¨:")
    print("-" * 80)
    
    ranking_urls = []
    for name, info in todo_rankings:
        ranking_urls.append({
            "name": name,
            "url": info['url'],
            "category": info['category'],
            "output_file": f"data/fanqie/rankings/{name}.json"
        })
    
    # ä¿å­˜å¾…çˆ¬å–æ¸…å•
    urls_file = output_dir / "todo_rankings.json"
    with open(urls_file, 'w', encoding='utf-8') as f:
        json.dump(ranking_urls, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å¾…çˆ¬å–æ¸…å•å·²ä¿å­˜: {urls_file}")
    print(f"\næ€»è®¡ {len(ranking_urls)} ä¸ªæ¦œå•å¾…çˆ¬å–")
    
    # è¾“å‡ºå‰5ä¸ªç¤ºä¾‹
    print("\nç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰:")
    for i, item in enumerate(ranking_urls[:5], 1):
        print(f"\n{i}. {item['name']}")
        print(f"   URL: {item['url']}")
        print(f"   ç±»åˆ«: {'ç”·é¢‘' if item['category'] == 'male' else 'å¥³é¢‘'}")
        print(f"   ä¿å­˜: {item['output_file']}")

if __name__ == "__main__":
    main()
