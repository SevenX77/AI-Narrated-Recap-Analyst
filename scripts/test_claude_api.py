#!/usr/bin/env python3
"""
Claude API æµ‹è¯•è„šæœ¬
ç”¨é€”ï¼šæµ‹è¯• Claude Sonnet 4.5 Thinking æ¨¡å‹çš„è¿æ¥æ€§å’Œå“åº”è´¨é‡
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from openai import OpenAI
import json
from datetime import datetime

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def estimate_tokens(text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡ï¼ˆç²—ç•¥ä¼°è®¡ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼‰
    """
    return len(text) // 4

def calculate_cost(input_tokens: int, output_tokens: int) -> dict:
    """
    è®¡ç®— Claude Sonnet 4.5 çš„è´¹ç”¨
    ä»·æ ¼ï¼šè¾“å…¥ $3/M tokensï¼Œè¾“å‡º $15/M tokens
    """
    input_cost = (input_tokens / 1_000_000) * 3
    output_cost = (output_tokens / 1_000_000) * 15
    total_cost = input_cost + output_cost
    
    return {
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "input_cost_usd": round(input_cost, 6),
        "output_cost_usd": round(output_cost, 6),
        "total_cost_usd": round(total_cost, 6),
        "total_cost_cny": round(total_cost * 7.2, 4),  # å‡è®¾æ±‡ç‡ 1 USD = 7.2 CNY
    }

def test_basic_connection():
    """æµ‹è¯•åŸºç¡€è¿æ¥"""
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯• 1: åŸºç¡€è¿æ¥æµ‹è¯•")
    print("="*60)
    
    api_key = os.getenv("CLAUDE_API_KEY")
    base_url = os.getenv("CLAUDE_BASE_URL", "https://api.anthropic.com/v1")
    model = os.getenv("CLAUDE_MODEL_NAME", "claude-sonnet-4-5-20250929")
    
    if not api_key:
        print("âŒ é”™è¯¯: CLAUDE_API_KEY æœªè®¾ç½®")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® CLAUDE_API_KEY")
        return False
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   API Key: {api_key[:20]}...{api_key[-10:]}")
    print(f"   Base URL: {base_url}")
    print(f"   Model: {model}")
    
    try:
        # OneChats ä½¿ç”¨ OpenAI å…¼å®¹çš„ API
        client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚"
        
        print(f"\nğŸ“¤ å‘é€æµ‹è¯•è¯·æ±‚...")
        print(f"   æç¤ºè¯: {test_prompt}")
        
        response = client.chat.completions.create(
            model=model,
            max_tokens=100,
            messages=[{
                "role": "user",
                "content": test_prompt
            }]
        )
        
        print(f"\nâœ… è¿æ¥æˆåŠŸ!")
        print(f"   å“åº”: {response.choices[0].message.content}")
        
        # è®¡ç®—è´¹ç”¨
        cost_info = calculate_cost(
            response.usage.prompt_tokens,
            response.usage.completion_tokens
        )
        
        print(f"\nğŸ’° è´¹ç”¨ç»Ÿè®¡:")
        print(f"   è¾“å…¥ tokens: {cost_info['input_tokens']}")
        print(f"   è¾“å‡º tokens: {cost_info['output_tokens']}")
        print(f"   æœ¬æ¬¡è´¹ç”¨: ${cost_info['total_cost_usd']} (â‰ˆ Â¥{cost_info['total_cost_cny']})")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ è¿æ¥å¤±è´¥: {str(e)}")
        return False

def test_thinking_mode():
    """æµ‹è¯• Thinking æ¨¡å¼ï¼ˆè¾ƒé•¿æ¨ç†ä»»åŠ¡ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ§  æµ‹è¯• 2: Thinking æ¨¡å¼æµ‹è¯•")
    print("="*60)
    
    api_key = os.getenv("CLAUDE_API_KEY")
    base_url = os.getenv("CLAUDE_BASE_URL", "https://api.anthropic.com/v1")
    model = os.getenv("CLAUDE_MODEL_NAME", "claude-sonnet-4-5-20250929")
    max_tokens = int(os.getenv("CLAUDE_MAX_TOKENS", "4096"))
    
    try:
        # OneChats ä½¿ç”¨ OpenAI å…¼å®¹çš„ API
        client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
        # ä½¿ç”¨ä¸€ä¸ªéœ€è¦æ¨ç†çš„é—®é¢˜
        test_prompt = """
è¯·åˆ†æä»¥ä¸‹å°è¯´ç‰‡æ®µçš„å™äº‹åŠŸèƒ½ï¼š

"å¼ æ˜æ¨å¼€é—¨ï¼Œå±‹å†…ä¸€ç‰‡æ¼†é»‘ã€‚ä»–æ‘¸ç´¢ç€æ‰¾åˆ°å¼€å…³ï¼Œç¯å…‰äº®èµ·çš„ç¬é—´ï¼Œä»–çœ‹åˆ°äº†æ¡Œä¸Šé‚£å°ä¿¡ã€‚"

è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æï¼š
1. æƒ…èŠ‚æ¨è¿›ä½œç”¨
2. æ°›å›´è¥é€ 
3. äººç‰©å¡‘é€ 
"""
        
        print(f"ğŸ“¤ å‘é€æ¨ç†ä»»åŠ¡...")
        print(f"   ä»»åŠ¡: å™äº‹åŠŸèƒ½åˆ†æ")
        print(f"   æœ€å¤§ tokens: {max_tokens}")
        
        start_time = datetime.now()
        
        response = client.chat.completions.create(
            model=model,
            max_tokens=max_tokens,
            messages=[{
                "role": "user",
                "content": test_prompt
            }]
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"\nâœ… æ¨ç†å®Œæˆ!")
        print(f"   è€—æ—¶: {duration:.2f} ç§’")
        print(f"\nğŸ“Š å“åº”å†…å®¹:")
        print("-" * 60)
        print(response.choices[0].message.content)
        print("-" * 60)
        
        # è®¡ç®—è´¹ç”¨
        cost_info = calculate_cost(
            response.usage.prompt_tokens,
            response.usage.completion_tokens
        )
        
        print(f"\nğŸ’° è´¹ç”¨ç»Ÿè®¡:")
        print(f"   è¾“å…¥ tokens: {cost_info['input_tokens']}")
        print(f"   è¾“å‡º tokens: {cost_info['output_tokens']}")
        print(f"   æœ¬æ¬¡è´¹ç”¨: ${cost_info['total_cost_usd']} (â‰ˆ Â¥{cost_info['total_cost_cny']})")
        print(f"   å¹³å‡é€Ÿåº¦: {cost_info['output_tokens']/duration:.1f} tokens/ç§’")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_with_project_config():
    """æµ‹è¯•ä½¿ç”¨é¡¹ç›®é…ç½®"""
    print("\n" + "="*60)
    print("âš™ï¸  æµ‹è¯• 3: é¡¹ç›®é…ç½®é›†æˆæµ‹è¯•")
    print("="*60)
    
    try:
        from src.core.config import config
        
        print(f"ğŸ“‹ å½“å‰é…ç½®:")
        print(f"   LLM Provider: {config.llm.provider}")
        print(f"   Model: {config.llm.model_name}")
        print(f"   Base URL: {config.llm.base_url}")
        
        if config.llm.provider != "claude":
            print(f"\nâš ï¸  æ³¨æ„: å½“å‰ LLM_PROVIDER è®¾ç½®ä¸º '{config.llm.provider}'")
            print(f"   å¦‚éœ€æµ‹è¯• Claudeï¼Œè¯·åœ¨ .env ä¸­è®¾ç½®: LLM_PROVIDER=claude")
            return False
        
        provider_config = config.llm.get_provider_config()
        
        print(f"\nğŸ“¦ å®Œæ•´é…ç½®:")
        print(json.dumps(
            {k: v for k, v in provider_config.items() if k != "api_key"},
            indent=2,
            ensure_ascii=False
        ))
        
        print(f"\nâœ… é…ç½®åŠ è½½æˆåŠŸ!")
        print(f"   æ‚¨å¯ä»¥åœ¨ä»£ç ä¸­ç›´æ¥ä½¿ç”¨ config.llm æ¥è®¿é—® Claude é…ç½®")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("ğŸš€ Claude Sonnet 4.5 Thinking æ¨¡å‹æµ‹è¯•")
    print("="*60)
    print(f"â° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.path.exists(project_root / ".env"):
        print("\nâš ï¸  è­¦å‘Š: .env æ–‡ä»¶ä¸å­˜åœ¨")
        print("è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ›å»º:")
        print("1. å¤åˆ¶ .env.example ä¸º .env")
        print("2. ç¡®ä¿ CLAUDE_API_KEY å·²æ­£ç¡®é…ç½®")
        print("3. è®¾ç½® LLM_PROVIDER=claude")
        return
    
    results = []
    
    # æµ‹è¯• 1: åŸºç¡€è¿æ¥
    results.append(("åŸºç¡€è¿æ¥", test_basic_connection()))
    
    # æµ‹è¯• 2: Thinking æ¨¡å¼
    if results[0][1]:  # åªæœ‰è¿æ¥æˆåŠŸæ‰ç»§ç»­
        results.append(("Thinking æ¨¡å¼", test_thinking_mode()))
    
    # æµ‹è¯• 3: é¡¹ç›®é…ç½®
    results.append(("é¡¹ç›®é…ç½®é›†æˆ", test_with_project_config()))
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    all_passed = all(result[1] for result in results)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Claude é…ç½®æˆåŠŸï¼")
        print("\nğŸ“ ä¸‹ä¸€æ­¥:")
        print("   1. åœ¨ .env ä¸­è®¾ç½® LLM_PROVIDER=claude å¯ç”¨ Claude")
        print("   2. è¿è¡Œæ‚¨çš„ä¸»ç¨‹åºï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨ Claude")
        print("   3. éšæ—¶å¯åˆ‡æ¢å› DeepSeek (LLM_PROVIDER=deepseek)")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    print("\n" + "="*60)

if __name__ == "__main__":
    main()
