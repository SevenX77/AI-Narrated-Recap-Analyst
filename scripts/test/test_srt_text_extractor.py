"""
æµ‹è¯•è„šæœ¬ï¼šSrtTextExtractor - SRTæ–‡æœ¬æå–å·¥å…·

æµ‹è¯•ç›®æ ‡ï¼š
1. ä»SRTæ¡ç›®ä¸­æå–æ–‡æœ¬
2. LLMæ™ºèƒ½æ·»åŠ æ ‡ç‚¹ç¬¦å·
3. å®ä½“æ ‡å‡†åŒ–ï¼ˆæœ‰/æ— å°è¯´å‚è€ƒä¸¤ç§æ¨¡å¼ï¼‰
4. é”™å­—ç¼ºå­—ä¿®å¤
5. è¿”å›æ­£ç¡®çš„SrtTextExtractionResult
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.tools.srt_importer import SrtImporter
from src.tools.srt_text_extractor import SrtTextExtractor
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_srt_text_extractor():
    """æµ‹è¯•SrtTextExtractorå·¥å…·"""
    
    # ========== æµ‹è¯•é…ç½® ==========
    test_srt_file = project_root / "archive/v2_data_20260208/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯/raw/ep01.srt"
    test_project_name = "æœ«å“¥è¶…å‡¡å…¬è·¯_test"
    test_episode = "ep01"
    
    # å¯é€‰ï¼šå°è¯´å‚è€ƒæ–‡æœ¬ï¼ˆæµ‹è¯• with_novel æ¨¡å¼ï¼‰
    test_novel_file = project_root / "data/projects/æœ«å“¥è¶…å‡¡å…¬è·¯_test/raw/novel.txt"
    novel_reference = None
    if test_novel_file.exists():
        with open(test_novel_file, 'r', encoding='utf-8') as f:
            # åªè¯»å‰5000å­—ä½œä¸ºå‚è€ƒ
            novel_reference = f.read(5000)
        logger.info(f"Loaded novel reference: {len(novel_reference)} chars")
    else:
        logger.info("No novel reference found, will test without_novel mode")
    
    if not test_srt_file.exists():
        logger.error(f"Test SRT file not found: {test_srt_file}")
        return
    
    logger.info("=" * 80)
    logger.info("æµ‹è¯• SrtTextExtractor - SRTæ–‡æœ¬æå–å·¥å…·")
    logger.info("=" * 80)
    
    # ========== Step 1: å…ˆä½¿ç”¨ SrtImporter å¯¼å…¥SRT ==========
    logger.info(f"\n{'=' * 80}")
    logger.info("Step 1: å¯¼å…¥SRTæ–‡ä»¶ï¼ˆä½¿ç”¨ SrtImporterï¼‰")
    
    importer = SrtImporter()
    import_result = importer.execute(
        source_file=test_srt_file,
        project_name=test_project_name,
        episode_name=test_episode,
        save_to_disk=False,  # ä¸ä¿å­˜ï¼Œä»…å†…å­˜æµ‹è¯•
        include_entries=True
    )
    
    logger.info(f"âœ… å¯¼å…¥æˆåŠŸï¼š{import_result.entry_count} æ¡SRTæ¡ç›®")
    
    # ========== Step 2: ä½¿ç”¨ SrtTextExtractor æå–å’Œå¤„ç†æ–‡æœ¬ ==========
    logger.info(f"\n{'=' * 80}")
    logger.info("Step 2: æå–å’Œå¤„ç†æ–‡æœ¬ï¼ˆä½¿ç”¨ SrtTextExtractorï¼‰")
    
    extractor = SrtTextExtractor(use_llm=True)
    logger.info(f"Tool: {extractor.name}")
    logger.info(f"Description: {extractor.description}")
    
    try:
        result = extractor.execute(
            srt_entries=import_result.entries,
            project_name=test_project_name,
            episode_name=test_episode,
            novel_reference=novel_reference
        )
        
        logger.info(f"\n{'=' * 80}")
        logger.info("âœ… æå–æˆåŠŸï¼")
        logger.info(f"{'=' * 80}")
        
        # ========== è¾“å‡ºç»“æœ ==========
        logger.info("\nğŸ“Š æå–ç»“æœï¼š")
        logger.info(f"  - å¤„ç†æ¨¡å¼: {result.processing_mode}")
        logger.info(f"  - åŸå§‹å­—ç¬¦æ•°: {result.original_chars}")
        logger.info(f"  - å¤„ç†åå­—ç¬¦æ•°: {result.processed_chars}")
        logger.info(f"  - å­—ç¬¦å˜åŒ–: {result.processed_chars - result.original_chars:+d}")
        logger.info(f"  - å¤„ç†è€—æ—¶: {result.processing_time:.2f} ç§’")
        
        # ========== ä¿®æ­£ç»Ÿè®¡ ==========
        logger.info(f"\nğŸ”§ ä¿®æ­£ç»Ÿè®¡ï¼š")
        for correction_type, count in result.corrections.items():
            logger.info(f"  - {correction_type}: {count}")
        
        # ========== å®ä½“æ ‡å‡†åŒ–ä¿¡æ¯ ==========
        if result.entity_standardization:
            logger.info(f"\nğŸ·ï¸  å®ä½“æ ‡å‡†åŒ–ä¿¡æ¯ï¼š")
            if isinstance(result.entity_standardization, dict):
                for category, entities in result.entity_standardization.items():
                    if category == "source":
                        logger.info(f"  - æ¥æº: {entities}")
                    elif isinstance(entities, dict):
                        logger.info(f"  - {category}: {len(entities)} ä¸ªå®ä½“")
                        # æ˜¾ç¤ºå‰3ä¸ªå®ä½“ç¤ºä¾‹
                        for i, (name, info) in enumerate(list(entities.items())[:3], 1):
                            if isinstance(info, list):
                                logger.info(f"    {i}. {name}")
                            elif isinstance(info, dict):
                                logger.info(f"    {i}. {name}: {info.get('standard_form', name)}")
        
        # ========== æ–‡æœ¬ç¤ºä¾‹ ==========
        logger.info(f"\nğŸ“ åŸå§‹æ–‡æœ¬ç¤ºä¾‹ï¼ˆå‰200å­—ï¼‰ï¼š")
        logger.info(f"  {result.raw_text[:200]}...")
        
        logger.info(f"\nâœ¨ å¤„ç†åæ–‡æœ¬ç¤ºä¾‹ï¼ˆå‰300å­—ï¼‰ï¼š")
        logger.info(f"  {result.processed_text[:300]}...")
        
        # ========== ä¿å­˜å¤„ç†åæ–‡æœ¬ï¼ˆå¯é€‰ï¼‰==========
        output_dir = project_root / f"output/temp/{test_project_name}/srt_text_extractor"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_file = output_dir / f"{test_episode}_processed.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(result.processed_text)
        logger.info(f"\nğŸ’¾ å¤„ç†åæ–‡æœ¬å·²ä¿å­˜åˆ°: {output_file}")
        
        # ä¿å­˜åŸå§‹æ–‡æœ¬å¯¹æ¯”
        raw_file = output_dir / f"{test_episode}_raw.txt"
        with open(raw_file, 'w', encoding='utf-8') as f:
            f.write(result.raw_text)
        logger.info(f"ğŸ’¾ åŸå§‹æ–‡æœ¬å·²ä¿å­˜åˆ°: {raw_file}")
        
        logger.info(f"\n{'=' * 80}")
        logger.info("ğŸ‰ æµ‹è¯•å®Œæˆï¼SrtTextExtractor å·¥ä½œæ­£å¸¸")
        logger.info(f"{'=' * 80}\n")
        
        return result
    
    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    test_srt_text_extractor()
