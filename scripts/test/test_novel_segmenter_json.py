#!/usr/bin/env python3
"""
NovelSegmenter JSONè¾“å‡ºæµ‹è¯•è„šæœ¬

æµ‹è¯•æ–°ç‰ˆNovelSegmenterçš„åŠŸèƒ½ï¼š
1. Two-Pass LLMåˆ†æ®µ
2. JSONæ ¼å¼è¾“å‡º
3. åŸæ–‡è¿˜åŸéªŒè¯
"""

import sys
import json
import logging
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.tools.novel_importer import NovelImporter
from src.tools.novel_chapter_detector import NovelChapterDetector
from src.tools.novel_segmenter import NovelSegmenter
from scripts.test.test_helpers import TestOutputManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_novel_segmenter_json():
    """æµ‹è¯•NovelSegmenterçš„JSONè¾“å‡ºå’ŒåŸæ–‡è¿˜åŸ"""
    
    logger.info("\n" + "="*60)
    logger.info("  NovelSegmenter JSONè¾“å‡ºæµ‹è¯•")
    logger.info("="*60 + "\n")
    
    # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
    test_novel_path = Path("åˆ†æèµ„æ–™/æœ‰åŸå°è¯´/01_æœ«å“¥è¶…å‡¡å…¬è·¯/novel/åºåˆ—å…¬è·¯æ±‚ç”Ÿï¼šæˆ‘åœ¨æœ«æ—¥å‡çº§ç‰©èµ„.txt")
    project_name = "æœ«å“¥è¶…å‡¡å…¬è·¯_json_test"
    
    # å¯¼å…¥å°è¯´
    importer = NovelImporter()
    import_result = importer.execute(
        source_file=test_novel_path,
        project_name=project_name
    )
    logger.info(f"Test novel imported to: {import_result.saved_path}")
    
    # åˆ›å»ºæµ‹è¯•è¾“å‡ºç›®å½•
    output_manager = TestOutputManager("novel_segmenter_json")
    
    # 2. è·å–ç¬¬1ç« å†…å®¹
    novel_file = Path(import_result.saved_path)
    chapter_detector = NovelChapterDetector()
    chapters = chapter_detector.execute(novel_file=novel_file)
    
    target_chapter_info = None
    for chapter_info in chapters:
        if chapter_info.number == 1:
            target_chapter_info = chapter_info
            break
    
    if not target_chapter_info:
        logger.error("Chapter 1 not found")
        return False
    
    full_text = novel_file.read_text(encoding='utf-8')
    chapter_content = full_text[target_chapter_info.start_char : target_chapter_info.end_char]
    
    # ç§»é™¤ç« èŠ‚æ ‡é¢˜è¡Œ
    lines = chapter_content.split('\n')
    if lines and lines[0].strip().startswith(f"=== ç¬¬1ç« "):
        chapter_content = '\n'.join(lines[1:]).strip()
    
    logger.info(f"Chapter content: {len(chapter_content)} chars")
    
    # 3. æ‰§è¡Œåˆ†æ®µ
    logger.info("\n" + "="*60)
    logger.info("  æ‰§è¡ŒNovelSegmenter")
    logger.info("="*60)
    
    segmenter = NovelSegmenter(provider="claude")
    
    try:
        result = segmenter.execute(
            chapter_content=chapter_content,
            chapter_number=1
        )
        
        logger.info(f"\nâœ… Segmentation complete!")
        logger.info(f"  Total paragraphs: {result.total_paragraphs}")
        logger.info(f"  Type distribution: {result.metadata['type_distribution']}")
        logger.info(f"  Processing time: {result.metadata['processing_time']}s")
        logger.info(f"  Model used: {result.metadata['model_used']}")
        
    except Exception as e:
        logger.error(f"âŒ Segmentation failed: {e}", exc_info=True)
        return False
    
    # 4. ä¿å­˜JSONè¾“å‡º
    logger.info("\n" + "="*60)
    logger.info("  ä¿å­˜JSONè¾“å‡º")
    logger.info("="*60)
    
    output_json = result.model_dump(mode='json')
    output_manager.save_json("segmentation_result.json", output_json)
    
    logger.info(f"âœ… JSON saved: {output_manager.get_path() / 'segmentation_result.json'}")
    
    # 5. éªŒè¯åŸæ–‡è¿˜åŸ
    logger.info("\n" + "="*60)
    logger.info("  éªŒè¯åŸæ–‡è¿˜åŸ")
    logger.info("="*60)
    
    restored_text = ''.join([p.content for p in result.paragraphs])
    original_stripped = chapter_content.rstrip()
    restored_stripped = restored_text.rstrip()
    
    if original_stripped == restored_stripped:
        logger.info("âœ… Text restoration: PASSED")
        restoration_status = "PASSED"
    else:
        diff_chars = len(original_stripped) - len(restored_stripped)
        logger.warning(f"âš ï¸ Text restoration: FAILED")
        logger.warning(f"  Original length: {len(original_stripped)}")
        logger.warning(f"  Restored length: {len(restored_stripped)}")
        logger.warning(f"  Difference: {diff_chars} chars")
        restoration_status = "FAILED"
        
        # ä¿å­˜å¯¹æ¯”æ–‡ä»¶
        output_manager.save_text("original_text.txt", original_stripped)
        output_manager.save_text("restored_text.txt", restored_stripped)
    
    # 6. ç”Ÿæˆæ®µè½æ‘˜è¦ï¼ˆç”¨äºäººå·¥æŸ¥çœ‹ï¼‰
    logger.info("\n" + "="*60)
    logger.info("  ç”Ÿæˆæ®µè½æ‘˜è¦")
    logger.info("="*60)
    
    summary_lines = [
        f"# ç¬¬{result.chapter_number}ç« åˆ†æ®µç»“æœæ‘˜è¦\n",
        f"**æ€»æ®µè½æ•°**: {result.total_paragraphs}\n",
        f"**ç±»å‹åˆ†å¸ƒ**: {result.metadata['type_distribution']}\n",
        f"**å¤„ç†æ—¶é—´**: {result.metadata['processing_time']}ç§’\n",
        f"**åŸæ–‡è¿˜åŸ**: {restoration_status}\n",
        "\n## æ®µè½åˆ—è¡¨\n"
    ]
    
    for para in result.paragraphs:
        summary_lines.append(f"\n### æ®µè½{para.index}ï¼ˆ{para.type}ç±»ï¼‰\n")
        summary_lines.append(f"- **ä½ç½®**: å­—ç¬¦ [{para.start_char}, {para.end_char})\n")
        summary_lines.append(f"- **é•¿åº¦**: {len(para.content)} å­—ç¬¦\n")
        summary_lines.append(f"- **å¼€å¤´**: {para.content[:50]}...\n")
    
    summary_text = ''.join(summary_lines)
    output_manager.save_text("segmentation_summary.md", summary_text)
    
    logger.info(f"âœ… Summary saved: {output_manager.get_path() / 'segmentation_summary.md'}")
    
    # 7. å¯¹æ¯”æ ‡å‡†ç»“æœï¼ˆå¯é€‰ï¼‰
    standard_paragraph_count = 11
    if result.total_paragraphs == standard_paragraph_count:
        logger.info(f"\nâœ… Paragraph count matches standard: {standard_paragraph_count}")
    else:
        logger.warning(f"\nâš ï¸ Paragraph count mismatch: {result.total_paragraphs} vs standard {standard_paragraph_count}")
    
    # 8. æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "="*60)
    print("  ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦")
    print("="*60 + "\n")
    print(f"âœ… åˆ†æ®µå®Œæˆ: {result.total_paragraphs}ä¸ªæ®µè½")
    print(f"  - Aç±»ï¼ˆè®¾å®šï¼‰: {result.metadata['type_distribution']['A']}ä¸ª")
    print(f"  - Bç±»ï¼ˆäº‹ä»¶ï¼‰: {result.metadata['type_distribution']['B']}ä¸ª")
    print(f"  - Cç±»ï¼ˆç³»ç»Ÿï¼‰: {result.metadata['type_distribution']['C']}ä¸ª")
    print(f"\n{'âœ…' if restoration_status == 'PASSED' else 'âš ï¸'} åŸæ–‡è¿˜åŸ: {restoration_status}")
    print(f"\nâ±ï¸  å¤„ç†æ—¶é—´: {result.metadata['processing_time']}ç§’")
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_manager.get_path()}")
    print(f"\nğŸ’¡ æŸ¥çœ‹ç»“æœ:")
    print(f"  JSON: cat '{output_manager.get_path() / 'segmentation_result.json'}'")
    print(f"  æ‘˜è¦: cat '{output_manager.get_path() / 'segmentation_summary.md'}'")
    print("\n" + "="*60 + "\n")
    
    # 9. æ¸…ç†æµ‹è¯•æ•°æ®
    import shutil
    test_project_dir = Path("data/projects") / project_name
    if test_project_dir.exists():
        shutil.rmtree(test_project_dir)
        logger.info(f"Test project cleaned up: {test_project_dir}")
    
    return restoration_status == "PASSED"


if __name__ == "__main__":
    try:
        success = test_novel_segmenter_json()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"Test failed: {e}", exc_info=True)
        sys.exit(1)
