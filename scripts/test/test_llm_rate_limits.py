"""
LLMé™æµè§„åˆ™æµ‹è¯•å·¥å…·

è‡ªåŠ¨æµ‹è¯•å„ä¸ªLLMæä¾›å•†çš„å®é™…é™æµè§„åˆ™ï¼Œå¹¶æ›´æ–°é…ç½®ã€‚
"""

import asyncio
import sys
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.core.llm_rate_limiter import LLMCallManager, LLMRateLimitConfig


class LLMRateLimitTester:
    """LLMé™æµè§„åˆ™æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.manager = LLMCallManager()
        self.test_results: Dict[str, Dict] = {}
    
    async def test_provider(
        self,
        provider: str,
        model: str,
        test_func,
        test_duration: int = 60,
        ramp_up_delay: float = 1.0
    ) -> Dict:
        """
        æµ‹è¯•å•ä¸ªæä¾›å•†çš„é™æµè§„åˆ™
        
        Args:
            provider: æä¾›å•†åç§°
            model: æ¨¡å‹åç§°
            test_func: æµ‹è¯•ç”¨çš„APIè°ƒç”¨å‡½æ•°
            test_duration: æµ‹è¯•æ—¶é•¿ï¼ˆç§’ï¼‰
            ramp_up_delay: åˆå§‹å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œé€æ¸å‡å°‘
        
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        print("=" * 80)
        print(f"ğŸ§ª æµ‹è¯• {provider}/{model}")
        print("=" * 80)
        
        start_time = time.time()
        success_count = 0
        rate_limit_count = 0
        error_count = 0
        last_success_time = start_time
        
        # è®°å½•è¯·æ±‚æ—¶é—´æˆ³
        request_times: List[float] = []
        
        # æµ‹è¯•é€»è¾‘ï¼šé€æ¸åŠ å¿«è¯·æ±‚é¢‘ç‡ï¼Œç›´åˆ°è§¦å‘é™æµ
        current_delay = ramp_up_delay
        
        while time.time() - start_time < test_duration:
            try:
                # è®°å½•è¯·æ±‚æ—¶é—´
                request_time = time.time()
                request_times.append(request_time)
                
                # è°ƒç”¨API
                print(f"ğŸ“ å‘èµ·è¯·æ±‚ï¼ˆå»¶è¿Ÿ={current_delay:.2f}sï¼‰...", end=" ")
                result = test_func()
                
                # æˆåŠŸ
                success_count += 1
                last_success_time = request_time
                print(f"âœ… æˆåŠŸï¼ˆæ€»è®¡{success_count}æ¬¡ï¼‰")
                
                # é€æ¸ç¼©çŸ­å»¶è¿Ÿ
                current_delay = max(0.1, current_delay * 0.9)
                
            except Exception as e:
                error_msg = str(e)
                
                # åˆ¤æ–­é”™è¯¯ç±»å‹
                is_rate_limit = any(
                    code in error_msg
                    for code in ["403", "429", "rate limit", "too many requests"]
                )
                
                if is_rate_limit:
                    rate_limit_count += 1
                    print(f"ğŸš« è§¦å‘é™æµï¼ˆæ€»è®¡{rate_limit_count}æ¬¡ï¼‰")
                    
                    # è§¦å‘é™æµåå»¶é•¿å»¶è¿Ÿ
                    current_delay = min(10.0, current_delay * 2)
                else:
                    error_count += 1
                    print(f"âŒ å…¶ä»–é”™è¯¯: {error_msg[:50]}")
            
            # ç­‰å¾…
            await asyncio.sleep(current_delay)
        
        # åˆ†æç»“æœ
        elapsed = time.time() - start_time
        
        # è®¡ç®—QPMï¼ˆåŸºäºæœ€è¿‘1åˆ†é’Ÿçš„æˆåŠŸè¯·æ±‚ï¼‰
        recent_requests = [t for t in request_times if t > last_success_time - 60]
        estimated_qpm = len(recent_requests) if recent_requests else success_count
        
        result = {
            "provider": provider,
            "model": model,
            "test_date": datetime.now().isoformat(),
            "test_duration_seconds": int(elapsed),
            "total_requests": success_count + rate_limit_count + error_count,
            "successful_requests": success_count,
            "rate_limited_requests": rate_limit_count,
            "other_errors": error_count,
            "estimated_qpm": estimated_qpm,
            "average_delay": elapsed / success_count if success_count > 0 else 0,
            "notes": ""
        }
        
        # æ·»åŠ å»ºè®®é…ç½®
        if rate_limit_count > 0:
            # è§¦å‘äº†é™æµï¼Œä½¿ç”¨ä¿å®ˆä¼°è®¡
            suggested_qpm = int(estimated_qpm * 0.8)  # ç•™20%ä½™é‡
            result["suggested_qpm"] = suggested_qpm
            result["notes"] = f"è§¦å‘{rate_limit_count}æ¬¡é™æµï¼Œå»ºè®®QPMè®¾ç½®ä¸º{suggested_qpm}"
        else:
            # æœªè§¦å‘é™æµï¼Œå¯ä»¥æ›´æ¿€è¿›
            result["suggested_qpm"] = estimated_qpm
            result["notes"] = f"æœªè§¦å‘é™æµï¼Œå¯è®¾ç½®QPMä¸º{estimated_qpm}æˆ–æ›´é«˜"
        
        self.test_results[f"{provider}_{model}"] = result
        
        print("\n" + "=" * 80)
        print("ğŸ“Š æµ‹è¯•ç»“æœ")
        print("=" * 80)
        print(f"æµ‹è¯•æ—¶é•¿: {elapsed:.1f}ç§’")
        print(f"æˆåŠŸè¯·æ±‚: {success_count}")
        print(f"é™æµæ¬¡æ•°: {rate_limit_count}")
        print(f"å…¶ä»–é”™è¯¯: {error_count}")
        print(f"ä¼°ç®—QPM: {estimated_qpm}")
        print(f"å»ºè®®QPM: {result['suggested_qpm']}")
        print(f"å¤‡æ³¨: {result['notes']}")
        print("=" * 80)
        print()
        
        return result
    
    async def quick_test_all(self):
        """å¿«é€Ÿæµ‹è¯•æ‰€æœ‰å·²é…ç½®çš„æä¾›å•†"""
        print("ğŸš€ å¼€å§‹å¿«é€Ÿæµ‹è¯•æ‰€æœ‰LLMæä¾›å•†")
        print()
        
        # è¿™é‡Œéœ€è¦å®é™…çš„APIè°ƒç”¨å‡½æ•°
        # æš‚æ—¶ä½¿ç”¨mockå‡½æ•°æ¼”ç¤º
        def mock_api_call():
            """æ¨¡æ‹ŸAPIè°ƒç”¨"""
            import random
            time.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
            
            # 10%æ¦‚ç‡è§¦å‘é™æµ
            if random.random() < 0.1:
                raise Exception("Error code: 403 - access forbidden")
            
            return {"status": "success"}
        
        # æµ‹è¯•æ‰€æœ‰æä¾›å•†
        for key, config in self.manager.configs.items():
            if key == "conservative":
                continue  # è·³è¿‡ä¿å®ˆé…ç½®
            
            try:
                await self.test_provider(
                    provider=config.provider,
                    model=config.model,
                    test_func=mock_api_call,
                    test_duration=30,  # å¿«é€Ÿæµ‹è¯•30ç§’
                    ramp_up_delay=2.0
                )
            except KeyboardInterrupt:
                print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
                break
            except Exception as e:
                print(f"âŒ æµ‹è¯•{key}æ—¶å‡ºé”™: {e}")
                continue
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        self._save_test_results()
    
    def _save_test_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        import json
        
        results_file = Path("data/llm_rate_limit_test_results.json")
        results_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    def update_configs_from_test(self):
        """æ ¹æ®æµ‹è¯•ç»“æœæ›´æ–°é…ç½®"""
        print("\nğŸ”§ æ ¹æ®æµ‹è¯•ç»“æœæ›´æ–°é…ç½®")
        
        for key, result in self.test_results.items():
            suggested_qpm = result.get("suggested_qpm")
            if suggested_qpm:
                self.manager.update_config(
                    key,
                    requests_per_minute=suggested_qpm,
                    is_tested=True,
                    last_test_date=result["test_date"],
                    test_notes=result["notes"]
                )
                print(f"âœ… æ›´æ–°{key}: QPM={suggested_qpm}")
        
        print("âœ… é…ç½®æ›´æ–°å®Œæˆ")


async def interactive_test():
    """äº¤äº’å¼æµ‹è¯•"""
    tester = LLMRateLimitTester()
    
    print("=" * 80)
    print("ğŸ§ª LLMé™æµè§„åˆ™æµ‹è¯•å·¥å…·")
    print("=" * 80)
    print()
    print("é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å¿«é€Ÿæµ‹è¯•æ‰€æœ‰æä¾›å•†ï¼ˆä½¿ç”¨mockæ•°æ®ï¼‰")
    print("2. æµ‹è¯•å•ä¸ªæä¾›å•†ï¼ˆéœ€è¦å®é™…APIï¼‰")
    print("3. æŸ¥çœ‹å½“å‰é…ç½®")
    print("4. é€€å‡º")
    print()
    
    choice = input("è¯·é€‰æ‹© (1-4): ").strip()
    
    if choice == "1":
        await tester.quick_test_all()
        
        # è¯¢é—®æ˜¯å¦æ›´æ–°é…ç½®
        update = input("\næ˜¯å¦æ ¹æ®æµ‹è¯•ç»“æœæ›´æ–°é…ç½®ï¼Ÿ(y/n): ").strip().lower()
        if update == 'y':
            tester.update_configs_from_test()
    
    elif choice == "2":
        print("\nâš ï¸ éœ€è¦å®é™…APIæ‰èƒ½æµ‹è¯•ï¼Œè¯·è‡ªè¡Œå®ç°test_func")
    
    elif choice == "3":
        print("\nğŸ“‹ å½“å‰é…ç½®:")
        print("=" * 80)
        for key, config in tester.manager.configs.items():
            print(f"\n{key}:")
            print(f"  æä¾›å•†: {config.provider}")
            print(f"  æ¨¡å‹: {config.model}")
            print(f"  QPM: {config.requests_per_minute}")
            print(f"  QPD: {config.requests_per_day}")
            print(f"  æœ€å¤§å¹¶å‘: {config.max_concurrent}")
            print(f"  å·²æµ‹è¯•: {config.is_tested}")
            if config.last_test_date:
                print(f"  æµ‹è¯•æ—¥æœŸ: {config.last_test_date}")
            if config.test_notes:
                print(f"  å¤‡æ³¨: {config.test_notes}")
        print("=" * 80)
    
    elif choice == "4":
        print("ğŸ‘‹ é€€å‡º")
        return


if __name__ == "__main__":
    asyncio.run(interactive_test())
