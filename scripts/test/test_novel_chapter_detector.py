"""
NovelChapterDetector Tool Test Script
æµ‹è¯• NovelChapterDetector å·¥å…·çš„åŠŸèƒ½æ­£ç¡®æ€§

æµ‹è¯•å†…å®¹ï¼š
1. æ­£å¸¸ç« èŠ‚æ£€æµ‹
2. ç« èŠ‚ä½ç½®è®¡ç®—
3. ç« èŠ‚å­—æ•°ç»Ÿè®¡
4. è¿ç»­æ€§éªŒè¯
5. è¾¹ç•Œæƒ…å†µæµ‹è¯•
"""

from pathlib import Path
import json
import shutil
from src.tools.novel_chapter_detector import NovelChapterDetector
from src.tools.novel_importer import NovelImporter
from scripts.test.test_helpers import TestOutputManager
from src.core.config import config
from src.core.schemas_novel import ChapterInfo

# Configure logging
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Define test data paths
TEST_SOURCE_NOVEL_PATH = Path("åˆ†æèµ„æ–™/æœ‰åŸå°è¯´/01_æœ«å“¥è¶…å‡¡å…¬è·¯/novel/åºåˆ—å…¬è·¯æ±‚ç”Ÿï¼šæˆ‘åœ¨æœ«æ—¥å‡çº§ç‰©èµ„.txt")
TEST_PROJECT_NAME = "æœ«å“¥è¶…å‡¡å…¬è·¯_test"
TEST_PROJECT_RAW_DIR = Path("data/projects") / TEST_PROJECT_NAME / "raw"
TEST_NOVEL_PATH_IN_PROJECT = TEST_PROJECT_RAW_DIR / "novel.txt"


def setup_and_teardown_test_project():
    """
    ä¸ºæµ‹è¯•æ¨¡å—è®¾ç½®å’Œæ¸…ç†æµ‹è¯•é¡¹ç›®ç›®å½•ï¼Œå¹¶ç¡®ä¿å°è¯´æ–‡ä»¶å·²å¯¼å…¥ã€‚
    """
    # Setup: ç¡®ä¿æµ‹è¯•é¡¹ç›®ç›®å½•å¹²å‡€å¹¶å¯¼å…¥å°è¯´
    if TEST_PROJECT_RAW_DIR.exists():
        shutil.rmtree(TEST_PROJECT_RAW_DIR.parent)
    TEST_PROJECT_RAW_DIR.mkdir(parents=True, exist_ok=True)
    
    importer = NovelImporter()
    importer.execute(
        source_file=TEST_SOURCE_NOVEL_PATH,
        project_name=TEST_PROJECT_NAME,
        save_to_disk=True,
        include_content=False
    )
    logger.info(f"Test novel imported to: {TEST_NOVEL_PATH_IN_PROJECT}")

    yield  # Run tests

    # Teardown: æ¸…ç†æµ‹è¯•é¡¹ç›®ç›®å½•
    if TEST_PROJECT_RAW_DIR.exists():
        shutil.rmtree(TEST_PROJECT_RAW_DIR.parent)
        logger.info(f"Test project directory cleaned up: {TEST_PROJECT_RAW_DIR}")


def run_main_test(output_manager: TestOutputManager, detector: NovelChapterDetector):
    """
    è¿è¡Œ NovelChapterDetector çš„ä¸»è¦æµ‹è¯•é€»è¾‘ã€‚
    """
    logger.info("\n" + "="*60)
    logger.info("  ğŸ”§ NovelChapterDetector å·¥å…·æµ‹è¯•")
    logger.info("="*60 + "\n")

    logger.info("ğŸ“ åˆå§‹åŒ–å·¥å…·...")
    logger.info(f"ğŸ“– æµ‹è¯•æ–‡ä»¶: {TEST_NOVEL_PATH_IN_PROJECT.name}")
    logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {TEST_NOVEL_PATH_IN_PROJECT.stat().st_size / 1024:.1f}KB")

    logger.info("ğŸš€ æ‰§è¡Œç« èŠ‚æ£€æµ‹...")
    chapters = detector.execute(novel_file=TEST_NOVEL_PATH_IN_PROJECT)
    logger.info("âœ… æ£€æµ‹æˆåŠŸï¼")

    logger.info("ğŸ’¾ ä¿å­˜æ£€æŸ¥æ–‡ä»¶...")
    
    # ä¿å­˜å®Œæ•´ç« èŠ‚ä¿¡æ¯
    chapters_data = [ch.model_dump(mode='json') for ch in chapters]
    output_manager.save_json("chapters.json", chapters_data)
    
    # ä¿å­˜ç« èŠ‚ç´¢å¼•ï¼ˆç®€åŒ–ç‰ˆï¼‰
    chapter_index = [
        {
            "number": ch.number,
            "title": ch.title,
            "word_count": ch.word_count,
            "lines": f"{ch.start_line}-{ch.end_line}"
        }
        for ch in chapters
    ]
    output_manager.save_json("chapter_index.json", chapter_index)
    
    # ç”Ÿæˆç« èŠ‚æ‘˜è¦æ–‡æœ¬
    summary_lines = ["# ç« èŠ‚æ£€æµ‹æ‘˜è¦\n"]
    summary_lines.append(f"æ€»ç« èŠ‚æ•°: {len(chapters)}\n\n")
    summary_lines.append("## ç« èŠ‚åˆ—è¡¨\n")
    for ch in chapters:
        summary_lines.append(
            f"- ç¬¬{ch.number}ç« : {ch.title or '(æ— æ ‡é¢˜)'} "
            f"({ch.word_count}å­—, è¡Œ{ch.start_line}-{ch.end_line})\n"
        )
    output_manager.save_text("chapter_summary.txt", ''.join(summary_lines))
    
    # ç»Ÿè®¡åˆ†æ
    total_words = sum(ch.word_count or 0 for ch in chapters)
    avg_words = total_words / len(chapters) if chapters else 0
    
    analysis = {
        "total_chapters": len(chapters),
        "total_words": total_words,
        "avg_words_per_chapter": round(avg_words, 2),
        "min_words": min(ch.word_count or 0 for ch in chapters) if chapters else 0,
        "max_words": max(ch.word_count or 0 for ch in chapters) if chapters else 0,
        "first_chapter": f"ç¬¬{chapters[0].number}ç« " if chapters else None,
        "last_chapter": f"ç¬¬{chapters[-1].number}ç« " if chapters else None
    }
    output_manager.save_json("chapter_analysis.json", analysis)

    logger.info("\n" + "-"*60)
    logger.info("  ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦")
    logger.info("-"*60 + "\n")
    logger.info(f"âœ… æ£€æµ‹çŠ¶æ€: æˆåŠŸ")
    logger.info(f"ğŸ“š æ€»ç« èŠ‚æ•°: {analysis['total_chapters']}")
    logger.info(f"ğŸ“ æ€»å­—æ•°: {analysis['total_words']:,}")
    logger.info(f"ğŸ“Š å¹³å‡æ¯ç« å­—æ•°: {analysis['avg_words_per_chapter']:,.0f}")
    logger.info(f"ğŸ“‰ æœ€çŸ­ç« èŠ‚: {analysis['min_words']:,} å­—")
    logger.info(f"ğŸ“ˆ æœ€é•¿ç« èŠ‚: {analysis['max_words']:,} å­—")
    logger.info(f"ğŸ é¦–ç« : {analysis['first_chapter']}")
    logger.info(f"ğŸ”š æœ«ç« : {analysis['last_chapter']}")

    # æ˜¾ç¤ºå‰5ç« èŠ‚è¯¦æƒ…
    logger.info(f"\nğŸ“– å‰5ç« è¯¦æƒ…:")
    for ch in chapters[:5]:
        logger.info(f"   ç¬¬{ch.number}ç« : {ch.title or '(æ— æ ‡é¢˜)'}")
        logger.info(f"      å­—æ•°: {ch.word_count:,}")
        logger.info(f"      ä½ç½®: è¡Œ {ch.start_line}-{ch.end_line}, å­—ç¬¦ {ch.start_char}-{ch.end_char}")

    logger.info(f"\nğŸ“ ä¸´æ—¶è¾“å‡º: {output_manager.get_path()}")
    logger.info(f"ğŸ’¡ å¿«é€ŸæŸ¥çœ‹:")
    logger.info(f"   - ç« èŠ‚ç´¢å¼•: cat {output_manager.get_path()}/chapter_index.json")
    logger.info(f"   - ç« èŠ‚æ‘˜è¦: cat {output_manager.get_path()}/chapter_summary.txt")
    logger.info(f"   - ç»Ÿè®¡åˆ†æ: cat {output_manager.get_path()}/chapter_analysis.json")
    logger.info("\n" + "-"*60 + "\n")
    
    return chapters


def run_chapter_extraction_test(output_manager: TestOutputManager, detector: NovelChapterDetector, chapters):
    """
    æµ‹è¯•ç« èŠ‚æå–åŠŸèƒ½ï¼ˆéªŒè¯ç« èŠ‚ä½ç½®æ˜¯å¦æ­£ç¡®ï¼‰
    """
    logger.info("\n" + "="*60)
    logger.info("  ğŸ”¬ ç« èŠ‚æå–éªŒè¯æµ‹è¯•")
    logger.info("="*60 + "\n")

    # è¯»å–å®Œæ•´æ–‡æœ¬
    content = TEST_NOVEL_PATH_IN_PROJECT.read_text(encoding='utf-8')
    lines = content.split('\n')
    
    # æå–å‰3ç« éªŒè¯
    logger.info("ğŸ“– æå–å‰3ç« éªŒè¯ä½ç½®å‡†ç¡®æ€§...")
    for ch in chapters[:3]:
        logger.info(f"\nç¬¬{ch.number}ç« : {ch.title}")
        
        # æå–ç« èŠ‚å†…å®¹
        chapter_lines = lines[ch.start_line:ch.end_line]
        chapter_content = '\n'.join(chapter_lines)
        
        # ä¿å­˜ç« èŠ‚å†…å®¹
        output_manager.save_text(f"chapter_{ch.number}_content.txt", chapter_content)
        
        # éªŒè¯é¦–è¡Œæ˜¯å¦ä¸ºç« èŠ‚æ ‡é¢˜
        first_line = chapter_lines[0] if chapter_lines else ""
        logger.info(f"   é¦–è¡Œ: {first_line[:60]}...")
        logger.info(f"   å®é™…å­—æ•°: {len(chapter_content)}")
        logger.info(f"   è®°å½•å­—æ•°: {ch.word_count}")
        
        # éªŒè¯å­—ç¬¦ä½ç½®
        extracted_by_char = content[ch.start_char:ch.end_char]
        char_match = (extracted_by_char == chapter_content)
        logger.info(f"   å­—ç¬¦ä½ç½®åŒ¹é…: {'âœ…' if char_match else 'âŒ'}")

    logger.info("\nâœ… ç« èŠ‚æå–éªŒè¯å®Œæˆï¼")


def run_edge_case_tests(detector: NovelChapterDetector):
    """
    è¿è¡Œ NovelChapterDetector çš„è¾¹ç•Œæƒ…å†µæµ‹è¯•ã€‚
    """
    logger.info("\n" + "="*60)
    logger.info("  ğŸ§ª è¾¹ç•Œæƒ…å†µæµ‹è¯•")
    logger.info("="*60 + "\n")

    # Test 1: æ–‡ä»¶ä¸å­˜åœ¨
    logger.info("Test 1: æ–‡ä»¶ä¸å­˜åœ¨")
    non_existent_file = Path("nonexistent_file.txt")
    try:
        detector.execute(novel_file=non_existent_file)
        assert False, "Expected FileNotFoundError but none was raised."
    except FileNotFoundError:
        logger.info("  âœ… æ­£ç¡®æ•è·å¼‚å¸¸: FileNotFoundError")
    except Exception as e:
        assert False, f"Expected FileNotFoundError but got {type(e).__name__}: {e}"

    # Test 2: æ— ç« èŠ‚æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰
    logger.info("Test 2: æ— ç« èŠ‚æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰")
    temp_no_chapter_file = Path("temp_no_chapter.txt")
    try:
        temp_no_chapter_file.write_text("è¿™æ˜¯ä¸€ä¸ªæ²¡æœ‰ç« èŠ‚æ ‡è®°çš„æ–‡æœ¬æ–‡ä»¶ã€‚\nåªæœ‰æ™®é€šå†…å®¹ã€‚", encoding='utf-8')
        detector.execute(novel_file=temp_no_chapter_file)
        assert False, "Expected ValueError for no chapters but none was raised."
    except ValueError as e:
        assert "No chapters detected" in str(e)
        logger.info("  âœ… æ­£ç¡®æ•è·å¼‚å¸¸: ValueError (No chapters detected)")
    finally:
        if temp_no_chapter_file.exists():
            temp_no_chapter_file.unlink()

    logger.info("\n" + "-"*60 + "\n")


def main():
    logger.info("\n" + "="*60)
    logger.info("  NovelChapterDetector å·¥å…·æµ‹è¯•å¥—ä»¶")
    logger.info("="*60 + "\n")

    # Setup
    setup_and_teardown_test_project()

    output_manager = TestOutputManager("03_chapter_detector")
    detector = NovelChapterDetector()

    try:
        # è¿è¡Œä¸»è¦æµ‹è¯•
        chapters = run_main_test(output_manager, detector)

        # è¿è¡Œç« èŠ‚æå–éªŒè¯
        run_chapter_extraction_test(output_manager, detector, chapters)

        # è¿è¡Œè¾¹ç•Œæƒ…å†µæµ‹è¯•
        run_edge_case_tests(detector)

        logger.info("\nâœ… æ‰€æœ‰ NovelChapterDetector æµ‹è¯•å®Œæˆï¼")
    finally:
        # Cleanup
        if TEST_PROJECT_RAW_DIR.exists():
            shutil.rmtree(TEST_PROJECT_RAW_DIR.parent)
            logger.info(f"Test project directory cleaned up: {TEST_PROJECT_RAW_DIR}")


if __name__ == "__main__":
    main()
