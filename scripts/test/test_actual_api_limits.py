"""
å®é™…APIé™æµæµ‹è¯•å·¥å…·

ç”¨äºæµ‹è¯•çœŸå®APIçš„é™æµè§„åˆ™ï¼Œå¹¶æ›´æ–°é…ç½®ã€‚
âš ï¸ è­¦å‘Šï¼šæ­¤æµ‹è¯•ä¼šæ¶ˆè€—å®é™…APIé…é¢ï¼
"""

import asyncio
import sys
import os
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional, Callable

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.core.llm_rate_limiter import LLMCallManager, LLMRateLimitConfig


class ActualAPITester:
    """å®é™…APIé™æµæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.manager = LLMCallManager()
        self.test_results: Dict[str, Dict] = {}
    
    def create_deepseek_caller(self) -> Optional[Callable]:
        """åˆ›å»ºDeepSeek APIè°ƒç”¨å‡½æ•°"""
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            print("âš ï¸ æœªæ‰¾åˆ°DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
            return None
        
        try:
            from openai import OpenAI
            
            client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com"
            )
            
            def call_deepseek():
                response = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[
                        {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯å›å¤ï¼šä½ å¥½"}
                    ],
                    max_tokens=50,
                    temperature=0.0
                )
                return {
                    "content": response.choices[0].message.content,
                    "tokens": response.usage.total_tokens
                }
            
            return call_deepseek
        
        except ImportError:
            print("âŒ æœªå®‰è£…openaiåº“: pip install openai")
            return None
        except Exception as e:
            print(f"âŒ DeepSeekåˆå§‹åŒ–å¤±è´¥: {e}")
            return None
    
    def create_anthropic_caller(self) -> Optional[Callable]:
        """åˆ›å»ºAnthropic APIè°ƒç”¨å‡½æ•°"""
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            print("âš ï¸ æœªæ‰¾åˆ°ANTHROPIC_API_KEYç¯å¢ƒå˜é‡")
            return None
        
        try:
            from anthropic import Anthropic
            
            client = Anthropic(api_key=api_key)
            
            def call_anthropic():
                response = client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=50,
                    messages=[
                        {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯å›å¤ï¼šä½ å¥½"}
                    ]
                )
                return {
                    "content": response.content[0].text,
                    "tokens": response.usage.input_tokens + response.usage.output_tokens
                }
            
            return call_anthropic
        
        except ImportError:
            print("âŒ æœªå®‰è£…anthropicåº“: pip install anthropic")
            return None
        except Exception as e:
            print(f"âŒ Anthropicåˆå§‹åŒ–å¤±è´¥: {e}")
            return None
    
    async def test_api_limits(
        self,
        provider: str,
        model: str,
        api_caller: Callable,
        test_duration: int = 120,
        initial_delay: float = 3.0
    ) -> Dict:
        """
        æµ‹è¯•APIå®é™…é™æµè§„åˆ™
        
        Args:
            provider: æä¾›å•†åç§°
            model: æ¨¡å‹åç§°
            api_caller: APIè°ƒç”¨å‡½æ•°
            test_duration: æµ‹è¯•æ—¶é•¿ï¼ˆç§’ï¼‰
            initial_delay: åˆå§‹å»¶è¿Ÿï¼ˆç§’ï¼‰
        
        Returns:
            æµ‹è¯•ç»“æœ
        """
        print("=" * 80)
        print(f"ğŸ§ª æµ‹è¯• {provider}/{model} å®é™…APIé™æµ")
        print("=" * 80)
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        print(f"â±ï¸ æµ‹è¯•æ—¶é•¿: {test_duration}ç§’")
        print(f"âš ï¸ è­¦å‘Šï¼šæ­¤æµ‹è¯•ä¼šæ¶ˆè€—å®é™…APIé…é¢ï¼")
        print()
        
        start_time = time.time()
        success_count = 0
        rate_limit_count = 0
        error_count = 0
        
        request_times = []
        token_usage = []
        
        current_delay = initial_delay
        
        while time.time() - start_time < test_duration:
            elapsed = time.time() - start_time
            print(f"\râ³ è¿›åº¦: {elapsed:.0f}/{test_duration}s | æˆåŠŸ:{success_count} é™æµ:{rate_limit_count} é”™è¯¯:{error_count}", end="")
            
            try:
                request_time = time.time()
                
                # è°ƒç”¨å®é™…API
                result = api_caller()
                
                # è®°å½•æˆåŠŸ
                success_count += 1
                request_times.append(request_time)
                token_usage.append(result.get("tokens", 0))
                
                # é€æ¸ç¼©çŸ­å»¶è¿Ÿï¼ˆæ¢æµ‹é™æµé˜ˆå€¼ï¼‰
                current_delay = max(0.5, current_delay * 0.95)
                
            except Exception as e:
                error_msg = str(e)
                
                # åˆ¤æ–­é”™è¯¯ç±»å‹
                is_rate_limit = any(
                    code in error_msg
                    for code in ["403", "429", "rate", "limit", "quota"]
                )
                
                if is_rate_limit:
                    rate_limit_count += 1
                    # è§¦å‘é™æµåå»¶é•¿å»¶è¿Ÿ
                    current_delay = min(30.0, current_delay * 2)
                else:
                    error_count += 1
                    print(f"\nâŒ å…¶ä»–é”™è¯¯: {error_msg[:80]}")
            
            # ç­‰å¾…
            await asyncio.sleep(current_delay)
        
        print()  # æ¢è¡Œ
        
        # åˆ†æç»“æœ
        total_elapsed = time.time() - start_time
        
        # è®¡ç®—QPMï¼ˆåŸºäºæˆåŠŸè¯·æ±‚ï¼‰
        if success_count > 0:
            estimated_qpm = int(success_count / total_elapsed * 60)
        else:
            estimated_qpm = 0
        
        # è®¡ç®—TPMï¼ˆåŸºäºtokenä½¿ç”¨ï¼‰
        if token_usage:
            total_tokens = sum(token_usage)
            estimated_tpm = int(total_tokens / total_elapsed * 60)
        else:
            estimated_tpm = 0
        
        # å»ºè®®é…ç½®
        if rate_limit_count > 0:
            # è§¦å‘äº†é™æµï¼Œä½¿ç”¨ä¿å®ˆä¼°è®¡
            suggested_qpm = max(10, int(estimated_qpm * 0.7))  # ç•™30%ä½™é‡
            suggested_concurrent = 1
            notes = f"è§¦å‘{rate_limit_count}æ¬¡é™æµï¼Œå»ºè®®ä¿å®ˆé…ç½®"
        else:
            # æœªè§¦å‘é™æµï¼Œå¯ä»¥æ›´æ¿€è¿›
            suggested_qpm = estimated_qpm
            suggested_concurrent = 2
            notes = f"æœªè§¦å‘é™æµï¼Œå¯ä»¥æ›´é«˜é…ç½®"
        
        result = {
            "provider": provider,
            "model": model,
            "test_date": datetime.now().isoformat(),
            "test_duration_seconds": int(total_elapsed),
            "total_attempts": success_count + rate_limit_count + error_count,
            "successful_requests": success_count,
            "rate_limited_requests": rate_limit_count,
            "other_errors": error_count,
            "estimated_qpm": estimated_qpm,
            "estimated_tpm": estimated_tpm,
            "suggested_qpm": suggested_qpm,
            "suggested_concurrent": suggested_concurrent,
            "notes": notes
        }
        
        # è¾“å‡ºç»“æœ
        print("\n" + "=" * 80)
        print("ğŸ“Š æµ‹è¯•ç»“æœ")
        print("=" * 80)
        print(f"æµ‹è¯•æ—¶é•¿: {total_elapsed:.1f}ç§’")
        print(f"æˆåŠŸè¯·æ±‚: {success_count}")
        print(f"é™æµæ¬¡æ•°: {rate_limit_count}")
        print(f"å…¶ä»–é”™è¯¯: {error_count}")
        print(f"ä¼°ç®—QPM: {estimated_qpm}")
        print(f"ä¼°ç®—TPM: {estimated_tpm}")
        print(f"\nğŸ’¡ å»ºè®®é…ç½®:")
        print(f"  QPM: {suggested_qpm}")
        print(f"  max_concurrent: {suggested_concurrent}")
        print(f"  å¤‡æ³¨: {notes}")
        print("=" * 80)
        
        self.test_results[f"{provider}_{model}"] = result
        
        return result
    
    def save_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        import json
        
        results_file = Path("output/llm_rate_limit_test_results.json")
        results_file.parent.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½å·²æœ‰ç»“æœ
        existing_results = {}
        if results_file.exists():
            with open(results_file, 'r', encoding='utf-8') as f:
                existing_results = json.load(f)
        
        # åˆå¹¶ç»“æœ
        existing_results.update(self.test_results)
        
        # ä¿å­˜
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(existing_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    def update_configs(self):
        """æ ¹æ®æµ‹è¯•ç»“æœæ›´æ–°é…ç½®"""
        print("\nğŸ”§ æ ¹æ®æµ‹è¯•ç»“æœæ›´æ–°é…ç½®")
        
        for key, result in self.test_results.items():
            suggested_qpm = result.get("suggested_qpm")
            suggested_concurrent = result.get("suggested_concurrent", 1)
            
            if suggested_qpm:
                self.manager.update_config(
                    key,
                    requests_per_minute=suggested_qpm,
                    max_concurrent=suggested_concurrent,
                    is_tested=True,
                    last_test_date=result["test_date"],
                    test_notes=result["notes"]
                )
                print(f"âœ… æ›´æ–°{key}: QPM={suggested_qpm}, å¹¶å‘={suggested_concurrent}")
        
        print("âœ… é…ç½®æ›´æ–°å®Œæˆ")


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("=" * 80)
    print("ğŸ§ª å®é™…APIé™æµæµ‹è¯•å·¥å…·")
    print("=" * 80)
    print()
    print("âš ï¸ è­¦å‘Šï¼šæ­¤æµ‹è¯•ä¼šæ¶ˆè€—å®é™…APIé…é¢ï¼")
    print()
    print("è¯·é€‰æ‹©è¦æµ‹è¯•çš„API:")
    print("1. DeepSeek (deepseek-chat)")
    print("2. Anthropic Claude (claude-3-5-sonnet)")
    print("3. é€€å‡º")
    print()
    
    choice = input("è¯·é€‰æ‹© (1-3): ").strip()
    
    tester = ActualAPITester()
    
    if choice == "1":
        print("\nğŸ” æ£€æŸ¥DeepSeek API...")
        api_caller = tester.create_deepseek_caller()
        
        if api_caller:
            confirm = input("\nç¡®è®¤å¼€å§‹æµ‹è¯•ï¼Ÿ(y/n): ").strip().lower()
            if confirm == 'y':
                result = await tester.test_api_limits(
                    provider="deepseek",
                    model="deepseek-chat",
                    api_caller=api_caller,
                    test_duration=120,  # æµ‹è¯•2åˆ†é’Ÿ
                    initial_delay=3.0
                )
                
                # ä¿å­˜ç»“æœ
                tester.save_results()
                
                # è¯¢é—®æ˜¯å¦æ›´æ–°é…ç½®
                update = input("\næ˜¯å¦æ ¹æ®æµ‹è¯•ç»“æœæ›´æ–°é…ç½®ï¼Ÿ(y/n): ").strip().lower()
                if update == 'y':
                    tester.update_configs()
    
    elif choice == "2":
        print("\nğŸ” æ£€æŸ¥Anthropic API...")
        api_caller = tester.create_anthropic_caller()
        
        if api_caller:
            confirm = input("\nç¡®è®¤å¼€å§‹æµ‹è¯•ï¼Ÿ(y/n): ").strip().lower()
            if confirm == 'y':
                result = await tester.test_api_limits(
                    provider="anthropic",
                    model="claude-3-5-sonnet-20241022",
                    api_caller=api_caller,
                    test_duration=120,
                    initial_delay=2.0
                )
                
                tester.save_results()
                
                update = input("\næ˜¯å¦æ ¹æ®æµ‹è¯•ç»“æœæ›´æ–°é…ç½®ï¼Ÿ(y/n): ").strip().lower()
                if update == 'y':
                    tester.update_configs()
    
    elif choice == "3":
        print("ğŸ‘‹ é€€å‡º")
        return
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ“‚ æŸ¥çœ‹ç»“æœ:")
    print("  - é…ç½®æ–‡ä»¶: config/llm_configs.json")
    print("  - æµ‹è¯•ç»“æœ: output/llm_rate_limit_test_results.json")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        print("éƒ¨åˆ†ç»“æœå¯èƒ½å·²ä¿å­˜")
