#!/usr/bin/env python3
"""
ä½¿ç”¨ Claude æŒ‰ç…§ NOVEL_SEGMENTATION_METHODOLOGY.md ä¸¥æ ¼æ ¼å¼åˆ†æç¬¬ä¸€ç« 
"""

import os
import sys
import re
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
load_dotenv()


def read_methodology():
    """è¯»å–æ–¹æ³•è®ºæ–‡æ¡£"""
    methodology_path = project_root / "docs/NOVEL_SEGMENTATION_METHODOLOGY.md"
    with open(methodology_path, 'r', encoding='utf-8') as f:
        return f.read()


def read_chapter1():
    """è¯»å–ç¬¬ä¸€ç« å†…å®¹"""
    novel_path = project_root / "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯/raw/novel.txt"
    
    if not novel_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°å°è¯´æ–‡ä»¶: {novel_path}")
        return None, None
    
    with open(novel_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–ç« èŠ‚
    chapter_pattern = re.compile(r'ç¬¬(\d+|ä¸€|äºŒ|ä¸‰|å››|äº”|å…­|ä¸ƒ|å…«|ä¹|å)ç« [ï¼š:\s]*([^\n]+)')
    chapters = list(chapter_pattern.finditer(content))
    
    if len(chapters) < 1:
        print("âŒ æœªæ‰¾åˆ°ç« èŠ‚")
        return None, None
    
    # ç¬¬ä¸€ç« 
    chapter1_start = chapters[0].start()
    chapter1_end = chapters[1].start() if len(chapters) > 1 else len(content)
    chapter1_content = content[chapter1_start:chapter1_end].strip()
    chapter_title = chapters[0].group(2).strip()
    
    return chapter1_content, chapter_title


def build_methodology_prompt(chapter_content: str, chapter_title: str, methodology: str) -> str:
    """æ„å»ºä¸¥æ ¼éµå¾ªæ–¹æ³•è®ºçš„ Prompt"""
    return f"""# ä»»åŠ¡ï¼šæŒ‰ç…§ã€Šå°è¯´å™äº‹åˆ†æ®µåˆ†ææ–¹æ³•è®ºã€‹åˆ†æå°è¯´ç« èŠ‚

## æ–¹æ³•è®ºæ–‡æ¡£

{methodology}

---

## åˆ†æä»»åŠ¡

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ–¹æ³•è®ºï¼Œå¯¹ä»¥ä¸‹ç« èŠ‚è¿›è¡Œå®Œæ•´çš„åŠŸèƒ½æ®µåˆ†æã€‚

**ç« èŠ‚ä¿¡æ¯**ï¼š
- å°è¯´ï¼šæœ«å“¥è¶…å‡¡å…¬è·¯
- ç« èŠ‚ï¼šç¬¬1ç«  {chapter_title}
- å­—æ•°ï¼š{len(chapter_content)} å­—

**è¾“å‡ºè¦æ±‚**ï¼š
1. ä¸¥æ ¼ä½¿ç”¨æ–¹æ³•è®ºå®šä¹‰çš„å…­ä¸ªç»´åº¦æ ‡ç­¾ï¼š
   - [å™äº‹åŠŸèƒ½]
   - [å™äº‹ç»“æ„]
   - [è§’è‰²ä¸å…³ç³»]
   - [æµ“ç¼©ä¼˜å…ˆçº§]
   - [æµ“ç¼©å»ºè®®]
   - [æ—¶ç©º]

2. ä½¿ç”¨æ–¹æ³•è®ºå®šä¹‰çš„æ ‡ç­¾æ ¼å¼ï¼š
   - åˆ—è¡¨å½¢å¼ï¼Œä¸è¦ç”¨ | åˆ†éš”
   - ä¿ç•™ [é¦–æ¬¡ä¿¡æ¯] æ ‡æ³¨
   - ä¿ç•™ [é‡å¤å¼ºè°ƒxæ¬¡] æ ‡æ³¨
   - ä¿ç•™å­æ ‡ç­¾æ ¼å¼ï¼ˆå¦‚ `[äººç‰©ç™»åœºï¼šè§’è‰²å]`ï¼‰

3. è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
```markdown
## æ®µè½1ï¼š[æ®µè½æ ‡é¢˜]

```
[åŸæ–‡å†…å®¹]
```

**[å™äº‹åŠŸèƒ½]**
- æ•…äº‹æ¨è¿›
- æ ¸å¿ƒæ•…äº‹è®¾å®šï¼ˆé¦–æ¬¡ï¼‰
- å…³é”®ä¿¡æ¯

**[å™äº‹ç»“æ„]**
- é’©å­-æ‚¬å¿µåˆ¶é€ 
- ä¼ç¬”
- é‡å¤å¼ºè°ƒx3ï¼š"ä¸è¦æ‰é˜Ÿ"

**[è§’è‰²ä¸å…³ç³»]**
- äººç‰©ç™»åœºï¼šé™ˆé‡
- äººç‰©å¡‘é€ ï¼šä¸»è§’ - æœæ–­åŠ¡å®

**[æµ“ç¼©ä¼˜å…ˆçº§]**
- P0-éª¨æ¶ï¼š[å†…å®¹]
- P1-è¡€è‚‰ï¼š[å†…å®¹]
- P2-çš®è‚¤ï¼š[å†…å®¹]
- é¦–æ¬¡ä¿¡æ¯ï¼š[æ ‡æ³¨]

**[æµ“ç¼©å»ºè®®]**
ä¿ç•™ï¼š[æ ¸å¿ƒå†…å®¹æ¦‚æ‹¬]
åˆ é™¤ï¼š[å¯åˆ å‡çš„ç»†èŠ‚]

**[æ—¶ç©º]**
- åœ°ç‚¹ï¼š[åœ°ç‚¹]
- æ—¶é—´ï¼š[æ—¶é—´]
```

4. åœ¨æ‰€æœ‰åŠŸèƒ½æ®µåˆ†æåï¼Œæ·»åŠ ç« èŠ‚æ•´ä½“åˆ†æï¼š
   - æ ¸å¿ƒåŠŸèƒ½ç»Ÿè®¡ï¼ˆè¡¨æ ¼ï¼‰
   - ä¼˜å…ˆçº§åˆ†å¸ƒ
   - æ—¶ç©ºè½¨è¿¹
   - æƒ…ç»ªæ›²çº¿
   - ç»“æ„ç‰¹ç‚¹
   - æµ“ç¼©å»ºè®®ï¼ˆ500å­—ç‰ˆæœ¬ï¼‰

---

## ç« èŠ‚åŸæ–‡

{chapter_content}

---

**è¯·ä¸¥æ ¼æŒ‰ç…§æ–¹æ³•è®ºæ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚**
"""


def analyze_with_claude(chapter_content: str, chapter_title: str, methodology: str):
    """ä½¿ç”¨ Claude åˆ†æç« èŠ‚"""
    print("\n" + "="*80)
    print("ğŸ¤– Claude - ä¸¥æ ¼æ–¹æ³•è®ºæ ¼å¼åˆ†æ")
    print("="*80)
    
    # æ£€æŸ¥é…ç½®
    api_key = os.getenv("CLAUDE_API_KEY")
    base_url = os.getenv("CLAUDE_BASE_URL", "https://chatapi.onechats.ai/v1/")
    model = os.getenv("CLAUDE_MODEL_NAME", "claude-sonnet-4-5-20250929")
    max_tokens = int(os.getenv("CLAUDE_MAX_TOKENS", "8000"))
    
    if not api_key:
        print("âŒ é”™è¯¯: CLAUDE_API_KEY æœªè®¾ç½®")
        return None
    
    print(f"\nğŸ“‹ é…ç½®:")
    print(f"   Model: {model}")
    print(f"   Max Tokens: {max_tokens}")
    print(f"   Chapter: ç¬¬1ç«  {chapter_title}")
    print(f"   å­—æ•°: {len(chapter_content)}")
    
    # æ„å»º prompt
    prompt = build_methodology_prompt(chapter_content, chapter_title, methodology)
    
    print(f"\nğŸ§  å¼€å§‹åˆ†æ...")
    print(f"   Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(f"   é¢„è®¡è¾“å…¥ tokens: ~{len(prompt)//4}")
    
    try:
        # è°ƒç”¨ Claude
        client = OpenAI(api_key=api_key, base_url=base_url)
        
        start_time = datetime.now()
        
        response = client.chat.completions.create(
            model=model,
            max_tokens=max_tokens,
            messages=[{
                "role": "user",
                "content": prompt
            }]
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        result = response.choices[0].message.content
        
        # ç»Ÿè®¡
        input_tokens = response.usage.prompt_tokens
        output_tokens = response.usage.completion_tokens
        total_tokens = response.usage.total_tokens
        
        print(f"\nâœ… åˆ†æå®Œæˆ!")
        print(f"   è€—æ—¶: {duration:.2f} ç§’")
        print(f"   è¾“å…¥ tokens: {input_tokens}")
        print(f"   è¾“å‡º tokens: {output_tokens}")
        print(f"   æ€»è®¡ tokens: {total_tokens}")
        print(f"   è¾“å‡ºé•¿åº¦: {len(result)} å­—ç¬¦")
        print(f"   ç”Ÿæˆé€Ÿåº¦: {output_tokens/duration:.1f} tokens/ç§’")
        
        # è´¹ç”¨ä¼°ç®—
        input_cost = (input_tokens / 1_000_000) * 3
        output_cost = (output_tokens / 1_000_000) * 15
        total_cost = input_cost + output_cost
        
        print(f"\nğŸ’° è´¹ç”¨:")
        print(f"   æœ¬æ¬¡: ${total_cost:.4f} (â‰ˆ Â¥{total_cost*7.2:.2f})")
        print(f"   é¢„è®¡10ç« : ${total_cost*10:.2f} (â‰ˆ Â¥{total_cost*10*7.2:.1f})")
        
        return result
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def save_result(result: str, chapter_title: str):
    """ä¿å­˜åˆ†æç»“æœ"""
    output_dir = project_root / "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯/novel"
    output_dir.mkdir(exist_ok=True, parents=True)
    
    output_path = output_dir / f"ç¬¬1ç« å®Œæ•´åˆ†æ®µåˆ†æ_Claude_æ–¹æ³•è®ºæ ¼å¼.md"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(result)
    
    print(f"\nğŸ’¾ å·²ä¿å­˜:")
    print(f"   {output_path}")
    print(f"   å¤§å°: {len(result)} å­—ç¬¦")


def main():
    print("\n" + "="*80)
    print("ğŸš€ Claude - ä¸¥æ ¼æŒ‰ç…§ NOVEL_SEGMENTATION_METHODOLOGY.md åˆ†æ")
    print("="*80)
    
    # 1. è¯»å–æ–¹æ³•è®º
    print("\nğŸ“– è¯»å–æ–¹æ³•è®º...")
    methodology = read_methodology()
    print(f"   âœ… æ–¹æ³•è®ºæ–‡æ¡£: {len(methodology)} å­—ç¬¦")
    
    # 2. è¯»å–ç« èŠ‚
    print("\nğŸ“– è¯»å–ç¬¬ä¸€ç« ...")
    chapter_content, chapter_title = read_chapter1()
    
    if not chapter_content:
        return
    
    print(f"   âœ… ç¬¬1ç« : {chapter_title}")
    print(f"   å­—æ•°: {len(chapter_content)}")
    
    # 3. åˆ†æ
    result = analyze_with_claude(chapter_content, chapter_title, methodology)
    
    if not result:
        return
    
    # 4. ä¿å­˜
    save_result(result, chapter_title)
    
    print("\n" + "="*80)
    print("âœ… å®Œæˆï¼")
    print("="*80)
    print("\nğŸ“ ä¸‹ä¸€æ­¥ï¼š")
    print("   1. å¯¹æ¯”åˆ†æç»“æœä¸æ‰‹å·¥åˆ†æ")
    print("   2. éªŒè¯æ˜¯å¦ä¸¥æ ¼éµå¾ªæ–¹æ³•è®ºæ ¼å¼")
    print("   3. å¦‚æœæ ¼å¼æ­£ç¡®ï¼Œå¯ç”¨äºæ‰¹é‡åˆ†æ2-10ç« ")


if __name__ == "__main__":
    main()
