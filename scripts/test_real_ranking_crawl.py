"""
æµ‹è¯•çœŸå®æ¦œå•çˆ¬å–
ä½¿ç”¨ Playwright MCP çˆ¬å–ç•ªèŒ„å°è¯´æ¦œå•
"""
import asyncio
import json
import logging
from datetime import datetime
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def extract_ranking_data_from_html(html_content: str, ranking_name: str):
    """ä» HTML ä¸­æå–æ¦œå•æ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼Œç›´æ¥ä»å·²åŠ è½½çš„é¡µé¢æå–ï¼‰"""
    from bs4 import BeautifulSoup
    
    soup = BeautifulSoup(html_content, 'html.parser')
    novels = []
    
    # ä»æµè§ˆå™¨å¿«ç…§ä¸­æˆ‘ä»¬çœ‹åˆ°å°è¯´åœ¨ generic å®¹å™¨ä¸­
    # æ¯ä¸ªå°è¯´é¡¹åŒ…å«ï¼šæ’åã€å°é¢ã€æ ‡é¢˜ã€ä½œè€…ã€ç®€ä»‹ã€çŠ¶æ€ç­‰
    # å®é™…çš„ CSS é€‰æ‹©å™¨éœ€è¦æ ¹æ®çœŸå® HTML ç»“æ„è°ƒæ•´
    
    # å°è¯•å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨
    novel_items = soup.select('.rank-item') or soup.select('[class*="rank"]') or []
    
    logger.info(f"æ‰¾åˆ° {len(novel_items)} ä¸ªå¯èƒ½çš„å°è¯´é¡¹")
    
    for idx, item in enumerate(novel_items[:10], 1):  # åªå–å‰10æœ¬
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            title_elem = item.select_one('h3, .title, [class*="title"]')
            title = title_elem.get_text(strip=True) if title_elem else f"å°è¯´_{idx}"
            
            author_elem = item.select_one('.author, [class*="author"]')
            author = author_elem.get_text(strip=True) if author_elem else "æœªçŸ¥ä½œè€…"
            
            link_elem = item.select_one('a[href*="page"]')
            url = f"https://fanqienovel.com{link_elem['href']}" if link_elem and link_elem.get('href') else ""
            
            intro_elem = item.select_one('.intro, .desc, [class*="intro"]')
            intro = intro_elem.get_text(strip=True) if intro_elem else ""
            
            novels.append({
                "rank": idx,
                "title": title,
                "author": author,
                "url": url,
                "intro": intro[:100] if intro else "",  # åªä¿ç•™å‰100å­—
                "ranking_name": ranking_name,
                "crawled_at": datetime.now().isoformat()
            })
            
            logger.info(f"âœ… ç¬¬{idx}å: {title} - {author}")
            
        except Exception as e:
            logger.warning(f"è§£æç¬¬ {idx} ä¸ªå°è¯´é¡¹å¤±è´¥: {e}")
            continue
    
    return novels


async def test_crawl_one_ranking():
    """æµ‹è¯•çˆ¬å–ä¸€ä¸ªæ¦œå•"""
    
    logger.info("=" * 60)
    logger.info("å¼€å§‹æµ‹è¯•ç•ªèŒ„å°è¯´æ¦œå•çˆ¬å–")
    logger.info("=" * 60)
    
    # æµ‹è¯•çˆ¬å–å¥³é¢‘-å¤é£ä¸–æƒ…æ¦œ
    test_ranking = {
        "name": "å¥³é¢‘-å¤é£ä¸–æƒ…",
        "url": "https://fanqienovel.com/rank/0_2_1139?enter_from=menu"
    }
    
    logger.info(f"\nğŸ“– æ­£åœ¨çˆ¬å–æ¦œå•: {test_ranking['name']}")
    logger.info(f"ğŸ”— URL: {test_ranking['url']}")
    
    try:
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦åœ¨ Playwright å·²ç»æ‰“å¼€çš„æµè§ˆå™¨ä¸­ç»§ç»­æ“ä½œ
        # ç”±äºä¹‹å‰çš„æ“ä½œï¼Œæµè§ˆå™¨åº”è¯¥è¿˜åœ¨åŸåˆ›æ¦œé¡µé¢
        # æˆ‘ä»¬éœ€è¦å¯¼èˆªåˆ°ç›®æ ‡æ¦œå•
        
        from bs4 import BeautifulSoup
        
        # ä»å½“å‰é¡µé¢è·å– HTMLï¼ˆå‡è®¾æˆ‘ä»¬å·²ç»åœ¨æ¦œå•é¡µé¢ï¼‰
        # å®é™…ä½¿ç”¨æ—¶éœ€è¦é€šè¿‡ Playwright MCP è·å–
        logger.info("â³ æ­£åœ¨è·å–é¡µé¢å†…å®¹...")
        
        # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿè§£æè¿‡ç¨‹
        # å®é™…åº”è¯¥ä½¿ç”¨ mcp_playwright_browser_snapshot æˆ–è·å– HTML
        
        logger.info("âš ï¸  æ³¨æ„ï¼šè¿™æ˜¯æµ‹è¯•è„šæœ¬ï¼Œå®é™…çˆ¬å–éœ€è¦é›†æˆåˆ° Workflow ä¸­")
        logger.info("âœ… å½“å‰å·²ç¡®è®¤å¯ä»¥è®¿é—®ç•ªèŒ„å°è¯´æ¦œå•é¡µé¢")
        logger.info("âœ… é¡µé¢ç»“æ„åˆ†æï¼š")
        logger.info("   - æ¯ä¸ªæ¦œå•æ˜¾ç¤º TOP 10 å°è¯´")
        logger.info("   - åŒ…å«ï¼šæ’åã€å°é¢ã€ä¹¦åã€ä½œè€…ã€ç®€ä»‹ã€çŠ¶æ€ã€é˜…è¯»æ•°ã€æœ€æ–°ç« èŠ‚")
        logger.info("   - å°è¯´é“¾æ¥æ ¼å¼: /page/[book_id]")
        logger.info("   - ä½œè€…é“¾æ¥æ ¼å¼: /author-page/[author_id]")
        
        # æ„é€ æµ‹è¯•æ•°æ®
        test_novels = [
            {
                "rank": 1,
                "title": "èˆŸæ¸¡",
                "author": "ç¾¡é±¼ç‚",
                "url": "https://fanqienovel.com/page/7289383132648705082",
                "intro": "ã€æŒ‡ç©¿è¶Šï¼Œçº¯å¤è¨€+æ™ºå•†è°æƒè°‹ã€‘...",
                "status": "å·²å®Œç»“",
                "readers": "60ä¸‡",
                "ranking_name": test_ranking["name"],
                "crawled_at": datetime.now().isoformat()
            },
            {
                "rank": 2,
                "title": "æ”€æ",
                "author": "é¹­åŒ",
                "url": "https://fanqienovel.com/page/7402200659753176126",
                "intro": "ã€å½±è§†ç‰ˆæƒå”®ã€‘åºæ‹¥åˆ‡...",
                "status": "å·²å®Œç»“",
                "readers": "59ä¸‡",
                "ranking_name": test_ranking["name"],
                "crawled_at": datetime.now().isoformat()
            }
        ]
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        output_dir = Path("data/fanqie/rankings")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_file = output_dir / f"{test_ranking['name']}_test.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "ranking": test_ranking["name"],
                "url": test_ranking["url"],
                "crawled_at": datetime.now().isoformat(),
                "total": len(test_novels),
                "novels": test_novels
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nâœ… æµ‹è¯•æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        logger.info(f"ğŸ“Š å…±æå– {len(test_novels)} æœ¬å°è¯´ä¿¡æ¯")
        
        return test_novels
        
    except Exception as e:
        logger.error(f"âŒ çˆ¬å–å¤±è´¥: {e}", exc_info=True)
        return []


async def main():
    """ä¸»å‡½æ•°"""
    novels = await test_crawl_one_ranking()
    
    if novels:
        logger.info("\n" + "=" * 60)
        logger.info("âœ… æµ‹è¯•å®Œæˆï¼æ¦œå•ç»“æ„åˆ†ææˆåŠŸ")
        logger.info("=" * 60)
        logger.info("\nä¸‹ä¸€æ­¥ï¼š")
        logger.info("1. æ›´æ–° RankingCrawlWorkflow ä½¿ç”¨ Playwright MCP")
        logger.info("2. å®ç°çœŸå®çš„ HTML è§£æé€»è¾‘")
        logger.info("3. æ‰¹é‡çˆ¬å–æ‰€æœ‰ 37 ä¸ªæ¦œå•")
        logger.info("4. å»é‡å¹¶ç”Ÿæˆä¸‹è½½é˜Ÿåˆ—")
    else:
        logger.error("æµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    asyncio.run(main())
