#!/usr/bin/env python3
"""
ä½¿ç”¨ Claude Sonnet 4.5 Thinking åˆ†æç¬¬ä¸€ç« 
"""

import sys
from pathlib import Path
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.config import config
from src.tools.novel_chapter_analyzer import NovelChapterAnalyzer
from src.core.artifact_manager import ArtifactManager

def main():
    print("\n" + "="*80)
    print("ğŸ¤– ä½¿ç”¨ Claude Sonnet 4.5 Thinking åˆ†æç¬¬ä¸€ç« ")
    print("="*80)
    
    # 1. æ£€æŸ¥é…ç½®
    print(f"\nğŸ“‹ å½“å‰é…ç½®:")
    print(f"   LLM Provider: {config.llm.provider}")
    print(f"   Model: {config.llm.model_name}")
    print(f"   Base URL: {config.llm.base_url}")
    
    if config.llm.provider != "claude":
        print(f"\nâŒ é”™è¯¯: å½“å‰ LLM_PROVIDER = '{config.llm.provider}'")
        print(f"   è¯·åœ¨ .env ä¸­è®¾ç½®: LLM_PROVIDER=claude")
        print(f"\nğŸ’¡ æç¤º:")
        print(f"   1. æ‰“å¼€ .env æ–‡ä»¶")
        print(f"   2. æ·»åŠ æˆ–ä¿®æ”¹: LLM_PROVIDER=claude")
        print(f"   3. ç¡®ä¿ CLAUDE_API_KEY å·²é…ç½®")
        print(f"   4. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        return
    
    # 2. è¯»å–ç¬¬ä¸€ç« å†…å®¹
    novel_dir = project_root / "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯"
    raw_novel_path = novel_dir / "raw/novel.txt"
    
    if not raw_novel_path.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å°è¯´æ–‡ä»¶: {raw_novel_path}")
        return
    
    print(f"\nğŸ“– è¯»å–å°è¯´...")
    with open(raw_novel_path, 'r', encoding='utf-8') as f:
        raw_content = f.read()
    
    # æå–ç¬¬ä¸€ç« ï¼ˆç®€å•ç‰ˆæœ¬ï¼Œå‡è®¾ç« èŠ‚æ ¼å¼ä¸º "ç¬¬Xç« "ï¼‰
    import re
    chapter_pattern = re.compile(r'ç¬¬(\d+|ä¸€|äºŒ|ä¸‰|å››|äº”|å…­|ä¸ƒ|å…«|ä¹|å)ç« [ï¼š:\s]*([^\n]+)')
    chapters = list(chapter_pattern.finditer(raw_content))
    
    if len(chapters) < 1:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°ç« èŠ‚")
        return
    
    # ç¬¬ä¸€ç« å†…å®¹
    chapter1_start = chapters[0].start()
    chapter1_end = chapters[1].start() if len(chapters) > 1 else len(raw_content)
    chapter1_content = raw_content[chapter1_start:chapter1_end].strip()
    
    # æå–æ ‡é¢˜
    chapter1_match = chapters[0]
    chapter_title = chapter1_match.group(2).strip()
    
    print(f"   âœ… ç¬¬1ç« : {chapter_title}")
    print(f"   å­—æ•°: {len(chapter1_content)}")
    
    # 3. ä½¿ç”¨ Claude åˆ†æ
    print(f"\nğŸ§  å¼€å§‹ Claude åˆ†æ...")
    print(f"   æ¨¡å‹: {config.llm.model_name}")
    print(f"   æ¸©åº¦: {config.llm.claude_temperature}")
    print(f"   æœ€å¤§ tokens: {config.llm.claude_max_tokens}")
    
    analyzer = NovelChapterAnalyzer()
    
    start_time = datetime.now()
    
    try:
        analysis_result = analyzer.execute(
            chapter_content=chapter1_content,
            chapter_number=1,
            chapter_title=chapter_title,
            novel_title="æœ«å“¥è¶…å‡¡å…¬è·¯"
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        print(f"   è€—æ—¶: {duration:.2f} ç§’")
        print(f"   åŠŸèƒ½æ®µæ•°é‡: {len(analysis_result.segments)}")
        print(f"   æ€»å­—æ•°: {analysis_result.metadata.total_word_count}")
        
        # 4. ä¿å­˜ç»“æœ
        output_dir = novel_dir / "novel"
        analysis_dir = novel_dir / "novel/functional_analysis"
        output_dir.mkdir(exist_ok=True, parents=True)
        analysis_dir.mkdir(exist_ok=True, parents=True)
        
        # ä¿å­˜ JSONï¼ˆversionedï¼‰
        print(f"\nğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
        artifact_type = "chpt_0001_functional_analysis_claude"
        ArtifactManager.save_artifact(
            content=analysis_result,
            artifact_type=artifact_type,
            project_id="æœ«å“¥è¶…å‡¡å…¬è·¯",
            base_dir=str(analysis_dir),
            extension="json"
        )
        print(f"   âœ… JSON: {artifact_type}_latest.json")
        
        # ä¿å­˜ Markdown
        md_output_path = output_dir / "ç¬¬1ç« å®Œæ•´åˆ†æ®µåˆ†æ_Claude.md"
        analyzer.save_markdown(analysis_result, md_output_path)
        print(f"   âœ… Markdown: {md_output_path.name}")
        
        # 5. æ˜¾ç¤ºæ¦‚è§ˆ
        print(f"\n" + "="*80)
        print(f"ğŸ“Š åˆ†ææ¦‚è§ˆ")
        print(f"="*80)
        
        print(f"\nç« èŠ‚ä¿¡æ¯:")
        print(f"  æ ‡é¢˜: {analysis_result.chapter_title}")
        print(f"  åŠŸèƒ½æ®µæ•°: {len(analysis_result.segments)}")
        print(f"  æ€»å­—æ•°: {analysis_result.metadata.total_word_count}")
        
        print(f"\nå‰3ä¸ªåŠŸèƒ½æ®µ:")
        for i, segment in enumerate(analysis_result.segments[:3], 1):
            print(f"\n  æ®µè½{i}: {segment.title}")
            print(f"    å­—æ•°: {segment.metadata.word_count}")
            print(f"    å™äº‹åŠŸèƒ½: {', '.join(segment.tags.narrative_function)}")
            print(f"    ä¼˜å…ˆçº§: {segment.tags.condensation_priority}")
        
        if len(analysis_result.segments) > 3:
            print(f"\n  ... è¿˜æœ‰ {len(analysis_result.segments) - 3} ä¸ªåŠŸèƒ½æ®µ")
        
        print(f"\nç« èŠ‚æ‘˜è¦:")
        print(f"  {analysis_result.chapter_summary.brief_summary}")
        
        print(f"\n" + "="*80)
        print(f"âœ… å®Œæˆï¼è¯·æŸ¥çœ‹ Markdown æ–‡ä»¶ä»¥è·å–å®Œæ•´åˆ†æ")
        print(f"="*80)
        
        # 6. è´¹ç”¨ä¼°ç®—ï¼ˆç²—ç•¥ï¼‰
        input_tokens = len(chapter1_content) // 4 + 1000  # å†…å®¹ + prompt
        output_tokens = len(str(analysis_result.model_dump_json())) // 4
        
        input_cost = (input_tokens / 1_000_000) * 3
        output_cost = (output_tokens / 1_000_000) * 15
        total_cost_usd = input_cost + output_cost
        total_cost_cny = total_cost_usd * 7.2
        
        print(f"\nğŸ’° è´¹ç”¨ä¼°ç®—:")
        print(f"   è¾“å…¥ tokens: ~{input_tokens}")
        print(f"   è¾“å‡º tokens: ~{output_tokens}")
        print(f"   æœ¬æ¬¡è´¹ç”¨: ~${total_cost_usd:.4f} (â‰ˆ Â¥{total_cost_cny:.2f})")
        print(f"   é¢„è®¡10ç« æ€»è´¹ç”¨: ~${total_cost_usd*10:.2f} (â‰ˆ Â¥{total_cost_cny*10:.1f})")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
