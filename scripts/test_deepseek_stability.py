"""
æµ‹è¯• DeepSeek ç¨³å®šæ€§ - è¿ç»­è¿è¡Œ3æ¬¡å¹¶è®°å½•ç»“æœ
"""

import sys
import shutil
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.tools.novel_chapter_analyzer import NovelChapterAnalyzer


def extract_chapter_content(novel_file: Path, chapter_num: int):
    """æå–æŒ‡å®šç« èŠ‚å†…å®¹"""
    with open(novel_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    import re
    chapter_pattern = r'===\s*ç¬¬\s*(\d+)\s*ç« \s*(.*)===\s*\n'
    matches = list(re.finditer(chapter_pattern, content))
    
    if len(matches) < chapter_num:
        return None, None
    
    start_match = matches[chapter_num - 1]
    chapter_number = int(start_match.group(1))
    chapter_title = start_match.group(2).strip()
    
    start_pos = start_match.end()
    end_pos = matches[chapter_num].start() if len(matches) > chapter_num else len(content)
    chapter_content = content[start_pos:end_pos].strip()
    
    return chapter_title, chapter_content


def run_single_test(run_num: int, output_dir: Path):
    """è¿è¡Œå•æ¬¡æµ‹è¯•"""
    print(f"\n{'='*80}")
    print(f"  ç¬¬ {run_num} æ¬¡è¿è¡Œ")
    print(f"{'='*80}\n")
    
    # è¯»å–åŸå§‹å°è¯´æ–‡ä»¶
    project_dir = Path(__file__).parent.parent / "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯"
    novel_file = project_dir / "raw/novel.txt"
    
    chapter_title, chapter_content = extract_chapter_content(novel_file, 1)
    
    if not chapter_content:
        print("âŒ æ— æ³•æå–ç« èŠ‚å†…å®¹")
        return None
    
    print(f"ğŸ“– ç« èŠ‚: ç¬¬1ç«  - {chapter_title}")
    print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(chapter_content)} å­—ç¬¦\n")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = NovelChapterAnalyzer()
    
    print("ğŸ”„ æ­£åœ¨è°ƒç”¨ DeepSeek è¿›è¡Œåˆ†æ...\n")
    
    try:
        # æ‰§è¡Œåˆ†æ
        result = analyzer.execute(
            chapter_content=chapter_content,
            chapter_number=1,
            chapter_title=chapter_title,
            novel_title="åºåˆ—å…¬è·¯æ±‚ç”Ÿï¼šæˆ‘åœ¨æœ«æ—¥å‡çº§ç‰©èµ„"
        )
        
        # ä¿å­˜Markdown
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        md_file = output_dir / f"run_{run_num}_{timestamp}.md"
        analyzer.save_markdown(result, md_file)
        
        # æå–æ®µè½1ä¿¡æ¯
        segment_1 = result.segments[0] if result.segments else None
        
        if segment_1:
            print(f"âœ… åˆ†æå®Œæˆï¼")
            print(f"ğŸ“Š åŠŸèƒ½æ®µæ€»æ•°: {result.chapter_summary.total_segments}")
            print(f"\nã€æ®µè½1ã€‘")
            print(f"  æ ‡é¢˜: {segment_1.title}")
            print(f"  å­—æ•°: {segment_1.metadata.word_count}")
            print(f"  å†…å®¹é¢„è§ˆ: {segment_1.content[:100]}...")
            print(f"  ä¼˜å…ˆçº§: {segment_1.tags.priority}")
            print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {md_file}")
            
            return {
                "run_num": run_num,
                "timestamp": timestamp,
                "file": md_file,
                "segment_1_title": segment_1.title,
                "segment_1_word_count": segment_1.metadata.word_count,
                "segment_1_content_preview": segment_1.content[:200],
                "total_segments": result.chapter_summary.total_segments,
                "p0_count": result.chapter_summary.p0_count,
                "p1_count": result.chapter_summary.p1_count,
                "p2_count": result.chapter_summary.p2_count
            }
        else:
            print("âŒ æ²¡æœ‰æ®µè½ç»“æœ")
            return None
            
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "ğŸ”¬" * 40)
    print("  DeepSeek ç¨³å®šæ€§æµ‹è¯• - è¿ç»­è¿è¡Œ3æ¬¡")
    print("ğŸ”¬" * 40)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent.parent / "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯/novel/functional_analysis/stability_test"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¿è¡Œ3æ¬¡æµ‹è¯•
    results = []
    for i in range(1, 4):
        result = run_single_test(i, output_dir)
        if result:
            results.append(result)
        
        if i < 3:
            print(f"\nâ³ ç­‰å¾…5ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡æµ‹è¯•...\n")
            import time
            time.sleep(5)
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "="*80)
    print("  ğŸ“Š å¯¹æ¯”æŠ¥å‘Š")
    print("="*80)
    
    if len(results) == 3:
        print(f"\nâœ… æˆåŠŸå®Œæˆ3æ¬¡æµ‹è¯•\n")
        
        # å¯¹æ¯”æ®µè½1
        print("### æ®µè½1å¯¹æ¯”\n")
        for r in results:
            print(f"**ç¬¬{r['run_num']}æ¬¡è¿è¡Œ** ({r['timestamp']}):")
            print(f"  - æ ‡é¢˜: {r['segment_1_title']}")
            print(f"  - å­—æ•°: {r['segment_1_word_count']}")
            print(f"  - å†…å®¹: {r['segment_1_content_preview']}...")
            print()
        
        # å¯¹æ¯”æ€»ä½“ç»Ÿè®¡
        print("### æ€»ä½“ç»Ÿè®¡å¯¹æ¯”\n")
        print("| è¿è¡Œæ¬¡æ•° | åŠŸèƒ½æ®µæ€»æ•° | P0 | P1 | P2 |")
        print("|---------|----------|----|----|----| ")
        for r in results:
            print(f"| ç¬¬{r['run_num']}æ¬¡ | {r['total_segments']} | {r['p0_count']} | {r['p1_count']} | {r['p2_count']} |")
        
        # åˆ¤æ–­ä¸€è‡´æ€§
        titles = [r['segment_1_title'] for r in results]
        word_counts = [r['segment_1_word_count'] for r in results]
        
        print(f"\n### ä¸€è‡´æ€§åˆ†æ\n")
        if len(set(titles)) == 1:
            print("âœ… **æ®µè½1æ ‡é¢˜å®Œå…¨ä¸€è‡´**")
        else:
            print("âš ï¸ **æ®µè½1æ ‡é¢˜ä¸ä¸€è‡´ï¼š**")
            for t in set(titles):
                count = titles.count(t)
                print(f"  - '{t}': {count}æ¬¡")
        
        if len(set(word_counts)) == 1:
            print("âœ… **æ®µè½1å­—æ•°å®Œå…¨ä¸€è‡´**")
        else:
            print("âš ï¸ **æ®µè½1å­—æ•°ä¸ä¸€è‡´ï¼š**")
            for w in set(word_counts):
                count = word_counts.count(w)
                print(f"  - {w}å­—: {count}æ¬¡")
        
        # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
        report_file = output_dir / f"stability_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# DeepSeek ç¨³å®šæ€§æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            f.write("## æ®µè½1å¯¹æ¯”\n\n")
            for r in results:
                f.write(f"### ç¬¬{r['run_num']}æ¬¡è¿è¡Œ ({r['timestamp']})\n\n")
                f.write(f"- **æ ‡é¢˜**: {r['segment_1_title']}\n")
                f.write(f"- **å­—æ•°**: {r['segment_1_word_count']}\n")
                f.write(f"- **å†…å®¹é¢„è§ˆ**: {r['segment_1_content_preview']}...\n")
                f.write(f"- **æ–‡ä»¶**: {r['file'].name}\n\n")
            
            f.write("## æ€»ä½“ç»Ÿè®¡\n\n")
            f.write("| è¿è¡Œæ¬¡æ•° | åŠŸèƒ½æ®µæ€»æ•° | P0 | P1 | P2 |\n")
            f.write("|---------|----------|----|----|----|\n")
            for r in results:
                f.write(f"| ç¬¬{r['run_num']}æ¬¡ | {r['total_segments']} | {r['p0_count']} | {r['p1_count']} | {r['p2_count']} |\n")
            
            f.write("\n## ç»“è®º\n\n")
            if len(set(titles)) == 1 and len(set(word_counts)) == 1:
                f.write("âœ… **ç»“æœå®Œå…¨ä¸€è‡´** - DeepSeekåœ¨æ­¤æ¬¡æµ‹è¯•ä¸­è¡¨ç°ç¨³å®š\n")
            else:
                f.write("âš ï¸ **ç»“æœä¸ä¸€è‡´** - DeepSeekå­˜åœ¨éšæœºæ€§ï¼Œä¸é€‚åˆç”¨äºç”Ÿäº§ç¯å¢ƒ\n")
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
    else:
        print(f"\nâš ï¸ åªå®Œæˆäº†{len(results)}æ¬¡æµ‹è¯•")
    
    print("\n" + "="*80)


if __name__ == "__main__":
    main()
