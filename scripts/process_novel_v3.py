"""
Novel å¤„ç†è„šæœ¬ V3 - é‡æ–°è®¾è®¡çš„å¤„ç†æµç¨‹

æ–°æµç¨‹:
1. æ‹†åˆ†ç®€ä»‹ (chpt_0000.md â†’ chpt_0000_ç®€ä»‹.md)
2. æ‹†åˆ†ç« èŠ‚ (raw/novel.txt â†’ chpt_XXXX.md å•ç« )
3. åŠŸèƒ½åˆ†æ (ä½¿ç”¨ R1/V3 â†’ chpt_XXXX_functional_analysis.json)
4. ç‰ˆæœ¬ç®¡ç† (_latest.json æŒ‡é’ˆ + æ—¶é—´æˆ³ç‰ˆæœ¬)
"""

import sys
import re
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.tools.novel_chapter_analyzer import NovelChapterAnalyzer


def extract_introduction(novel_file: Path) -> str:
    """æå–ç®€ä»‹éƒ¨åˆ†"""
    with open(novel_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–ç¬¬ä¸€ä¸ª===ä¹‹å‰çš„å†…å®¹ä½œä¸ºç®€ä»‹
    first_chapter = re.search(r'===\s*ç¬¬\s*\d+\s*ç« ', content)
    if first_chapter:
        intro = content[:first_chapter.start()].strip()
        return intro
    return ""


def extract_all_chapters(novel_file: Path) -> List[Dict]:
    """æå–æ‰€æœ‰ç« èŠ‚"""
    with open(novel_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    chapter_pattern = r'===\s*ç¬¬\s*(\d+)\s*ç« \s*(.*)===\s*\n'
    matches = list(re.finditer(chapter_pattern, content))
    
    chapters = []
    for i, match in enumerate(matches):
        chapter_number = int(match.group(1))
        chapter_title = match.group(2).strip()
        
        start_pos = match.end()
        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(content)
        chapter_content = content[start_pos:end_pos].strip()
        
        chapters.append({
            'number': chapter_number,
            'title': chapter_title,
            'content': chapter_content,
            'word_count': len(chapter_content)
        })
    
    return chapters


def save_introduction(intro: str, output_dir: Path):
    """ä¿å­˜ç®€ä»‹"""
    intro_file = output_dir / "chpt_0000_ç®€ä»‹.md"
    with open(intro_file, 'w', encoding='utf-8') as f:
        f.write("# åºåˆ—å…¬è·¯æ±‚ç”Ÿï¼šæˆ‘åœ¨æœ«æ—¥å‡çº§ç‰©èµ„\n\n")
        f.write("## ç®€ä»‹\n\n")
        f.write(intro)
    print(f"âœ… ç®€ä»‹å·²ä¿å­˜: {intro_file.name}")


def save_chapter_markdown(chapter: Dict, output_dir: Path):
    """ä¿å­˜å•ç« åˆ†æ®µmarkdown"""
    chapter_file = output_dir / f"chpt_{chapter['number']:04d}.md"
    
    with open(chapter_file, 'w', encoding='utf-8') as f:
        f.write(f"# ç¬¬{chapter['number']}ç«  - {chapter['title']}\n\n")
        f.write(f"> **å­—æ•°**: {chapter['word_count']}\n\n")
        f.write("---\n\n")
        f.write(chapter['content'])
    
    print(f"âœ… ç« èŠ‚å·²ä¿å­˜: {chapter_file.name} ({chapter['word_count']}å­—)")


def save_functional_analysis_with_version(
    analysis,
    chapter_number: int,
    output_dir: Path
) -> Tuple[Path, Path]:
    """
    ä¿å­˜åŠŸèƒ½åˆ†æç»“æœï¼ˆç‰ˆæœ¬åŒ–ï¼‰
    
    Returns:
        Tuple[versioned_file, latest_file]
    """
    # æ—¶é—´æˆ³ç‰ˆæœ¬
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    versioned_file = output_dir / f"chpt_{chapter_number:04d}_functional_analysis_v{timestamp}.json"
    
    # _latest æŒ‡é’ˆ
    latest_file = output_dir / f"chpt_{chapter_number:04d}_functional_analysis_latest.json"
    
    # ä¿å­˜æ—¶é—´æˆ³ç‰ˆæœ¬
    with open(versioned_file, 'w', encoding='utf-8') as f:
        json.dump(analysis.model_dump(mode='json'), f, ensure_ascii=False, indent=2)
    
    # æ›´æ–° _latest æŒ‡é’ˆ
    with open(latest_file, 'w', encoding='utf-8') as f:
        json.dump(analysis.model_dump(mode='json'), f, ensure_ascii=False, indent=2)
    
    return versioned_file, latest_file


def main():
    """ä¸»å¤„ç†æµç¨‹"""
    print("\n" + "ğŸ“š" * 40)
    print("  Novel å¤„ç† V3 - é‡æ–°è®¾è®¡çš„æµç¨‹")
    print("ğŸ“š" * 40)
    print("\nğŸ“‹ æµç¨‹:")
    print("  1. æ‹†åˆ†ç®€ä»‹")
    print("  2. æ‹†åˆ†ç« èŠ‚ (å•ç« md)")
    print("  3. åŠŸèƒ½åˆ†æ (R1/V3 + fallback)")
    print("  4. ç‰ˆæœ¬ç®¡ç† (_latest.json + æ—¶é—´æˆ³)\n")
    
    # è·¯å¾„è®¾ç½®
    project_dir = Path(__file__).parent.parent / "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯"
    novel_file = project_dir / "raw/novel.txt"
    novel_dir = project_dir / "novel"
    analysis_dir = novel_dir / "functional_analysis"
    analysis_dir.mkdir(parents=True, exist_ok=True)
    
    # Step 1: æå–å¹¶ä¿å­˜ç®€ä»‹
    print("="*80)
    print("  Step 1: æå–ç®€ä»‹")
    print("="*80)
    intro = extract_introduction(novel_file)
    if intro:
        save_introduction(intro, novel_dir)
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ç®€ä»‹")
    
    # Step 2: æå–æ‰€æœ‰ç« èŠ‚
    print("\n" + "="*80)
    print("  Step 2: æå–ç« èŠ‚")
    print("="*80)
    chapters = extract_all_chapters(novel_file)
    print(f"âœ… æˆåŠŸæå– {len(chapters)} ç« \n")
    
    # Step 3: ä¿å­˜å•ç« markdown
    print("="*80)
    print("  Step 3: ä¿å­˜å•ç«  Markdown")
    print("="*80)
    for chapter in chapters[:10]:  # å…ˆå¤„ç†å‰10ç« 
        save_chapter_markdown(chapter, novel_dir)
    
    # Step 4: åŠŸèƒ½åˆ†æï¼ˆä½¿ç”¨ R1/V3 + fallbackï¼‰
    print("\n" + "="*80)
    print("  Step 4: åŠŸèƒ½åˆ†æ (R1/V3 + Fallback)")
    print("="*80)
    print("âš™ï¸ é…ç½®: ä¸»æ¨¡å‹=V3, Fallbackæ¨¡å‹=R1")
    print("ğŸ” Fallbackè§¦å‘æ¡ä»¶:")
    print("  - V3 APIé”™è¯¯")
    print("  - æ®µè½1å­—æ•° < 120 (åªæœ‰å¹¿æ’­æ²¡æœ‰ååº”)")
    print("  - æ®µè½1å­—æ•° > 400 (è¿‡åº¦èšåˆ)\n")
    
    analyzer = NovelChapterAnalyzer()
    
    success_count = 0
    failed_chapters = []
    
    for i, chapter in enumerate(chapters[:10], 1):  # å…ˆå¤„ç†å‰10ç« 
        print(f"\n{'â”€'*80}")
        print(f"  [{i}/10] ç¬¬{chapter['number']}ç«  - {chapter['title']}")
        print(f"{'â”€'*80}\n")
        
        try:
            # æ‰§è¡Œåˆ†æ
            result = analyzer.execute(
                chapter_content=chapter['content'],
                chapter_number=chapter['number'],
                chapter_title=chapter['title'],
                novel_title="åºåˆ—å…¬è·¯æ±‚ç”Ÿï¼šæˆ‘åœ¨æœ«æ—¥å‡çº§ç‰©èµ„"
            )
            
            # ç‰ˆæœ¬åŒ–ä¿å­˜
            versioned_file, latest_file = save_functional_analysis_with_version(
                result,
                chapter['number'],
                analysis_dir
            )
            
            # ç»Ÿè®¡ä¿¡æ¯
            seg_1 = result.segments[0] if result.segments else None
            
            print(f"âœ… åˆ†æå®Œæˆ")
            print(f"  - åŠŸèƒ½æ®µ: {result.chapter_summary.total_segments}")
            print(f"  - P0: {result.chapter_summary.p0_count}")
            print(f"  - P1: {result.chapter_summary.p1_count}")
            print(f"  - P2: {result.chapter_summary.p2_count}")
            if seg_1:
                print(f"  - æ®µè½1å­—æ•°: {seg_1.metadata.word_count}")
            print(f"\nğŸ’¾ å·²ä¿å­˜:")
            print(f"  - {versioned_file.name}")
            print(f"  - {latest_file.name}")
            
            success_count += 1
            
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
            failed_chapters.append(chapter['number'])
            import traceback
            traceback.print_exc()
        
        # è¿›åº¦æç¤º
        if i < 10:
            print(f"\nâ³ ç­‰å¾…3ç§’...")
            import time
            time.sleep(3)
    
    # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
    print("\n" + "="*80)
    print("  ğŸ“Š å¤„ç†å®Œæˆ")
    print("="*80)
    
    print(f"\nâœ… æˆåŠŸ: {success_count}/10")
    if failed_chapters:
        print(f"âŒ å¤±è´¥ç« èŠ‚: {failed_chapters}")
    
    # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    report = {
        "timestamp": datetime.now().isoformat(),
        "total_chapters": len(chapters),
        "processed_chapters": 10,
        "success_count": success_count,
        "failed_chapters": failed_chapters,
        "version": "v3",
        "model_config": {
            "primary_model": "deepseek-chat",
            "fallback_model": "deepseek-reasoner",
            "enable_fallback": True
        }
    }
    
    report_file = analysis_dir / f"processing_report_v3_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ å¤„ç†æŠ¥å‘Š: {report_file.name}")
    print("\n" + "="*80)


if __name__ == "__main__":
    main()
