# å®Œæ•´å·¥ä½œæµè®¾è®¡

**æœ€åæ›´æ–°**: 2026-02-12  
**ç›®çš„**: è¯¦ç»†è¯´æ˜æ¯ä¸€æ­¥çš„å‰ç«¯åŠŸèƒ½â†’åç«¯å·¥å…·å·¥ä½œæµâ†’dataç»“æœå­˜å‚¨

---

## ğŸ“Š æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (React)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Step 1   â”‚  â”‚ Step 2   â”‚  â”‚ Step 3   â”‚  â”‚ Step 4   â”‚        â”‚
â”‚  â”‚ Import   â”‚â†’ â”‚ Script   â”‚â†’ â”‚ Novel    â”‚â†’ â”‚Alignment â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Backend API (FastAPI)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ /api/v2/projects/{project_id}/                           â”‚   â”‚
â”‚  â”‚  â”œâ”€ POST /files (ä¸Šä¼ )                                  â”‚   â”‚
â”‚  â”‚  â”œâ”€ GET /workflow-state (çŠ¶æ€)                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ POST /workflow/{step_id}/start (å¯åŠ¨)               â”‚   â”‚
â”‚  â”‚  â””â”€ WS /ws (å®æ—¶æ›´æ–°)                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“ è°ƒç”¨
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Workflows & Tools (Python)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Preprocess     â”‚  â”‚ Script         â”‚  â”‚ Novel          â”‚    â”‚
â”‚  â”‚ Service        â”‚  â”‚ Processing     â”‚  â”‚ Processing     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“ å†™å…¥/è¯»å–
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Storage (JSON Files)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ raw/   â”‚â†’ â”‚ processed/ â”‚â†’ â”‚analysis/ â”‚â†’ â”‚reports/ â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Step 1: Import - æ–‡ä»¶å¯¼å…¥ä¸æ ‡å‡†åŒ–

### å‰ç«¯åŠŸèƒ½

**é¡µé¢**: `Step1ImportPage.tsx`

**UIç»„ä»¶**:
```typescript
<Step1ImportPage>
  <FileUploadZone 
    accept=".txt,.srt"
    multiple={true}
    onUpload={handleFileUpload}
  />
  
  <FileList>
    {/* Novelæ–‡ä»¶ */}
    <FileItem 
      name="åºåˆ—å…¬è·¯æ±‚ç”Ÿ.txt"
      status="imported"
      size="500KB"
      type="novel"
    />
    
    {/* Scriptæ–‡ä»¶ */}
    <FileItem 
      name="ep01.srt"
      status="processing"
      progress={45}
      type="script"
    />
  </FileList>
  
  <PreprocessStatus>
    <StatusBadge status="running" />
    <ProgressBar value={45} />
    <TaskList>
      <Task name="Novel: ç« èŠ‚æ£€æµ‹" status="completed" />
      <Task name="Script: ep01.srt æ–‡æœ¬æå–" status="running" progress={45} />
    </TaskList>
  </PreprocessStatus>
</Step1ImportPage>
```

**ç”¨æˆ·æ“ä½œ**:
1. æ‹–æ‹½æ–‡ä»¶æˆ–ç‚¹å‡»ä¸Šä¼ 
2. è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶ç±»å‹ï¼ˆ.txt â†’ Novel, .srt â†’ Scriptï¼‰
3. å®æ—¶æ˜¾ç¤ºé¢„å¤„ç†è¿›åº¦

**APIè°ƒç”¨**:
```typescript
// ä¸Šä¼ æ–‡ä»¶
const formData = new FormData();
formData.append('file', file);

await fetch(`/api/v2/projects/${projectId}/files`, {
  method: 'POST',
  body: formData
});

// è½®è¯¢é¢„å¤„ç†çŠ¶æ€ï¼ˆæˆ–ä½¿ç”¨WebSocketï¼‰
const status = await fetch(`/api/v2/projects/${projectId}/preprocess-status`);
```

---

### åç«¯å·¥ä½œæµ

**è§¦å‘æ–¹å¼**: æ–‡ä»¶ä¸Šä¼ åè‡ªåŠ¨è§¦å‘

**æœåŠ¡**: `PreprocessService` (å¼‚æ­¥åå°ä»»åŠ¡)

**å·¥å…·é“¾**:

#### Novelé¢„å¤„ç†
```python
PreprocessService.process_novel(project_id, file_path)
    â†“
1. NovelImporter.execute(novel_path)
   - ç¼–ç æ£€æµ‹ (chardet)
   - è½¬æ¢ä¸ºUTF-8
   - ä¿å­˜åˆ° processed/novel/standardized.txt
    â†“
2. NovelMetadataExtractor.execute(standardized_text)
   - æå–æ ‡é¢˜ã€ä½œè€…ã€å­—æ•°
   - ä¿å­˜åˆ° processed/novel/metadata.json
    â†“
3. NovelChapterDetector.execute(standardized_text)
   - æ£€æµ‹ç« èŠ‚è¾¹ç•Œï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
   - æå–ç« èŠ‚æ ‡é¢˜
   - ä¿å­˜åˆ° processed/novel/chapters.json
```

#### Scripté¢„å¤„ç†
```python
PreprocessService.process_script(project_id, file_path)
    â†“
1. SrtImporter.execute(srt_path)
   - è§£æSRTæ ¼å¼
   - éªŒè¯æ—¶é—´è½´
   - ä¿å­˜åˆ° processed/script/{episode_id}.json
    â†“
2. SrtTextExtractor.execute(srt_entries)
   - æå–çº¯æ–‡æœ¬
   - LLMæ·»åŠ æ ‡ç‚¹ç¬¦å·
   - ä¿®æ­£é”™åˆ«å­—
   - ä¿å­˜åˆ° processed/script/{episode_id}-imported.md
```

**é…ç½®**:
```python
PreprocessConfig(
    novel_encoding_detection=True,
    script_text_extraction=True,
    use_llm_for_punctuation=True,
    llm_provider="deepseek"  # ä½æˆæœ¬
)
```

**æˆæœ¬**: ~$0.02-0.04 / é›†ï¼ˆä»…æ ‡ç‚¹ä¿®å¤ï¼‰

---

### Dataå­˜å‚¨ç»“æœ

**å†™å…¥è·¯å¾„**:
```
data/projects/{project_id}/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ novel/
â”‚   â”‚   â””â”€â”€ åºåˆ—å…¬è·¯æ±‚ç”Ÿ.txt              # ç”¨æˆ·ä¸Šä¼ 
â”‚   â””â”€â”€ srt/
â”‚       â”œâ”€â”€ ep01.srt                      # ç”¨æˆ·ä¸Šä¼ 
â”‚       â””â”€â”€ ep02.srt
â”‚
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ novel/
â”‚   â”‚   â”œâ”€â”€ standardized.txt              # âœ… Step 1è¾“å‡º
â”‚   â”‚   â”œâ”€â”€ metadata.json                 # âœ… Step 1è¾“å‡º
â”‚   â”‚   â”‚   {
â”‚   â”‚   â”‚     "title": "åºåˆ—å…¬è·¯æ±‚ç”Ÿ",
â”‚   â”‚   â”‚     "author": "æœ«å“¥è¶…å‡¡",
â”‚   â”‚   â”‚     "total_chars": 500000,
â”‚   â”‚   â”‚     "chapter_count": 50
â”‚   â”‚   â”‚   }
â”‚   â”‚   â””â”€â”€ chapters.json                 # âœ… Step 1è¾“å‡º
â”‚   â”‚       [
â”‚   â”‚         {
â”‚   â”‚           "id": "chapter_001",
â”‚   â”‚           "title": "ç¬¬ä¸€ç«  æœ«æ—¥é™ä¸´",
â”‚   â”‚           "start_line": 1,
â”‚   â”‚           "end_line": 150
â”‚   â”‚         },
â”‚   â”‚         ...
â”‚   â”‚       ]
â”‚   â”‚
â”‚   â””â”€â”€ script/
â”‚       â”œâ”€â”€ ep01.json                     # âœ… Step 1è¾“å‡º
â”‚       â”‚   {
â”‚       â”‚     "episode_id": "ep01",
â”‚       â”‚     "total_entries": 146,
â”‚       â”‚     "entries": [...]
â”‚       â”‚   }
â”‚       â”œâ”€â”€ ep01-imported.md              # âœ… Step 1è¾“å‡º
â”‚       â”‚   æœ«æ—¥é™ä¸´ï¼Œå…¬è·¯æ±‚ç”Ÿã€‚è‹çƒˆç‹¬è‡ª...
â”‚       â””â”€â”€ episodes.json                 # âœ… Step 1è¾“å‡º
â”‚           [
â”‚             {
â”‚               "episode_id": "ep01",
â”‚               "name": "ç¬¬ä¸€é›†",
â”‚               "status": "imported"
â”‚             },
â”‚             ...
â”‚           ]
â”‚
â””â”€â”€ meta.json
    {
      "phase_i_analyst": {
        "step_1_import": {
          "status": "completed",              # âœ… çŠ¶æ€æ›´æ–°
          "novel_imported": true,
          "novel_chapter_count": 50,
          "script_imported": true,
          "script_episodes": ["ep01", "ep02"]
        }
      }
    }
```

**çŠ¶æ€æ›´æ–°**:
```python
# æ›´æ–° meta.json
meta.phase_i_analyst.step_1_import.status = PhaseStatus.COMPLETED
meta.phase_i_analyst.step_1_import.novel_imported = True
meta.phase_i_analyst.step_1_import.novel_chapter_count = 50
meta.phase_i_analyst.step_1_import.script_episodes = ["ep01", "ep02", ...]
project_manager_v2.save_project_meta(meta)
```

---

## ğŸ¯ Step 2: Script Analysis - è„šæœ¬åˆ†æ

### å‰ç«¯åŠŸèƒ½

**é¡µé¢**: `Step2ScriptAnalysisPage.tsx`

**UIç»„ä»¶**:
```typescript
<Step2ScriptAnalysisPage>
  {/* å¼€å§‹æŒ‰é’® */}
  <StartButton 
    disabled={!canStart}
    onClick={handleStart}
  >
    Start Analysis
  </StartButton>
  
  {/* é…ç½®é€‰é¡¹ */}
  <ConfigPanel>
    <Switch label="Enable Hook Detection (ep01)" checked={true} />
    <Switch label="Enable ABC Classification" checked={true} />
    <Select label="LLM Provider" value="deepseek" />
  </ConfigPanel>
  
  {/* é›†æ•°åˆ—è¡¨ */}
  <EpisodeList>
    <EpisodeCard 
      episodeId="ep01"
      status="running"
      progress={45}
      currentTask="Segmenting script..."
    />
    <EpisodeCard 
      episodeId="ep02"
      status="pending"
    />
  </EpisodeList>
  
  {/* å®æ—¶æ—¥å¿— */}
  <LogViewer logs={workflowLogs} />
</Step2ScriptAnalysisPage>
```

**ç”¨æˆ·æ“ä½œ**:
1. ç‚¹å‡» "Start Analysis" æŒ‰é’®
2. æŸ¥çœ‹å®æ—¶è¿›åº¦å’Œæ—¥å¿—
3. å¯å•ç‹¬å¯åŠ¨/åœæ­¢æŸä¸€é›†

**APIè°ƒç”¨**:
```typescript
// å¯åŠ¨æ•´ä½“åˆ†æ
await fetch(`/api/v2/projects/${projectId}/workflow/step_2_script/start`, {
  method: 'POST'
});

// å¯åŠ¨å•é›†
await fetch(`/api/v2/projects/${projectId}/episodes/${episodeId}/start`, {
  method: 'POST'
});

// åœæ­¢å•é›†
await fetch(`/api/v2/projects/${projectId}/episodes/${episodeId}/stop`, {
  method: 'POST'
});
```

---

### åç«¯å·¥ä½œæµ

**è§¦å‘æ–¹å¼**: ç”¨æˆ·ç‚¹å‡» "Start Analysis"

**å·¥ä½œæµ**: `ScriptProcessingWorkflow`

**Phaseè®¾è®¡**:

```python
async def _execute_script_workflow(project_id: str):
    """æ‰¹é‡å¤„ç†æ‰€æœ‰SRTæ–‡ä»¶"""
    
    # 1. åŠ è½½é¡¹ç›®å’Œé›†æ•°åˆ—è¡¨
    meta = project_manager_v2.get_project(project_id)
    episodes = meta.phase_i_analyst.step_1_import.script_episodes
    
    # 2. é…ç½®
    config = ScriptProcessingConfig(
        enable_hook_detection=True,       # ep01å¯ç”¨
        enable_abc_classification=True,
        segmentation_provider="deepseek",
        min_quality_score=70
    )
    
    # 3. é€é›†å¤„ç†
    for i, episode_id in enumerate(episodes):
        # æ›´æ–°çŠ¶æ€
        await broadcast_progress(
            project_id, "step_2_script",
            progress=(i / len(episodes)) * 100,
            current_task=f"Processing {episode_id} ({i+1}/{len(episodes)})"
        )
        
        # æ‰§è¡ŒWorkflow
        result = await process_single_episode(
            project_id, episode_id, config
        )
        
        # ä¿å­˜ç»“æœ
        save_episode_result(project_id, episode_id, result)
    
    # 4. å®Œæˆ
    meta.phase_i_analyst.step_2_script.status = PhaseStatus.COMPLETED
    project_manager_v2.save_project_meta(meta)
```

**å•é›†å¤„ç†æµç¨‹**:
```python
def process_single_episode(project_id, episode_id, config):
    """
    Phase 1: SRTå¯¼å…¥ï¼ˆå·²åœ¨Step 1å®Œæˆï¼Œè·³è¿‡ï¼‰
    Phase 2: æ–‡æœ¬æå–ï¼ˆå·²åœ¨Step 1å®Œæˆï¼Œè·³è¿‡ï¼‰
    Phase 3: Hookæ£€æµ‹ï¼ˆä»…ep01ï¼‰
    Phase 4: è¯­ä¹‰åˆ†æ®µ + ABCåˆ†ç±»
    Phase 5: è´¨é‡éªŒè¯
    """
    
    # è¯»å–é¢„å¤„ç†ç»“æœ
    srt_entries = load_json(f"processed/script/{episode_id}.json")
    extracted_text = load_text(f"processed/script/{episode_id}-imported.md")
    
    # Phase 3: Hookæ£€æµ‹ï¼ˆä»…ep01ï¼‰
    hook_result = None
    if episode_id == "ep01" and config.enable_hook_detection:
        hook_result = HookDetector.execute(
            extracted_text=extracted_text,
            novel_intro=load_novel_intro(project_id)
        )
        # ä¿å­˜Hookç»“æœ
        artifact_manager.save_artifact(
            content=hook_result.model_dump(),
            artifact_type=f"{episode_id}_hook",
            base_dir=f"analysis/script"
        )
    
    # Phase 4: è¯­ä¹‰åˆ†æ®µ + ABCåˆ†ç±»ï¼ˆTwo-Passï¼‰
    segmentation_result = ScriptSegmenter.execute(
        extracted_text=extracted_text,
        srt_entries=srt_entries["entries"],
        enable_abc_classification=config.enable_abc_classification,
        provider=config.segmentation_provider
    )
    # ä¿å­˜åˆ†æ®µç»“æœ
    artifact_manager.save_artifact(
        content=segmentation_result.model_dump(),
        artifact_type=f"{episode_id}_segmentation",
        base_dir=f"analysis/script"
    )
    
    # Phase 5: è´¨é‡éªŒè¯
    validation_result = ScriptValidator.execute(
        srt_entries=srt_entries,
        segmentation_result=segmentation_result
    )
    # ä¿å­˜éªŒè¯ç»“æœ
    artifact_manager.save_artifact(
        content=validation_result.model_dump(),
        artifact_type=f"{episode_id}_validation",
        base_dir=f"analysis/script"
    )
    
    return {
        "episode_id": episode_id,
        "hook_result": hook_result,
        "segmentation_result": segmentation_result,
        "validation_result": validation_result
    }
```

**é…ç½®**:
```python
ScriptProcessingConfig(
    enable_hook_detection=True,       # ep01å¯ç”¨Hookæ£€æµ‹
    enable_abc_classification=True,   # å¯ç”¨ABCåˆ†ç±»
    segmentation_provider="deepseek", # DeepSeeké™ä½æˆæœ¬
    text_extraction_provider="deepseek",
    min_quality_score=70,
    retry_on_error=True,
    max_retries=3
)
```

**æˆæœ¬**: 
- ep01ï¼ˆå«Hookï¼‰: ~$0.19
- ep02-10ï¼ˆæ— Hookï¼‰: ~$0.09/é›†
- 10é›†æ€»è®¡: ~$2.00

---

### Dataå­˜å‚¨ç»“æœ

**å†™å…¥è·¯å¾„**:
```
data/projects/{project_id}/
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ script/
â”‚       â”œâ”€â”€ ep01_hook_latest.json                 # âœ… Step 2è¾“å‡ºï¼ˆep01ä¸“å±ï¼‰
â”‚       â”‚   {
â”‚       â”‚     "episode_id": "ep01",
â”‚       â”‚     "has_hook": true,
â”‚       â”‚     "hook_end_time": 45.6,
â”‚       â”‚     "confidence": 0.92
â”‚       â”‚   }
â”‚       â”‚
â”‚       â”œâ”€â”€ ep01_segmentation_latest.json         # âœ… Step 2è¾“å‡º
â”‚       â”‚   {
â”‚       â”‚     "episode_id": "ep01",
â”‚       â”‚     "total_segments": 12,
â”‚       â”‚     "segments": [
â”‚       â”‚       {
â”‚       â”‚         "segment_id": "seg001",
â”‚       â”‚         "content": "æœ«æ—¥é™ä¸´ï¼Œå…¬è·¯æ±‚ç”Ÿã€‚",
â”‚       â”‚         "category": "A",  // A=è®¾å®š, B=äº‹ä»¶, C=ç³»ç»Ÿ
â”‚       â”‚         "start_time": 0.0,
â”‚       â”‚         "end_time": 2.5
â”‚       â”‚       },
â”‚       â”‚       ...
â”‚       â”‚     ]
â”‚       â”‚   }
â”‚       â”‚
â”‚       â”œâ”€â”€ ep01_validation_latest.json           # âœ… Step 2è¾“å‡º
â”‚       â”‚   {
â”‚       â”‚     "episode_id": "ep01",
â”‚       â”‚     "quality_score": 85,
â”‚       â”‚     "issues": [],
â”‚       â”‚     "suggestions": ["..."]
â”‚       â”‚   }
â”‚       â”‚
â”‚       â”œâ”€â”€ ep02_segmentation_latest.json         # âœ… Step 2è¾“å‡º
â”‚       â”‚
â”‚       â””â”€â”€ history/                              # å†å²ç‰ˆæœ¬
â”‚           â”œâ”€â”€ ep01_hook_v20260212_180000.json
â”‚           â”œâ”€â”€ ep01_segmentation_v20260212_180100.json
â”‚           â””â”€â”€ ...
â”‚
â””â”€â”€ meta.json
    {
      "phase_i_analyst": {
        "step_2_script": {
          "status": "completed",                  # âœ… çŠ¶æ€æ›´æ–°
          "total_episodes": 5,
          "completed_episodes": 5,
          "episodes_status": {
            "ep01": {
              "status": "completed",
              "has_hook": true,
              "quality_score": 85
            },
            "ep02": {
              "status": "completed",
              "quality_score": 82
            }
          }
        }
      }
    }
```

---

## ğŸ¯ Step 3: Novel Analysis - å°è¯´åˆ†æ

### å‰ç«¯åŠŸèƒ½

**é¡µé¢**: `Step3NovelAnalysisPage.tsx`

**UIç»„ä»¶**:
```typescript
<Step3NovelAnalysisPage>
  {/* å¼€å§‹æŒ‰é’® */}
  <StartButton onClick={handleStart}>
    Start Analysis
  </StartButton>
  
  {/* é…ç½® */}
  <ConfigPanel>
    <InputNumber label="Chapter Range" value={[1, 10]} />
    <InputNumber label="Max Concurrent" value={3} />
    <Switch label="Enable System Analysis" checked={true} />
    <Select label="LLM Provider" value="claude" />
  </ConfigPanel>
  
  {/* ç« èŠ‚åˆ—è¡¨ */}
  <ChapterList>
    <ChapterCard 
      chapterId="chapter_001"
      title="ç¬¬ä¸€ç«  æœ«æ—¥é™ä¸´"
      status="completed"
      qualityScore={88}
    />
    <ChapterCard 
      chapterId="chapter_002"
      status="running"
      progress={60}
      currentTask="Annotating chapter..."
    />
  </ChapterList>
</Step3NovelAnalysisPage>
```

**ç”¨æˆ·æ“ä½œ**:
1. é…ç½®å¤„ç†èŒƒå›´ï¼ˆå‰10ç« ï¼‰
2. ç‚¹å‡» "Start Analysis"
3. æŸ¥çœ‹ç« èŠ‚å¤„ç†è¿›åº¦

---

### åç«¯å·¥ä½œæµ

**å·¥ä½œæµ**: `NovelProcessingWorkflow`

**Phaseè®¾è®¡**:

```python
async def _execute_novel_workflow(project_id: str):
    """å¹¶è¡Œå¤„ç†å¤šä¸ªç« èŠ‚"""
    
    # 1. åŠ è½½ç« èŠ‚åˆ—è¡¨
    chapters = load_json(f"processed/novel/chapters.json")
    target_chapters = chapters[0:10]  # åªå¤„ç†å‰10ç« 
    
    # 2. é…ç½®
    config = NovelProcessingConfig(
        enable_parallel=True,
        max_concurrent_chapters=3,
        segmentation_provider="claude",
        annotation_provider="claude",
        enable_system_analysis=True
    )
    
    # 3. å¹¶è¡Œå¤„ç†ç« èŠ‚
    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = []
        for chapter in target_chapters:
            future = executor.submit(
                process_single_chapter,
                project_id, chapter, config
            )
            futures.append(future)
        
        # ç­‰å¾…æ‰€æœ‰ç« èŠ‚å®Œæˆ
        for i, future in enumerate(as_completed(futures)):
            result = future.result()
            
            # æ›´æ–°è¿›åº¦
            await broadcast_progress(
                project_id, "step_3_novel",
                progress=(i / len(target_chapters)) * 100
            )
    
    # 4. ç³»ç»Ÿå…ƒç´ åˆ†æï¼ˆå…¨ä¹¦ä¸€æ¬¡ï¼‰
    if config.enable_system_analysis:
        system_catalog = NovelSystemAnalyzer.execute(
            annotated_chapters=load_all_annotated_chapters(project_id)
        )
        # ä¿å­˜ç³»ç»Ÿç›®å½•
        artifact_manager.save_artifact(
            content=system_catalog.model_dump(),
            artifact_type="system_catalog",
            base_dir=f"analysis/novel"
        )
    
    # 5. å®Œæˆ
    meta.phase_i_analyst.step_3_novel.status = PhaseStatus.COMPLETED
    project_manager_v2.save_project_meta(meta)
```

**å•ç« å¤„ç†æµç¨‹**:
```python
def process_single_chapter(project_id, chapter, config):
    """
    Phase 1: ç« èŠ‚å¯¼å…¥ï¼ˆå·²åœ¨Step 1å®Œæˆï¼‰
    Phase 2: ç« èŠ‚åˆ†æ®µï¼ˆTwo-Passï¼‰
    Phase 3: ç« èŠ‚æ ‡æ³¨ï¼ˆThree-Passï¼‰
    Phase 4: è´¨é‡éªŒè¯
    """
    
    chapter_id = chapter["id"]
    
    # è¯»å–ç« èŠ‚æ–‡æœ¬
    standardized_text = load_text(f"processed/novel/standardized.txt")
    chapter_text = extract_chapter_text(
        standardized_text,
        chapter["start_line"],
        chapter["end_line"]
    )
    
    # Phase 2: ç« èŠ‚åˆ†æ®µï¼ˆTwo-Passï¼‰
    segmentation_result = NovelSegmenter.execute(
        chapter_text=chapter_text,
        chapter_id=chapter_id,
        provider=config.segmentation_provider
    )
    # ä¿å­˜åˆ†æ®µç»“æœ
    artifact_manager.save_artifact(
        content=segmentation_result.model_dump(),
        artifact_type=f"{chapter_id}_segmentation",
        base_dir=f"analysis/novel"
    )
    
    # Phase 3: ç« èŠ‚æ ‡æ³¨ï¼ˆThree-Passï¼‰
    annotation_result = NovelAnnotator.execute(
        segmented_chapter=segmentation_result,
        provider=config.annotation_provider
    )
    # ä¿å­˜æ ‡æ³¨ç»“æœ
    artifact_manager.save_artifact(
        content=annotation_result.model_dump(),
        artifact_type=f"{chapter_id}_annotation",
        base_dir=f"analysis/novel"
    )
    
    # Phase 4: è´¨é‡éªŒè¯
    validation_result = NovelValidator.execute(
        annotation_result=annotation_result
    )
    # ä¿å­˜éªŒè¯ç»“æœ
    artifact_manager.save_artifact(
        content=validation_result.model_dump(),
        artifact_type=f"{chapter_id}_validation",
        base_dir=f"analysis/novel"
    )
    
    return {
        "chapter_id": chapter_id,
        "segmentation_result": segmentation_result,
        "annotation_result": annotation_result,
        "validation_result": validation_result
    }
```

**æˆæœ¬**:
- å•ç« æˆæœ¬: ~$0.15
- 10ç« æ€»è®¡: ~$1.50

---

### Dataå­˜å‚¨ç»“æœ

**å†™å…¥è·¯å¾„**:
```
data/projects/{project_id}/
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ novel/
â”‚       â”œâ”€â”€ chapter_001_segmentation_latest.json     # âœ… Step 3è¾“å‡º
â”‚       â”‚   {
â”‚       â”‚     "chapter_id": "chapter_001",
â”‚       â”‚     "total_paragraphs": 50,
â”‚       â”‚     "paragraphs": [
â”‚       â”‚       {
â”‚       â”‚         "paragraph_id": "p001",
â”‚       â”‚         "content": "æœ«æ—¥é™ä¸´çš„é‚£ä¸€å¤©...",
â”‚       â”‚         "category": "narrative"
â”‚       â”‚       },
â”‚       â”‚       ...
â”‚       â”‚     ]
â”‚       â”‚   }
â”‚       â”‚
â”‚       â”œâ”€â”€ chapter_001_annotation_latest.json       # âœ… Step 3è¾“å‡º
â”‚       â”‚   {
â”‚       â”‚     "chapter_id": "chapter_001",
â”‚       â”‚     "event_timeline": [
â”‚       â”‚       {
â”‚       â”‚         "event_id": "ev001",
â”‚       â”‚         "description": "è‹çƒˆé©¾è½¦è¡Œé©¶åœ¨é«˜é€Ÿå…¬è·¯",
â”‚       â”‚         "timestamp": "Day 1, 10:00",
â”‚       â”‚         "participants": ["è‹çƒˆ"]
â”‚       â”‚       },
â”‚       â”‚       ...
â”‚       â”‚     ],
â”‚       â”‚     "setting_library": [...]
â”‚       â”‚   }
â”‚       â”‚
â”‚       â”œâ”€â”€ chapter_001_validation_latest.json       # âœ… Step 3è¾“å‡º
â”‚       â”‚
â”‚       â”œâ”€â”€ chapter_002_segmentation_latest.json
â”‚       â”œâ”€â”€ chapter_002_annotation_latest.json
â”‚       â”‚
â”‚       â”œâ”€â”€ system_catalog_latest.json               # âœ… Step 3è¾“å‡ºï¼ˆå…¨ä¹¦ï¼‰
â”‚       â”‚   {
â”‚       â”‚     "system_name": "åºåˆ—å…¬è·¯æ±‚ç”Ÿç³»ç»Ÿ",
â”‚       â”‚     "categories": {
â”‚       â”‚       "player_stats": [...],
â”‚       â”‚       "items": [...],
â”‚       â”‚       "skills": [...]
â”‚       â”‚     }
â”‚       â”‚   }
â”‚       â”‚
â”‚       â””â”€â”€ history/
â”‚           â””â”€â”€ ...
â”‚
â””â”€â”€ meta.json
    {
      "phase_i_analyst": {
        "step_3_novel": {
          "status": "completed",                    # âœ… çŠ¶æ€æ›´æ–°
          "total_chapters": 10,
          "completed_chapters": 10,
          "total_events": 150,
          "total_settings": 80,
          "novel_steps": {
            "chapter_001": {
              "status": "completed",
              "quality_score": 88
            },
            ...
          }
        }
      }
    }
```

---

## ğŸ¯ Step 4: Alignment - å¯¹é½åˆ†æ

### å‰ç«¯åŠŸèƒ½

**é¡µé¢**: `Step4AlignmentPage.tsx`

**UIç»„ä»¶**:
```typescript
<Step4AlignmentPage>
  {/* ä¾èµ–æ£€æŸ¥ */}
  <DependencyCheck>
    <CheckItem label="Step 2: Script Analysis" status="completed" />
    <CheckItem label="Step 3: Novel Analysis" status="completed" />
  </DependencyCheck>
  
  {/* å¼€å§‹æŒ‰é’® */}
  <StartButton 
    disabled={!canStart}
    onClick={handleStart}
  >
    Start Alignment
  </StartButton>
  
  {/* å¯¹é½è¿›åº¦ */}
  <AlignmentProgress>
    <PairCard 
      chapterId="chapter_001"
      episodeId="ep01"
      status="running"
      progress={60}
    />
  </AlignmentProgress>
</Step4AlignmentPage>
```

---

### åç«¯å·¥ä½œæµ

**å·¥ä½œæµ**: `AlignmentWorkflow` ğŸš§ å¾…å®ç°

**Phaseè®¾è®¡**:

```python
async def _execute_alignment_workflow(project_id: str):
    """å¯¹é½Novelå’ŒScript"""
    
    # 1. åŠ è½½æ•°æ®
    novel_annotations = load_novel_annotations(project_id)
    script_segmentations = load_script_segmentations(project_id)
    
    # 2. é…ç½®
    config = AlignmentConfig(
        enable_hook_alignment=True,
        min_confidence_threshold=0.7,
        alignment_provider="claude"
    )
    
    # 3. é€å¯¹å¤„ç†
    for chapter, episode in zip(chapters, episodes):
        # Phase 1: æ•°æ®éªŒè¯
        # Phase 2: Hook-Bodyåˆ†ç¦»
        # Phase 3: å¥å­çº§å¯¹é½
        # Phase 4: ABCç±»å‹åŒ¹é…
        # Phase 5: è¦†ç›–ç‡åˆ†æ
        
        alignment_result = NovelScriptAligner.execute(
            annotated_chapter=novel_annotations[chapter],
            script_segmentation=script_segmentations[episode],
            config=config
        )
        
        # ä¿å­˜å¯¹é½ç»“æœ
        artifact_manager.save_artifact(
            content=alignment_result.model_dump(),
            artifact_type=f"{chapter}_{episode}_alignment",
            base_dir=f"analysis/alignment"
        )
```

---

### Dataå­˜å‚¨ç»“æœ

**å†™å…¥è·¯å¾„**:
```
data/projects/{project_id}/
â”œâ”€â”€ analysis/
â”‚   â””â”€â”€ alignment/
â”‚       â”œâ”€â”€ chapter_001_ep01_alignment_latest.json   # âœ… Step 4è¾“å‡º
â”‚       â”‚   {
â”‚       â”‚     "chapter_id": "chapter_001",
â”‚       â”‚     "episode_id": "ep01",
â”‚       â”‚     "alignments": [
â”‚       â”‚       {
â”‚       â”‚         "script_segment_id": "seg001",
â”‚       â”‚         "novel_paragraph_id": "p001",
â”‚       â”‚         "confidence": 0.92,
â”‚       â”‚         "rewrite_strategy": "paraphrase"
â”‚       â”‚       },
â”‚       â”‚       ...
â”‚       â”‚     ],
â”‚       â”‚     "coverage": {
â”‚       â”‚       "event_coverage": 0.95,
â”‚       â”‚       "setting_coverage": 0.85
â”‚       â”‚     }
â”‚       â”‚   }
â”‚       â”‚
â”‚       â””â”€â”€ history/
â”‚           â””â”€â”€ ...
â”‚
â””â”€â”€ meta.json
    {
      "phase_i_analyst": {
        "step_4_alignment": {
          "status": "completed",                    # âœ… çŠ¶æ€æ›´æ–°
          "total_alignments": 10,
          "average_confidence": 0.89,
          "event_coverage_rate": 0.92
        }
      }
    }
```

---

## ğŸ“‹ å®Œæ•´æµç¨‹æ€»ç»“

### æ•°æ®æµå‘

```
ç”¨æˆ·ä¸Šä¼  (raw/)
    â†“
Step 1: è‡ªåŠ¨é¢„å¤„ç† (processed/)
    â”œâ”€ Novel: standardized.txt, metadata.json, chapters.json
    â””â”€ Script: ep01.json, ep01-imported.md, episodes.json
    â†“
Step 2 & 3: ç”¨æˆ·å¯åŠ¨åˆ†æ (analysis/)
    â”œâ”€ Script: ep01_segmentation, ep01_hook
    â””â”€ Novel: chapter_001_segmentation, chapter_001_annotation, system_catalog
    â†“
Step 4: å¯¹é½åˆ†æ (analysis/alignment/)
    â””â”€ chapter_001_ep01_alignment
```

### çŠ¶æ€åŒæ­¥

```
å‰ç«¯ (UIçŠ¶æ€)
    â†• WebSocket
åç«¯ (meta.json)
    â†• æ–‡ä»¶I/O
Data (JSONæ–‡ä»¶)
```

### æˆæœ¬æ±‡æ€»

| Step | å·¥å…· | æˆæœ¬/å•ä½ | 10å•ä½æ€»è®¡ |
|------|------|----------|-----------|
| Step 1 | Preprocess | ~$0.02/é›† | ~$0.20 |
| Step 2 | ScriptProcessing | ~$0.10/é›† | ~$1.00 |
| Step 3 | NovelProcessing | ~$0.15/ç«  | ~$1.50 |
| Step 4 | Alignment | ~$0.12/å¯¹ | ~$1.20 |
| **æ€»è®¡** | - | - | **~$3.90** |

---

**æœ€åæ›´æ–°**: 2026-02-12  
**ä¸‹ä¸€æ­¥**: å®æ–½ç›®å½•æ¸…ç†å’Œå‘½åç»Ÿä¸€
