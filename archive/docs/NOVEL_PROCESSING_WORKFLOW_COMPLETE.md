# å°è¯´å¤„ç†å®Œæ•´Workflowï¼ˆä»0å¼€å§‹ï¼‰

**æ›´æ–°æ—¥æœŸ**: 2026-02-08  
**ç‰ˆæœ¬**: v3.2ï¼ˆR1æ¨¡å‹ä¸ºä¸»ï¼‰  
**çŠ¶æ€**: âœ… å½“å‰æ­£ç¡®æµç¨‹

---

## ğŸ“‹ å‰ç½®æ¡ä»¶

### 1. æ¨¡å‹é…ç½®ï¼ˆé‡è¦ï¼ï¼‰

**é…ç½®æ–‡ä»¶**: `src/core/config.py`

```python
# åŒæ¨¡å‹æ”¯æŒï¼šR1ä¸ºä¸»ï¼ˆé˜…è¯»ç†è§£ä¼˜å…ˆï¼‰ï¼ŒV3 Fallback
primary_model: str = "deepseek-reasoner"   # DeepSeek R1ï¼ˆä¸»æ¨¡å‹ï¼‰âœ…
fallback_model: str = "deepseek-chat"      # DeepSeek V3ï¼ˆå¤‡ç”¨ï¼‰âœ…
enable_fallback: bool = True
```

**ä¸ºä»€ä¹ˆR1ä¸ºä¸»ï¼Ÿ**
- å°è¯´åˆ†æ®µæ˜¯**é˜…è¯»ç†è§£ä»»åŠ¡**ï¼Œéœ€è¦æ·±åº¦æ¨ç†
- R1çš„æ¨ç†èƒ½åŠ›è¿œè¶…V3ï¼Œåˆ†æ®µæ›´å‡†ç¡®
- V3å®¹æ˜“è¿‡åº¦èšåˆï¼ˆå¦‚æŠŠ3æ®µåˆæˆ1æ®µï¼‰

### 2. åŸå§‹æ•°æ®å‡†å¤‡

```
åˆ†æèµ„æ–™/æœ‰åŸå°è¯´/01_æœ«å“¥è¶…å‡¡å…¬è·¯/
â””â”€â”€ novel/
    â””â”€â”€ novel.txt  â† åŸå§‹å°è¯´æ–‡æœ¬ï¼ˆé€è¡Œæ ¼å¼ï¼‰
```

---

## ğŸ”„ å®Œæ•´å¤„ç†æµç¨‹

### æµç¨‹å›¾

```
åŸå§‹å°è¯´ (åˆ†æèµ„æ–™/)
    â†“
[Step 1] æ•°æ®æ‘„å…¥
    â†“
raw/novel.txt
    â†“
[Step 2] ç®€ä»‹æå– + LLMè¿‡æ»¤
    â†“
novel/chpt_0000_ç®€ä»‹.md
    â†“
[Step 3] åŠŸèƒ½æ®µåˆ†æï¼ˆR1æ¨¡å‹ï¼‰
    ç›´æ¥ä» raw/novel.txt è¯»å–ç« èŠ‚å¹¶åˆ†æ
    â†“
functional_analysis/
â”œâ”€â”€ chpt_XXXX_functional_analysis_latest.json
â”œâ”€â”€ ç¬¬Xç« å®Œæ•´åˆ†æ®µåˆ†æ.md
â””â”€â”€ history/
    â””â”€â”€ chpt_XXXX_functional_analysis_vXXXXXX.json
```

**âš ï¸ æ³¨æ„**: 
- âŒ **ä¸éœ€è¦** ç”Ÿæˆ `novel/chpt_0001.md` ç­‰å•ç« æ–‡ä»¶ï¼ˆå†—ä½™ï¼‰
- âœ… **ç›´æ¥** ä» `raw/novel.txt` è¯»å–å¹¶åˆ†æ
- âœ… åŠŸèƒ½æ®µåˆ†æå·²ç»åŒ…å«äº†æ›´ç²¾ç»†çš„åˆ†æ®µ

---

## ğŸ“ å„æ­¥éª¤è¯¦è§£

### Step 1: æ•°æ®æ‘„å…¥

**å·¥å…·**: æ‰‹åŠ¨å¤åˆ¶ï¼ˆæˆ–ä½¿ç”¨è¿ç§»è„šæœ¬ï¼‰

**æ“ä½œ**:
```bash
cp "åˆ†æèµ„æ–™/æœ‰åŸå°è¯´/01_æœ«å“¥è¶…å‡¡å…¬è·¯/novel/novel.txt" \
   "data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯/raw/novel.txt"
```

**è¾“å‡º**:
- `data/projects/with_novel/æœ«å“¥è¶…å‡¡å…¬è·¯/raw/novel.txt`

---

### Step 2: ç®€ä»‹æå– + LLMè¿‡æ»¤

**å·¥å…·**: `MetadataExtractor(use_llm=True)`

**æ–‡ä»¶**: `src/tools/novel_chapter_processor.py`

**åŠŸèƒ½**:
1. æå–ä¹¦åã€ä½œè€…ã€æ ‡ç­¾
2. **LLMè¿‡æ»¤ç®€ä»‹**ï¼ˆå»é™¤å°é¢é“¾æ¥ã€"åˆæœ‰ä¹¦å"ã€åˆ†éš”ç¬¦ç­‰ï¼‰
3. è¾“å‡ºçº¯å‡€ç®€ä»‹

**æ‰§è¡Œæ–¹å¼**:
```python
from src.tools.novel_chapter_processor import MetadataExtractor

extractor = MetadataExtractor(use_llm=True)
metadata = extractor.execute(novel_text)
```

**è¾“å‡º**:
- `novel/chpt_0000_ç®€ä»‹.md` âœ… çº¯å‡€ç®€ä»‹
- `metadata.json` ï¼ˆä¹¦åã€ä½œè€…ã€æ ‡ç­¾ï¼‰

**ç¤ºä¾‹è¾“å‡º**:
```markdown
# åºåˆ—å…¬è·¯æ±‚ç”Ÿï¼šæˆ‘åœ¨æœ«æ—¥å‡çº§ç‰©èµ„

## ç®€ä»‹

è¯¡å¼‚é™ä¸´ï¼ŒåŸå¸‚æˆäº†äººç±»ç¦åŒºã€‚
äººä»¬åªèƒ½ä¾é åºåˆ—è¶…å‡¡ä¸åœçš„è¿å¾™ï¼Œå®šå±…ç”Ÿæ´»æ–¹å¼å˜æˆäº†è¿å¾™ç”Ÿæ´»æ–¹å¼ã€‚

åœ¨è¿å¾™çš„è¿‡ç¨‹ä¹‹ä¸­ï¼Œé™ˆé‡è§‰é†’äº†å‡çº§ç³»ç»Ÿã€‚
ç”Ÿé”ˆçš„è‡ªè¡Œè½¦åœ¨ä»–æ‰‹ä¸­èœ•å˜ä¸ºè£…ç”²æˆ˜è½¦ã€‚
ç ´æ—§å¸ç¯·è¿›åŒ–æˆç§»åŠ¨å ¡å’ã€‚
...
```

**âš ï¸ å¸¸è§é”™è¯¯**:
- âŒ ä½¿ç”¨ç®€å•æ­£åˆ™æå– `content[:first_chapter.start()]`
- âœ… å¿…é¡»ä½¿ç”¨ `MetadataExtractor(use_llm=True)`

---

### Step 3: åŠŸèƒ½æ®µåˆ†æï¼ˆæ ¸å¿ƒæ­¥éª¤ï¼‰

**å·¥å…·**: `NovelChapterAnalyzer()`

**æ–‡ä»¶**: `src/tools/novel_chapter_analyzer.py`

**æ¨¡å‹**: **DeepSeek R1**ï¼ˆ`deepseek-reasoner`ï¼‰âœ…

**åŠŸèƒ½**:
1. **LLMé©±åŠ¨çš„è¯­ä¹‰åˆ†æ®µ**ï¼ˆä¸æ˜¯è§„åˆ™åˆ†æ®µï¼‰
2. å¤šç»´åº¦æ ‡ç­¾æå–ï¼š
   - å™äº‹åŠŸèƒ½ï¼ˆæ•…äº‹æ¨è¿›ã€æ ¸å¿ƒè®¾å®šã€å…³é”®é“å…·ç­‰ï¼‰
   - å™äº‹ç»“æ„ï¼ˆé’©å­ã€ä¼ç¬”ã€å›åº”ä¼ç¬”ç­‰ï¼‰
   - è§’è‰²å…³ç³»ï¼ˆäººç‰©å¡‘é€ ã€å¯¹ç«‹å…³ç³»ç­‰ï¼‰
   - æµ“ç¼©ä¼˜å…ˆçº§ï¼ˆP0-éª¨æ¶ã€P1-è¡€è‚‰ã€P2-çš®è‚¤ï¼‰
3. æµ“ç¼©å»ºè®®ï¼ˆä¿ç•™ä»€ä¹ˆã€åˆ é™¤ä»€ä¹ˆï¼‰
4. ç« èŠ‚çº§æ‘˜è¦å’Œæ´å¯Ÿ

**æ‰§è¡Œæ–¹å¼**:
```python
import re
from src.tools.novel_chapter_analyzer import NovelChapterAnalyzer
from src.core.artifact_manager import ArtifactManager

# 1. è¯»å–åŸå§‹å°è¯´
with open('raw/novel.txt', 'r', encoding='utf-8') as f:
    novel_text = f.read()

# 2. è¯†åˆ«ç« èŠ‚ï¼ˆä» raw/novel.txt ç›´æ¥æå–ï¼‰
chapter_pattern = r'===\s*ç¬¬\s*(\d+)\s*ç« \s*(.*)===\s*\n'
matches = list(re.finditer(chapter_pattern, novel_text))

# 3. åˆå§‹åŒ–åˆ†æå™¨ï¼ˆä½¿ç”¨R1æ¨¡å‹ï¼‰
analyzer = NovelChapterAnalyzer()

# 4. é€ç« åˆ†æ
for i, match in enumerate(matches):
    chapter_number = int(match.group(1))
    chapter_title = match.group(2).strip()
    
    # æå–ç« èŠ‚å†…å®¹
    start_pos = match.end()
    end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(novel_text)
    chapter_content = novel_text[start_pos:end_pos].strip()
    
    # åˆ†æ
    analysis = analyzer.execute(
        chapter_content=chapter_content,
        chapter_number=chapter_number,
        chapter_title=chapter_title
    )
    
    # ä¿å­˜ï¼ˆä½¿ç”¨ArtifactManagerè¿›è¡Œç‰ˆæœ¬ç®¡ç†ï¼‰
    ArtifactManager.save_artifact(
        content=analysis.model_dump(mode='json'),
        artifact_type=f"chpt_{chapter_number:04d}_functional_analysis",
        project_id="æœ«å“¥è¶…å‡¡å…¬è·¯",
        base_dir=str(analysis_dir),
        extension="json"
    )
```

**å…³é”®ç‚¹**:
- âœ… **ç›´æ¥ä» `raw/novel.txt` è¯»å–**ï¼Œä¸éœ€è¦é¢„å…ˆç”Ÿæˆå•ç« æ–‡ä»¶
- âœ… ä½¿ç”¨æ­£åˆ™è¯†åˆ«ç« èŠ‚è¾¹ç•Œ
- âœ… é€ç« æå–å†…å®¹å¹¶åˆ†æ
- âœ… ä¸äº§ç”Ÿå†—ä½™çš„ä¸­é—´æ–‡ä»¶

**è¾“å‡º**:
1. **JSONæ–‡ä»¶**ï¼ˆæœºå™¨å¯è¯»ï¼‰:
   ```
   functional_analysis/
   â”œâ”€â”€ chpt_0001_functional_analysis_latest.json â† æœ€æ–°ç‰ˆæœ¬æŒ‡é’ˆ
   â”œâ”€â”€ chpt_0002_functional_analysis_latest.json
   â””â”€â”€ history/
       â”œâ”€â”€ chpt_0001_functional_analysis_v20260208_052641.json â† æ—¶é—´æˆ³ç‰ˆæœ¬
       â””â”€â”€ chpt_0002_functional_analysis_v20260208_053012.json
   ```

2. **Markdownæ–‡ä»¶**ï¼ˆäººç±»å¯è¯»ï¼‰:
   ```
   novel/
   â”œâ”€â”€ ç¬¬1ç« å®Œæ•´åˆ†æ®µåˆ†æ.md
   â”œâ”€â”€ ç¬¬2ç« å®Œæ•´åˆ†æ®µåˆ†æ.md
   â””â”€â”€ ...
   ```
   
   **âš ï¸ æ³¨æ„**: Markdownæ–‡ä»¶è¾“å‡ºåˆ° `novel/` ç›®å½•ï¼ŒJSONæ–‡ä»¶è¾“å‡ºåˆ° `novel/functional_analysis/` ç›®å½•

**JSONæ•°æ®ç»“æ„**:
```json
{
  "chapter_id": "chpt_001",
  "chapter_number": 1,
  "chapter_title": "è½¦é˜Ÿç¬¬ä¸€é“å¾‹",
  "segments": [
    {
      "segment_id": "func_seg_chpt_001_01",
      "title": "æ®µè½1ï¼šå¼€ç¯‡é’©å­ï¼ˆå¹¿æ’­ï¼‰",
      "content": "åŸæ–‡å†…å®¹...",
      "tags": {
        "narrative_function": ["æ•…äº‹æ¨è¿›", "æ ¸å¿ƒæ•…äº‹è®¾å®š(é¦–æ¬¡)"],
        "structure": ["é’©å­-æ‚¬å¿µåˆ¶é€ "],
        "character": ["äººç‰©å¡‘é€ -é™ˆé‡"],
        "priority": "P0-éª¨æ¶",
        "location": "è½¦é˜Ÿ",
        "time": "2030å¹´10æœˆ13æ—¥ä¸Šåˆ"
      },
      "metadata": {
        "word_count": 185,
        "contains_first_appearance": true,
        "repetition_items": ["ä¸è¦å‰å¾€"],
        "foreshadowing": {
          "type": "åŸ‹è®¾",
          "content": "çº¢æœˆã€å½±å­ã€æ­»è€…å¤æ´»è§„åˆ™",
          "reference": null
        }
      },
      "condensation_suggestion": "ä¿ç•™ï¼šæ—¶é—´ã€ä¸Šæ²ªæ²¦é™·ã€ä¸‰æ¡ç”Ÿå­˜è§„åˆ™..."
    }
  ],
  "chapter_summary": {
    "total_segments": 11,
    "p0_count": 4,
    "p1_count": 5,
    "p2_count": 2,
    "key_events": ["ä¸Šæ²ªæ²¦é™·", "ç³»ç»Ÿè§‰é†’", "å‡çº§å†³å®š"],
    "foreshadowing_planted": ["æ‰é˜Ÿå¿…æ­»"],
    "foreshadowing_paid_off": []
  },
  "structure_insight": {
    "narrative_rhythm": "å‰æ…¢åå¿«ï¼Œç¬¬9æ®µè½¬æŠ˜",
    "emotional_arc": "ç»æœ›â†’æƒŠå–œâ†’å¸Œæœ›",
    "turning_points": ["ç³»ç»Ÿè§‰é†’ï¼ˆæ®µè½9ï¼‰"]
  },
  "analyzed_at": "2026-02-08T05:26:41.826Z",
  "version": "20260208_052641"
}
```

**Markdownæ ¼å¼ç¤ºä¾‹**:
```markdown
# ç¬¬1ç«  - è½¦é˜Ÿç¬¬ä¸€é“å¾‹

**åŠŸèƒ½æ®µæ•°**: 11
**P0æ®µè½**: 4
**P1æ®µè½**: 5
**P2æ®µè½**: 2

---

## æ®µè½1ï¼šå¼€ç¯‡é’©å­ï¼ˆå¹¿æ’­ï¼‰

**ID**: `func_seg_chpt_001_01`

**å™äº‹åŠŸèƒ½**: æ•…äº‹æ¨è¿›, æ ¸å¿ƒæ•…äº‹è®¾å®š(é¦–æ¬¡)
**å™äº‹ç»“æ„**: é’©å­-æ‚¬å¿µåˆ¶é€ 
**ä¼˜å…ˆçº§**: P0-éª¨æ¶
**åœ°ç‚¹**: è½¦é˜Ÿ
**æ—¶é—´**: 2030å¹´10æœˆ13æ—¥ä¸Šåˆ

### ğŸ“„ å†…å®¹

"æ»‹æ»‹â€¦â€¦ç°åœ¨çš„æ—¶é—´æ˜¯2030å¹´10æœˆ13æ—¥ä¸Šåˆ10:23ã€‚"
...

### ğŸ’¡ æµ“ç¼©å»ºè®®

ä¿ç•™ï¼šæ—¶é—´ã€ä¸Šæ²ªæ²¦é™·ã€ä¸‰æ¡ç”Ÿå­˜è§„åˆ™...
åˆ é™¤ï¼šå¹¿æ’­çš„æˆå‰§æ€§æªè¾...
```

---

## ğŸ”§ ç‰ˆæœ¬ç®¡ç†è§„èŒƒ

### ç­–ç•¥ï¼šLatest Pointer + æ—¶é—´æˆ³ç‰ˆæœ¬

**ä¸»ç›®å½•**ï¼ˆåªæœ‰ `_latest.json`ï¼‰:
```
functional_analysis/
â”œâ”€â”€ chpt_0001_functional_analysis_latest.json  â† æŒ‡å‘æœ€æ–°ç‰ˆæœ¬
â”œâ”€â”€ chpt_0002_functional_analysis_latest.json
â””â”€â”€ ...
```

**history/ ç›®å½•**ï¼ˆæ‰€æœ‰å†å²ç‰ˆæœ¬ï¼‰:
```
functional_analysis/history/
â”œâ”€â”€ chpt_0001_functional_analysis_v20260208_052641.json
â”œâ”€â”€ chpt_0001_functional_analysis_v20260208_043012.json (æ—§ç‰ˆæœ¬)
â””â”€â”€ ...
```

**å®ç°å·¥å…·**: `src/core/artifact_manager.py`

```python
# âœ… æ­£ç¡®ç”¨æ³•
ArtifactManager.save_artifact(
    content=analysis_dict,
    artifact_type="chpt_0001_functional_analysis",
    project_id="æœ«å“¥è¶…å‡¡å…¬è·¯",
    base_dir=str(analysis_dir),
    extension="json"
)

# âŒ é”™è¯¯ï¼šä¸è¦è‡ªå·±å®ç°ç‰ˆæœ¬ç®¡ç†ï¼
```

---

## ğŸš¨ å¸¸è§é”™è¯¯ä¸é¿å…æ–¹æ³•

### é”™è¯¯1ï¼šä½¿ç”¨V3è€Œä¸æ˜¯R1

**ç—‡çŠ¶**: åˆ†æ®µè¿‡åº¦èšåˆï¼ˆæŠŠ3æ®µåˆæˆ1æ®µï¼‰

**åŸå› **:
```python
# âŒ é”™è¯¯é…ç½®
primary_model: str = "deepseek-chat"  # V3
```

**ä¿®å¤**:
```python
# âœ… æ­£ç¡®é…ç½®
primary_model: str = "deepseek-reasoner"  # R1
```

### é”™è¯¯2ï¼šç®€ä»‹æœªæ¸…ç†

**ç—‡çŠ¶**: ç®€ä»‹åŒ…å«"åˆæœ‰ä¹¦å"ã€å°é¢é“¾æ¥ã€åˆ†éš”ç¬¦

**åŸå› **:
```python
# âŒ é”™è¯¯ï¼šä½¿ç”¨æ­£åˆ™
intro = content[:first_chapter.start()].strip()
```

**ä¿®å¤**:
```python
# âœ… æ­£ç¡®ï¼šä½¿ç”¨MetadataExtractor
extractor = MetadataExtractor(use_llm=True)
metadata = extractor.execute(novel_text)
intro = metadata['novel']['introduction']
```

### é”™è¯¯3ï¼šè‡ªå®šä¹‰ç‰ˆæœ¬ç®¡ç†

**ç—‡çŠ¶**: ä¸»ç›®å½•æœ‰ `_vXXXXXX.json` æ–‡ä»¶ï¼Œæ²¡æœ‰ `history/` ç›®å½•

**åŸå› **:
```python
# âŒ é”™è¯¯ï¼šè‡ªå·±å®ç°
def save_with_version(...):
    versioned_file = f"chpt_{num}_v{timestamp}.json"
    latest_file = f"chpt_{num}_latest.json"
    # ä¿å­˜åˆ°åŒä¸€ç›®å½•
```

**ä¿®å¤**:
```python
# âœ… æ­£ç¡®ï¼šä½¿ç”¨ArtifactManager
ArtifactManager.save_artifact(...)
```

### é”™è¯¯4ï¼šä½¿ç”¨åºŸå¼ƒå·¥å…·

**åºŸå¼ƒå·¥å…·**:
- âŒ `NovelSegmentationTool`ï¼ˆè§„åˆ™åˆ†æ®µï¼Œå·²å½’æ¡£ï¼‰
- âŒ `process_novel_v3.py`ï¼ˆé”™è¯¯å®ç°ï¼Œå·²åºŸå¼ƒï¼‰

**æ­£ç¡®å·¥å…·**:
- âœ… `NovelChapterAnalyzer`ï¼ˆLLMåˆ†æ®µï¼‰
- âœ… `process_novel_v3_refactored.py`ï¼ˆæˆ–é‡å‘½åä¸º `process_novel_v3.py`ï¼‰

---

## ğŸ“Š è´¨é‡éªŒè¯æ¸…å•

### ç®€ä»‹æ£€æŸ¥

```python
# è¯»å–ç®€ä»‹
with open('novel/chpt_0000_ç®€ä»‹.md', 'r') as f:
    intro = f.read()

# éªŒè¯
assert 'åˆæœ‰ä¹¦å' not in intro  # âœ… ä¸åŒ…å«
assert 'ã€' not in intro        # âœ… ä¸åŒ…å«æ ‡ç­¾
assert 'Title:' not in intro    # âœ… ä¸åŒ…å«å…ƒä¿¡æ¯
assert '[å°é¢:' not in intro    # âœ… ä¸åŒ…å«å°é¢
assert '====' not in intro      # âœ… ä¸åŒ…å«åˆ†éš”ç¬¦
```

### åˆ†æ®µæ£€æŸ¥

```python
# è¯»å–ç¬¬1ç« åˆ†æ
with open('functional_analysis/chpt_0001_functional_analysis_latest.json', 'r') as f:
    analysis = json.load(f)

# éªŒè¯
seg1 = analysis['segments'][0]
print(f"ç¬¬1æ®µå­—æ•°: {seg1['metadata']['word_count']}")

# ç¬¬1æ®µåº”è¯¥åªåŒ…å«å¹¿æ’­ï¼Œä¸åŒ…å«ä¸–ç•Œè§‚å’Œä¸»è§’è¡ŒåŠ¨
assert 'å‡ ä¸ªæœˆå‰' not in seg1['content']  # âœ… ä¸åº”è¯¥åœ¨ç¬¬1æ®µ
assert 'ä»æ±ŸåŸé€ƒå‡ºæ¥' not in seg1['content']  # âœ… ä¸åº”è¯¥åœ¨ç¬¬1æ®µ
```

### ç‰ˆæœ¬ç®¡ç†æ£€æŸ¥

```bash
# ä¸»ç›®å½•åº”è¯¥åªæœ‰ _latest.json
ls functional_analysis/*.json | grep -v latest
# è¾“å‡ºåº”è¯¥ä¸ºç©º âœ…

# history/ åº”è¯¥åŒ…å«æ‰€æœ‰ç‰ˆæœ¬
ls functional_analysis/history/*.json | wc -l
# è¾“å‡ºåº”è¯¥ > 0 âœ…
```

---

## ğŸ¯ å®Œæ•´æ‰§è¡Œè„šæœ¬

æ¨èä½¿ç”¨ï¼š`scripts/process_novel_v3_refactored.py`

**ç‰¹ç‚¹**:
- âœ… ä½¿ç”¨ `MetadataExtractor`ï¼ˆLLMè¿‡æ»¤ï¼‰
- âœ… ä½¿ç”¨ `NovelChapterProcessor`ï¼ˆç« èŠ‚æ‹†åˆ†ï¼‰
- âœ… ä½¿ç”¨ `NovelChapterAnalyzer`ï¼ˆåŠŸèƒ½åˆ†æï¼ŒR1æ¨¡å‹ï¼‰
- âœ… ä½¿ç”¨ `ArtifactManager`ï¼ˆç‰ˆæœ¬ç®¡ç†ï¼‰

**æ‰§è¡Œ**:
```bash
cd "/Users/sevenx/Documents/coding/AI-Narrated Recap Analyst"
python3 scripts/process_novel_v3_refactored.py
```

**å•ç« æµ‹è¯•**:
```bash
python3 scripts/test_refactored_process.py
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `docs/DEV_STANDARDS.md` - å·¥å…·åˆ—è¡¨å’Œæ¶æ„è§„èŒƒ
- `docs/architecture/logic_flows.md` - ç³»ç»Ÿæ¶æ„å’Œæ•°æ®æµ
- `docs/NOVEL_SEGMENTATION_METHODOLOGY.md` - åˆ†æ®µæ–¹æ³•è®º
- `src/prompts/novel_chapter_functional_analysis.yaml` - åˆ†æPrompt
- `src/core/artifact_manager.py` - ç‰ˆæœ¬ç®¡ç†å®ç°

---

**æœ€åæ›´æ–°**: 2026-02-08  
**ç»´æŠ¤è€…**: AI Assistant  
**ç‰ˆæœ¬**: v3.2ï¼ˆR1æ¨¡å‹ä¸ºä¸»ï¼‰
