"""
ScriptValidator - è„šæœ¬å¤„ç†è´¨é‡éªŒè¯å·¥å…·

éªŒè¯è„šæœ¬å¤„ç†çš„å„ä¸ªç¯èŠ‚è´¨é‡ï¼Œç”Ÿæˆè´¨é‡æŠ¥å‘Šã€‚
"""

import logging
from typing import List, Dict, Any
from datetime import datetime, timedelta
import re

from src.core.interfaces import BaseTool
from src.core.schemas_script import (
    SrtEntry,
    SrtTextExtractionResult,
    ScriptSegmentationResult,
    ScriptValidationReport,
    ScriptValidationIssue
)

logger = logging.getLogger(__name__)


class ScriptValidator(BaseTool):
    """
    è„šæœ¬å¤„ç†è´¨é‡éªŒè¯å·¥å…·
    
    èŒè´£ (Responsibility):
        éªŒè¯è„šæœ¬å¤„ç†çš„å„ä¸ªç¯èŠ‚è´¨é‡ï¼Œç¡®ä¿æ•°æ®å‡†ç¡®æ€§å’Œåˆç†æ€§ã€‚
    
    æ£€æŸ¥é¡¹:
        1. æ—¶é—´è½´è¿ç»­æ€§: æ£€æŸ¥æ—¶é—´è·³è·ƒã€é‡å 
        2. æ–‡æœ¬å®Œæ•´æ€§: éªŒè¯SRTè¦†ç›–ç‡
        3. åˆ†æ®µåˆç†æ€§: åˆ†æ®µæ•°é‡ã€æ®µè½é•¿åº¦
    
    æ¥å£ (Interface):
        è¾“å…¥:
            - srt_entries: List[SrtEntry]
            - text_extraction: SrtTextExtractionResult
            - segmentation: ScriptSegmentationResult
        
        è¾“å‡º:
            - ScriptValidationReport: éªŒè¯æŠ¥å‘Š
    """
    
    name = "script_validator"
    description = "éªŒè¯è„šæœ¬å¤„ç†è´¨é‡"
    
    def __init__(self):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        super().__init__()
        self.quality_weights = {
            "timeline": 0.3,      # æ—¶é—´è½´æƒé‡
            "text": 0.4,          # æ–‡æœ¬å®Œæ•´æ€§æƒé‡
            "segmentation": 0.3   # åˆ†æ®µåˆç†æ€§æƒé‡
        }
    
    def execute(
        self,
        srt_entries: List[SrtEntry],
        text_extraction: SrtTextExtractionResult = None,
        segmentation: ScriptSegmentationResult = None,
        episode_name: str = "ep01",
        **kwargs
    ) -> ScriptValidationReport:
        """
        æ‰§è¡Œè„šæœ¬è´¨é‡éªŒè¯
        
        Args:
            srt_entries: SRTæ¡ç›®åˆ—è¡¨
            text_extraction: æ–‡æœ¬æå–ç»“æœï¼ˆå¯é€‰ï¼‰
            segmentation: åˆ†æ®µç»“æœï¼ˆå¯é€‰ï¼‰
            episode_name: é›†æ•°åç§°
        
        Returns:
            ScriptValidationReport: éªŒè¯æŠ¥å‘Š
        """
        logger.info(f"ğŸ” å¼€å§‹éªŒè¯è„šæœ¬å¤„ç†è´¨é‡: {episode_name}")
        
        issues: List[ScriptValidationIssue] = []
        warnings: List[str] = []
        recommendations: List[str] = []
        
        # 1. æ—¶é—´è½´è¿ç»­æ€§æ£€æŸ¥
        timeline_check = self._check_timeline(srt_entries, issues, warnings)
        
        # 2. æ–‡æœ¬å®Œæ•´æ€§æ£€æŸ¥
        text_check = {}
        if text_extraction:
            text_check = self._check_text_completeness(
                srt_entries, text_extraction, issues, warnings
            )
        
        # 3. åˆ†æ®µåˆç†æ€§æ£€æŸ¥
        segmentation_check = {}
        if segmentation:
            segmentation_check = self._check_segmentation(
                segmentation, srt_entries, issues, warnings, recommendations
            )
        
        # è®¡ç®—æ€»ä½“è´¨é‡è¯„åˆ†
        quality_score = self._calculate_quality_score(
            timeline_check,
            text_check,
            segmentation_check
        )
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        statistics = self._generate_statistics(
            srt_entries, text_extraction, segmentation
        )
        
        # ç”ŸæˆæŠ¥å‘Š
        report = ScriptValidationReport(
            episode_name=episode_name,
            validation_time=datetime.now(),
            quality_score=quality_score,
            is_valid=quality_score >= 70.0,
            timeline_check=timeline_check,
            text_check=text_check,
            segmentation_check=segmentation_check,
            issues=issues,
            warnings=warnings,
            recommendations=recommendations,
            statistics=statistics
        )
        
        logger.info(f"âœ… éªŒè¯å®Œæˆ: è´¨é‡è¯„åˆ† {quality_score:.1f}/100")
        logger.info(f"   é—®é¢˜æ•°: {len(issues)}, è­¦å‘Šæ•°: {len(warnings)}")
        
        return report
    
    def _parse_time(self, time_str: str) -> timedelta:
        """è§£æSRTæ—¶é—´æ ¼å¼ä¸ºtimedelta"""
        # æ ¼å¼: HH:MM:SS,mmm
        parts = re.match(r'(\d+):(\d+):(\d+),(\d+)', time_str)
        if parts:
            hours, minutes, seconds, milliseconds = map(int, parts.groups())
            return timedelta(
                hours=hours,
                minutes=minutes,
                seconds=seconds,
                milliseconds=milliseconds
            )
        return timedelta(0)
    
    def _check_timeline(
        self,
        srt_entries: List[SrtEntry],
        issues: List[ScriptValidationIssue],
        warnings: List[str]
    ) -> Dict[str, Any]:
        """æ£€æŸ¥æ—¶é—´è½´è¿ç»­æ€§"""
        logger.info("   æ£€æŸ¥æ—¶é—´è½´è¿ç»­æ€§...")
        
        if not srt_entries:
            issues.append(ScriptValidationIssue(
                severity="error",
                category="timeline",
                description="æœªæ£€æµ‹åˆ°ä»»ä½•SRTæ¡ç›®",
                recommendation="æ£€æŸ¥SRTæ–‡ä»¶æ ¼å¼"
            ))
            return {"passed": False, "total_entries": 0}
        
        gaps = []
        overlaps = []
        
        for i in range(len(srt_entries) - 1):
            current = srt_entries[i]
            next_entry = srt_entries[i + 1]
            
            current_end = self._parse_time(current.end_time)
            next_start = self._parse_time(next_entry.start_time)
            
            # æ£€æŸ¥é—´éš”ï¼ˆ>1ç§’ä¸ºå¼‚å¸¸ï¼‰
            gap = (next_start - current_end).total_seconds()
            if gap > 1.0:
                gaps.append({
                    "entries": f"{current.index}-{next_entry.index}",
                    "gap_seconds": round(gap, 2),
                    "time_range": f"{current.end_time} â†’ {next_entry.start_time}"
                })
            
            # æ£€æŸ¥é‡å 
            if next_start < current_end:
                overlaps.append({
                    "entries": f"{current.index}-{next_entry.index}",
                    "overlap_seconds": round((current_end - next_start).total_seconds(), 2),
                    "time_range": f"{next_entry.start_time} â†’ {current.end_time}"
                })
        
        # æ·»åŠ é—®é¢˜å’Œè­¦å‘Š
        if gaps:
            for gap_info in gaps[:3]:  # åªæŠ¥å‘Šå‰3ä¸ª
                issues.append(ScriptValidationIssue(
                    severity="warning",
                    category="timeline",
                    description=f"æ—¶é—´è½´é—´éš”: {gap_info['time_range']} ({gap_info['gap_seconds']}ç§’)",
                    location=f"srt_entry_{gap_info['entries']}",
                    recommendation="æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¼ºå¤±å­—å¹•"
                ))
            if len(gaps) > 3:
                warnings.append(f"å…±å‘ç° {len(gaps)} ä¸ªæ—¶é—´è½´é—´éš”")
        
        if overlaps:
            issues.append(ScriptValidationIssue(
                severity="error",
                category="timeline",
                description=f"æ—¶é—´è½´é‡å : {len(overlaps)} å¤„",
                recommendation="æ£€æŸ¥SRTæ–‡ä»¶æ—¶é—´æˆ³"
            ))
        
        passed = len(gaps) <= 5 and len(overlaps) == 0
        
        return {
            "passed": passed,
            "total_entries": len(srt_entries),
            "gaps": gaps,
            "overlaps": overlaps
        }
    
    def _check_text_completeness(
        self,
        srt_entries: List[SrtEntry],
        text_extraction: SrtTextExtractionResult,
        issues: List[ScriptValidationIssue],
        warnings: List[str]
    ) -> Dict[str, Any]:
        """æ£€æŸ¥æ–‡æœ¬å®Œæ•´æ€§"""
        logger.info("   æ£€æŸ¥æ–‡æœ¬å®Œæ•´æ€§...")
        
        # è®¡ç®—åŸå§‹SRTæ–‡æœ¬æ€»é•¿åº¦
        srt_text_total = sum(len(e.text) for e in srt_entries)
        
        # æå–åçš„æ–‡æœ¬é•¿åº¦
        extracted_text_length = len(text_extraction.processed_text)
        
        # è®¡ç®—è¦†ç›–ç‡
        coverage = extracted_text_length / srt_text_total if srt_text_total > 0 else 0
        
        missing_chars = srt_text_total - extracted_text_length
        
        passed = coverage >= 0.95
        
        if not passed:
            issues.append(ScriptValidationIssue(
                severity="warning",
                category="text",
                description=f"æ–‡æœ¬è¦†ç›–ç‡ä½: {coverage:.1%} (ç¼ºå¤± {missing_chars} å­—ç¬¦)",
                recommendation="æ£€æŸ¥æ–‡æœ¬æå–é€»è¾‘"
            ))
        
        return {
            "passed": passed,
            "coverage": round(coverage, 3),
            "srt_text_length": srt_text_total,
            "extracted_text_length": extracted_text_length,
            "missing_chars": missing_chars
        }
    
    def _check_segmentation(
        self,
        segmentation: ScriptSegmentationResult,
        srt_entries: List[SrtEntry],
        issues: List[ScriptValidationIssue],
        warnings: List[str],
        recommendations: List[str]
    ) -> Dict[str, Any]:
        """æ£€æŸ¥åˆ†æ®µåˆç†æ€§"""
        logger.info("   æ£€æŸ¥åˆ†æ®µåˆç†æ€§...")
        
        total_segments = segmentation.total_segments
        
        # æ£€æŸ¥åˆ†æ®µæ•°é‡ï¼ˆ5-20æ®µ/é›†ä¸ºæ­£å¸¸èŒƒå›´ï¼‰
        segments_ok = 5 <= total_segments <= 20
        
        if total_segments < 5:
            warnings.append(f"åˆ†æ®µæ•°é‡è¿‡å°‘: {total_segments}æ®µ (å»ºè®®5-20æ®µ)")
        elif total_segments > 20:
            warnings.append(f"åˆ†æ®µæ•°é‡è¿‡å¤š: {total_segments}æ®µ (å»ºè®®5-20æ®µ)")
        
        # è®¡ç®—å¹³å‡æ®µè½æ—¶é•¿
        segment_durations = []
        for seg in segmentation.segments:
            start = self._parse_time(seg.start_time)
            end = self._parse_time(seg.end_time)
            duration = (end - start).total_seconds()
            segment_durations.append(duration)
        
        avg_duration = sum(segment_durations) / len(segment_durations) if segment_durations else 0
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸çŸ­æˆ–å¼‚å¸¸é•¿çš„æ®µè½
        short_segments = [i for i, d in enumerate(segment_durations, 1) if d < 10]
        long_segments = [i for i, d in enumerate(segment_durations, 1) if d > 180]
        
        if short_segments:
            warnings.append(f"å­˜åœ¨è¿‡çŸ­æ®µè½(<10ç§’): æ®µè½ {short_segments[:3]}")
        
        if long_segments:
            warnings.append(f"å­˜åœ¨è¿‡é•¿æ®µè½(>3åˆ†é’Ÿ): æ®µè½ {long_segments[:3]}")
        
        # ç”Ÿæˆå»ºè®®
        if segments_ok and len(short_segments) == 0 and len(long_segments) == 0:
            recommendations.append("åˆ†æ®µè´¨é‡ä¼˜ç§€ï¼Œå»ºè®®ä¿æŒå½“å‰ç­–ç•¥")
        
        return {
            "passed": segments_ok,
            "total_segments": total_segments,
            "avg_duration_seconds": round(avg_duration, 1),
            "avg_sentence_count": segmentation.avg_sentence_count,
            "short_segments": short_segments,
            "long_segments": long_segments
        }
    
    def _calculate_quality_score(
        self,
        timeline_check: Dict,
        text_check: Dict,
        segmentation_check: Dict
    ) -> float:
        """è®¡ç®—æ€»ä½“è´¨é‡è¯„åˆ†"""
        scores = {}
        
        # æ—¶é—´è½´è¯„åˆ†
        scores["timeline"] = 100.0 if timeline_check.get("passed") else 70.0
        
        # æ–‡æœ¬å®Œæ•´æ€§è¯„åˆ†
        if text_check:
            coverage = text_check.get("coverage", 0)
            scores["text"] = coverage * 100
        else:
            scores["text"] = 100.0  # æ— æ–‡æœ¬æå–ç»“æœï¼Œä¸æ‰£åˆ†
        
        # åˆ†æ®µè¯„åˆ†
        if segmentation_check:
            scores["segmentation"] = 100.0 if segmentation_check.get("passed") else 80.0
        else:
            scores["segmentation"] = 100.0  # æ— åˆ†æ®µç»“æœï¼Œä¸æ‰£åˆ†
        
        # åŠ æƒå¹³å‡
        total_score = sum(
            scores[key] * weight 
            for key, weight in self.quality_weights.items()
        )
        
        return round(total_score, 1)
    
    def _generate_statistics(
        self,
        srt_entries: List[SrtEntry],
        text_extraction: SrtTextExtractionResult,
        segmentation: ScriptSegmentationResult
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_srt_entries": len(srt_entries),
        }
        
        if srt_entries:
            total_duration = self._parse_time(srt_entries[-1].end_time)
            stats["total_duration_seconds"] = total_duration.total_seconds()
            stats["total_duration_formatted"] = str(total_duration)
        
        if text_extraction:
            stats["text_length"] = len(text_extraction.processed_text)
        
        if segmentation:
            stats["total_segments"] = segmentation.total_segments
            stats["avg_sentence_count"] = segmentation.avg_sentence_count
        
        return stats
