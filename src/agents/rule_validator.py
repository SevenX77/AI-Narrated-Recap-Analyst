"""
è§„åˆ™éªŒè¯Agent

éªŒè¯æå–çš„è§„åˆ™èƒ½å¦å‡†ç¡®é¢„æµ‹Ground Truthé¡¹ç›®çš„çƒ­åº¦
"""

import json
from typing import Dict, Any, List
from datetime import datetime

from src.core.schemas_feedback import RuleBook, ValidationResult
from src.core.interfaces import BaseAgent
from src.utils.logger import logger
from src.utils.prompt_loader import load_prompts


class RuleValidatorAgent(BaseAgent):
    """
    è§„åˆ™éªŒè¯Agent
    
    è´Ÿè´£éªŒè¯è§„åˆ™åº“çš„æœ‰æ•ˆæ€§ï¼š
    1. ç”¨è§„åˆ™å¯¹GTé¡¹ç›®è¯„åˆ†
    2. æ¯”è¾ƒè¯„åˆ†ä¸å®é™…çƒ­åº¦çš„ç›¸å…³æ€§
    3. åˆ†æå„ç»´åº¦çš„é‡è¦æ€§
    4. æå‡ºä¼˜åŒ–å»ºè®®
    """
    
    def __init__(self, client: Any, model_name: str = "deepseek-chat"):
        """
        åˆå§‹åŒ–è§„åˆ™éªŒè¯Agent
        
        Args:
            client: LLMå®¢æˆ·ç«¯
            model_name: æ¨¡å‹åç§°
        """
        super().__init__(context={})
        self.client = client
        self.model_name = model_name
        self.prompts = load_prompts("rule_validation")
    
    def validate_rulebook(
        self,
        rulebook: RuleBook,
        gt_projects_data: Dict[str, Dict[str, Any]],
        actual_heat_scores: Dict[str, float]
    ) -> ValidationResult:
        """
        éªŒè¯è§„åˆ™åº“
        
        Args:
            rulebook: å¾…éªŒè¯çš„è§„åˆ™åº“
            gt_projects_data: GTé¡¹ç›®æ•°æ®
            actual_heat_scores: å®é™…çƒ­åº¦å€¼
            
        Returns:
            ValidationResult: éªŒè¯ç»“æœ
        """
        logger.info(f"ğŸ” å¼€å§‹éªŒè¯è§„åˆ™åº“ {rulebook.version}...")
        
        # å‡†å¤‡æ•°æ®
        rulebook_json = rulebook.model_dump_json(indent=2)
        projects_summary = self._prepare_projects_summary(gt_projects_data)
        heat_scores_json = json.dumps(actual_heat_scores, indent=2, ensure_ascii=False)
        
        system_prompt = self.prompts["validate_rules"]["system"]
        user_prompt = self.prompts["validate_rules"]["user"].format(
            rulebook=rulebook_json,
            gt_projects_data=projects_summary,
            actual_heat_scores=heat_scores_json
        )
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            result_json = response.choices[0].message.content
            data = json.loads(result_json)
            
            # æ„å»ºValidationResult
            validation_result = ValidationResult(
                rulebook_version=rulebook.version,
                validated_at=datetime.now().isoformat(),
                project_scores=data.get("project_scores", {}),
                correlation=data.get("correlation", 0.0),
                is_valid=data.get("is_valid", False),
                dimension_importance=data.get("dimension_importance", {}),
                optimization_suggestions=data.get("optimization_suggestions", []),
                details=data
            )
            
            logger.info(f"âœ… è§„åˆ™éªŒè¯å®Œæˆ:")
            logger.info(f"   - ç›¸å…³æ€§: {validation_result.correlation:.2f}")
            logger.info(f"   - æ˜¯å¦æœ‰æ•ˆ: {validation_result.is_valid}")
            logger.info(f"   - ä¼˜åŒ–å»ºè®®æ•°: {len(validation_result.optimization_suggestions)}")
            
            return validation_result
            
        except Exception as e:
            logger.error(f"âŒ è§„åˆ™éªŒè¯å¤±è´¥: {e}")
            raise
    
    def score_content_by_rules(
        self,
        rulebook: RuleBook,
        content_data: Dict[str, Any],
        content_type: str
    ) -> Dict[str, Any]:
        """
        ç”¨è§„åˆ™å¯¹å†…å®¹è¯„åˆ†
        
        Args:
            rulebook: è§„åˆ™åº“
            content_data: å†…å®¹æ•°æ®
            content_type: å†…å®¹ç±»å‹ (hook/ep01/ep02_plus)
            
        Returns:
            è¯„åˆ†ç»“æœ
        """
        logger.info(f"ğŸ“Š ä½¿ç”¨è§„åˆ™å¯¹ {content_type} å†…å®¹è¯„åˆ†...")
        
        rulebook_json = rulebook.model_dump_json(indent=2)
        content_json = json.dumps(content_data, indent=2, ensure_ascii=False)
        
        system_prompt = self.prompts["score_content_by_rules"]["system"]
        user_prompt = self.prompts["score_content_by_rules"]["user"].format(
            rulebook=rulebook_json,
            content_data=content_json,
            content_type=content_type
        )
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            
            result_json = response.choices[0].message.content
            data = json.loads(result_json)
            
            logger.info(f"âœ… è¯„åˆ†å®Œæˆ: {data.get('total_score')}/{data.get('max_score')}")
            
            return data
            
        except Exception as e:
            logger.error(f"âŒ è¯„åˆ†å¤±è´¥: {e}")
            raise
    
    def _prepare_projects_summary(
        self,
        projects_data: Dict[str, Dict[str, Any]]
    ) -> str:
        """
        å‡†å¤‡é¡¹ç›®æ•°æ®æ‘˜è¦
        
        Args:
            projects_data: é¡¹ç›®æ•°æ®
            
        Returns:
            æ ¼å¼åŒ–çš„æ‘˜è¦å­—ç¬¦ä¸²
        """
        summary_parts = []
        
        for project_id, data in projects_data.items():
            summary = f"""
ã€{project_id}ã€‘
- SRTå†…å®¹: {data.get('srt_content', '')[:300]}...
- äº‹ä»¶æ•°: {len(data.get('events', []))}
- Hookä¿¡æ¯: {json.dumps(data.get('hook_info', {}), ensure_ascii=False)}
"""
            summary_parts.append(summary)
        
        return "\n".join(summary_parts)
    
    async def process(self, **kwargs) -> Any:
        """
        BaseAgentæ¥å£å®ç°
        
        Args:
            **kwargs: å¯èƒ½åŒ…å« rulebook, gt_projects_data, actual_heat_scores
            
        Returns:
            ValidationResultæˆ–è¯„åˆ†ç»“æœ
        """
        rulebook = kwargs.get('rulebook')
        gt_projects_data = kwargs.get('gt_projects_data')
        actual_heat_scores = kwargs.get('actual_heat_scores')
        content_data = kwargs.get('content_data')
        content_type = kwargs.get('content_type')
        
        if rulebook and gt_projects_data and actual_heat_scores:
            return self.validate_rulebook(rulebook, gt_projects_data, actual_heat_scores)
        elif rulebook and content_data and content_type:
            return self.score_content_by_rules(rulebook, content_data, content_type)
        
        raise ValueError("å‚æ•°ä¸è¶³ï¼Œæ— æ³•æ‰§è¡ŒéªŒè¯æˆ–è¯„åˆ†")
