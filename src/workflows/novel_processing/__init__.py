import logging
import time
from pathlib import Path
from typing import Optional

from src.core.schemas_novel import (
    NovelProcessingConfig,
    NovelProcessingResult,
    ChapterProcessingError
)
from src.workflows import report_generator
from src.workflows.novel_processing.base import NovelProcessingWorkflowBase

# Import Steps
from src.workflows.novel_processing.steps.import_step import step1_import_novel
from src.workflows.novel_processing.steps.metadata_step import step2_extract_metadata
from src.workflows.novel_processing.steps.chapter_step import step3_detect_chapters
from src.workflows.novel_processing.steps.segmentation_step import step4_segment_chapters
from src.workflows.novel_processing.steps.annotation_step import step5_annotate_chapters
from src.workflows.novel_processing.steps.system_step import step6_analyze_system, step7_track_system
from src.workflows.novel_processing.steps.validation_step import step8_validate_quality

logger = logging.getLogger(__name__)

class NovelProcessingWorkflow(NovelProcessingWorkflowBase):
    """
    å°è¯´å¤„ç†å·¥ä½œæµ
    
    å®Œæ•´çš„å°è¯´å¤„ç†pipelineï¼Œæ”¯æŒå¹¶è¡Œå¤„ç†ã€é”™è¯¯æ¢å¤å’Œæ–­ç‚¹ç»­ä¼ ã€‚
    
    Attributes:
        name (str): å·¥ä½œæµåç§°
        config (NovelProcessingConfig): å·¥ä½œæµé…ç½®
        project_name (str): é¡¹ç›®åç§°
        processing_dir (str): ä¸­é—´ç»“æœä¿å­˜ç›®å½•
    """
    
    async def run(
        self,
        novel_path: str,
        project_name: str,
        config: Optional[NovelProcessingConfig] = None,
        resume_from_step: Optional[int] = None
    ) -> NovelProcessingResult:
        """
        æ‰§è¡Œå®Œæ•´çš„å°è¯´å¤„ç†æµç¨‹
        """
        self.start_time = time.time()
        workflow_config = config or NovelProcessingConfig()
        
        logger.info("=" * 80)
        logger.info(f"ğŸš€ å¯åŠ¨ NovelProcessingWorkflow")
        logger.info(f"ğŸ“ é¡¹ç›®: {project_name}")
        logger.info(f"ğŸ“– å°è¯´: {novel_path}")
        logger.info(f"âš™ï¸  é…ç½®: å¹¶è¡Œ={workflow_config.enable_parallel}, "
                   f"å¹¶å‘æ•°={workflow_config.max_concurrent_chapters}, "
                   f"ç« èŠ‚èŒƒå›´={workflow_config.chapter_range}")
        logger.info("=" * 80)
        
        # åˆ›å»ºå¤„ç†ç›®å½•
        processing_dir = self._setup_processing_directory(project_name)
        
        # åˆå§‹åŒ–ç»“æœå¯¹è±¡
        result = NovelProcessingResult(
            project_name=project_name,
            import_result=None,  # å°†åœ¨åç»­æ­¥éª¤å¡«å……
            metadata=None,
            chapters=[],
            intermediate_results_dir=processing_dir
        )
        
        try:
            # Step 1: å°è¯´å¯¼å…¥ä¸è§„èŒƒåŒ–
            if not resume_from_step or resume_from_step <= 1:
                result.import_result = await step1_import_novel(
                    self, novel_path, project_name, processing_dir
                )
                result.completed_steps.append(1)
                if workflow_config.output_markdown_reports:
                    report_generator.output_step1_report(result.import_result, processing_dir)
            
            # Step 2: æå–å°è¯´å…ƒæ•°æ®
            if not resume_from_step or resume_from_step <= 2:
                result.metadata = await step2_extract_metadata(
                    self, result.import_result.saved_path, processing_dir
                )
                result.completed_steps.append(2)
                
                # ç”Ÿæˆå…ƒæ•°æ®Markdownåˆ°novelæ–‡ä»¶å¤¹
                report_generator.generate_metadata_markdown(result.metadata, project_name)
                
                if workflow_config.output_markdown_reports:
                    report_generator.output_step2_report(result.metadata, processing_dir)
            
            # Step 3: æ£€æµ‹ç« èŠ‚è¾¹ç•Œ
            if not resume_from_step or resume_from_step <= 3:
                result.chapters = await step3_detect_chapters(
                    self,
                    result.import_result.saved_path, 
                    workflow_config.chapter_range,
                    processing_dir
                )
                result.completed_steps.append(3)
                
                # ç”Ÿæˆç« èŠ‚ç´¢å¼•Markdownåˆ°novelæ–‡ä»¶å¤¹
                report_generator.generate_chapters_index_markdown(result.chapters, project_name)
                
                if workflow_config.output_markdown_reports:
                    report_generator.output_step3_report(result.chapters, processing_dir)
            
            # Step 4: ç« èŠ‚å¹¶è¡Œåˆ†æ®µ
            if not resume_from_step or resume_from_step <= 4:
                result.segmentation_results = await step4_segment_chapters(
                    self,
                    result.import_result.saved_path,
                    result.chapters,
                    workflow_config,
                    processing_dir
                )
                result.completed_steps.append(4)
                
                # ç”Ÿæˆæ¯ç« åˆ†æ®µMarkdownåˆ°novelæ–‡ä»¶å¤¹
                report_generator.generate_chapter_markdown(
                    result.segmentation_results,
                    result.chapters,
                    project_name
                )
                
                if workflow_config.output_markdown_reports:
                    report_generator.output_step4_report(result.segmentation_results, processing_dir)
            
            # Step 5: ç« èŠ‚å¹¶è¡Œæ ‡æ³¨
            if not resume_from_step or resume_from_step <= 5:
                result.annotation_results = await step5_annotate_chapters(
                    self,
                    result.segmentation_results,
                    workflow_config,
                    processing_dir
                )
                result.completed_steps.append(5)
                if workflow_config.output_markdown_reports:
                    report_generator.output_step5_report(result.annotation_results, processing_dir)
            
            # Step 6-7: ç³»ç»Ÿåˆ†æä¸è¿½è¸ªï¼ˆå¯é€‰ï¼‰
            if workflow_config.enable_system_analysis:
                if not resume_from_step or resume_from_step <= 6:
                    result.system_catalog = await step6_analyze_system(
                        self,
                        result.import_result.saved_path,
                        result.chapters,
                        processing_dir
                    )
                    result.completed_steps.append(6)
                
                if not resume_from_step or resume_from_step <= 7:
                    system_results = await step7_track_system(
                        self,
                        result.annotation_results,
                        result.segmentation_results,
                        result.system_catalog,
                        workflow_config,
                        processing_dir
                    )
                    result.system_updates = system_results["updates"]
                    result.system_tracking = system_results["tracking"]
                    result.completed_steps.append(7)
                    
                    if workflow_config.output_markdown_reports:
                        report_generator.output_step67_report(
                            result.system_catalog,
                            result.system_updates,
                            result.system_tracking,
                            processing_dir
                        )
            
            # Step 8: è´¨é‡éªŒè¯
            if not resume_from_step or resume_from_step <= 8:
                result.validation_report = await step8_validate_quality(
                    self,
                    result,
                    processing_dir
                )
                result.completed_steps.append(8)
                if workflow_config.output_markdown_reports:
                    report_generator.output_step8_report(result.validation_report, processing_dir)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            result.processing_time = time.time() - self.start_time
            result.llm_calls_count = self.llm_calls_count
            result.total_cost = self.total_cost
            result.processing_stats = self._calculate_stats(result)
            
            # ä¿å­˜æœ€ç»ˆç»“æœ
            self._save_final_result(result, processing_dir)
            
            # ç”Ÿæˆå®Œæ•´çš„HTMLå¯è§†åŒ–
            novel_title = result.metadata.title if result.metadata else Path(novel_path).stem
            report_generator.generate_comprehensive_html(result, project_name, novel_title)
            
            # è¾“å‡ºLLMä½¿ç”¨ç»Ÿè®¡
            llm_stats = self.llm_manager.get_all_stats()
            if llm_stats:
                logger.info("\nğŸ“Š LLMä½¿ç”¨ç»Ÿè®¡:")
                for model, stats in llm_stats.items():
                    logger.info(f"  {model}:")
                    logger.info(f"    - è¯·æ±‚æ•°(æœ€è¿‘1åˆ†é’Ÿ): {stats['requests_last_minute']}")
                    logger.info(f"    - Tokens(æœ€è¿‘1åˆ†é’Ÿ): {stats['tokens_last_minute']}")
            
            logger.info("=" * 80)
            logger.info(f"âœ… NovelProcessingWorkflow æ‰§è¡Œå®Œæˆ")
            logger.info(f"â±ï¸  æ€»è€—æ—¶: {result.processing_time:.1f}ç§’ ({result.processing_time/60:.1f}åˆ†é’Ÿ)")
            logger.info(f"ğŸ“Š LLMè°ƒç”¨: {result.llm_calls_count}æ¬¡")
            logger.info(f"ğŸ’° æ€»æˆæœ¬: ${result.total_cost:.4f}")
            logger.info(f"ğŸ“ˆ æˆåŠŸå¤„ç†: {len(result.segmentation_results)}/{len(result.chapters)} ç« èŠ‚")
            if result.errors:
                logger.warning(f"âš ï¸  é”™è¯¯æ•°é‡: {len(result.errors)}")
            logger.info("=" * 80)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Workflowæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            result.errors.append(ChapterProcessingError(
                chapter_number=0,
                step="workflow",
                error_type=type(e).__name__,
                error_message=str(e)
            ))
            # ä¿å­˜é”™è¯¯çŠ¶æ€
            self._save_final_result(result, processing_dir)
            raise
