"""
Step Reports - å°è¯´å¤„ç†å·¥ä½œæµçš„æ­¥éª¤æŠ¥å‘Šç”Ÿæˆ

ç”Ÿæˆæ¯ä¸ªå¤„ç†æ­¥éª¤çš„è¯¦ç»†æŠ¥å‘Šï¼ˆSteps 1-8ï¼‰ã€‚

Author: AI-Narrated Recap Analyst Team
Created: 2026-02-13 (Refactored from report_generator.py)
"""

import logging
from pathlib import Path
from typing import Dict, List
from datetime import datetime

from src.core.schemas_novel import (
    NovelImportResult,
    NovelMetadata,
    ChapterInfo,
    ParagraphSegmentationResult,
    AnnotatedChapter,
    SystemCatalog,
    SystemUpdateResult,
    SystemTrackingResult,
    NovelValidationReport,
    ChapterProcessingError
)

logger = logging.getLogger(__name__)


def output_step1_report(import_result: NovelImportResult, processing_dir: str):
    """è¾“å‡ºStep 1æŠ¥å‘Š"""
    report_path = Path(processing_dir) / "reports" / "step1_import_report.md"
    
    content = f"""# Step 1: å°è¯´å¯¼å…¥æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **é¡¹ç›®åç§°**: {import_result.project_name}
- **åŸå§‹è·¯å¾„**: {import_result.original_path}
- **ä¿å­˜è·¯å¾„**: {import_result.saved_path}

## æ–‡ä»¶ä¿¡æ¯
- **ç¼–ç **: {import_result.encoding}
- **æ–‡ä»¶å¤§å°**: {import_result.file_size} å­—èŠ‚ ({import_result.file_size/1024:.2f} KB)
- **å­—ç¬¦æ•°**: {import_result.char_count}
- **è¡Œæ•°**: {import_result.line_count}
- **åŒ…å«BOM**: {'æ˜¯' if import_result.has_bom else 'å¦'}

## è§„èŒƒåŒ–æ“ä½œ
{chr(10).join(f'- {op}' for op in import_result.normalization_applied)}

---
*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    logger.info(f"ğŸ“„ Step 1 æŠ¥å‘Š: {report_path}")


def output_step2_report(metadata: NovelMetadata, processing_dir: str):
    """è¾“å‡ºStep 2æŠ¥å‘Š"""
    report_path = Path(processing_dir) / "reports" / "step2_metadata_report.md"
    
    content = f"""# Step 2: å°è¯´å…ƒæ•°æ®æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **ä¹¦å**: {metadata.title}
- **ä½œè€…**: {metadata.author}

## æ ‡ç­¾
{chr(10).join(f'- {tag}' for tag in metadata.tags)}

## ç®€ä»‹
{metadata.introduction}

---
*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    logger.info(f"ğŸ“„ Step 2 æŠ¥å‘Š: {report_path}")


def output_step3_report(chapters: List[ChapterInfo], processing_dir: str):
    """è¾“å‡ºStep 3æŠ¥å‘Š"""
    report_path = Path(processing_dir) / "reports" / "step3_chapters_report.md"
    
    content = f"""# Step 3: ç« èŠ‚æ£€æµ‹æŠ¥å‘Š

## æ¦‚è§ˆ
- **æ€»ç« èŠ‚æ•°**: {len(chapters)}
- **æ€»å­—æ•°**: {sum((ch.word_count or 0) for ch in chapters)}

## ç« èŠ‚åˆ—è¡¨

| ç« èŠ‚å· | æ ‡é¢˜ | å­—æ•° | èµ·å§‹è¡Œ | ç»“æŸè¡Œ |
|-------|------|------|--------|--------|
"""
    
    for ch in chapters:
        content += f"| {ch.number} | {ch.title} | {ch.word_count or 'N/A'} | {ch.start_line} | {ch.end_line or 'N/A'} |\n"
    
    content += f"""
---
*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    logger.info(f"ğŸ“„ Step 3 æŠ¥å‘Š: {report_path}")


def output_step4_report(
    segmentation_results: Dict[int, ParagraphSegmentationResult],
    processing_dir: str
):
    """è¾“å‡ºStep 4è´¨é‡åˆ†ææŠ¥å‘Šï¼ˆä¸¥æ ¼è¯„åˆ†ï¼‰"""
    report_path = Path(processing_dir) / "reports" / "step4_segmentation_quality.md"
    
    if not segmentation_results:
        return
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_paragraphs = sum(len(seg.paragraphs) for seg in segmentation_results.values())
    a_count = sum(sum(1 for p in seg.paragraphs if p.type == "A") for seg in segmentation_results.values())
    b_count = sum(sum(1 for p in seg.paragraphs if p.type == "B") for seg in segmentation_results.values())
    c_count = sum(sum(1 for p in seg.paragraphs if p.type == "C") for seg in segmentation_results.values())
    
    avg_para = total_paragraphs/len(segmentation_results)
    a_pct = a_count/total_paragraphs*100 if total_paragraphs else 0
    b_pct = b_count/total_paragraphs*100 if total_paragraphs else 0
    c_pct = c_count/total_paragraphs*100 if total_paragraphs else 0
    
    # è´¨é‡è¯„åˆ†ï¼ˆä¸¥æ ¼æ ‡å‡†ï¼‰
    quality_score = 100
    issues = []
    warnings = []
    
    # 1. ABCåˆ†å¸ƒæ£€æŸ¥
    if a_pct > 40:
        issues.append(f"Aç±»å æ¯”è¿‡é«˜({a_pct:.1f}%)ï¼Œå¯èƒ½å­˜åœ¨è¿‡åº¦è¯†åˆ«")
        quality_score -= 15
    elif a_pct < 3 and len(segmentation_results) <= 5:
        warnings.append(f"å¼€ç¯‡Aç±»å æ¯”åä½({a_pct:.1f}%)ï¼Œå¯èƒ½é—æ¼è®¾å®š")
        quality_score -= 5
    
    if b_pct < 50:
        issues.append(f"Bç±»å æ¯”è¿‡ä½({b_pct:.1f}%)ï¼Œäº‹ä»¶ä¸»çº¿ä¸æ˜æ˜¾")
        quality_score -= 15
    
    if c_pct > 20:
        issues.append(f"Cç±»å æ¯”è¿‡é«˜({c_pct:.1f}%)ï¼Œå¯èƒ½å­˜åœ¨è¯¯åˆ¤")
        quality_score -= 10
    
    # 2. åˆ†æ®µç²’åº¦æ£€æŸ¥
    abnormal_chapters = []
    for chapter_num, seg in segmentation_results.items():
        para_count = len(seg.paragraphs)
        if para_count < 3:
            abnormal_chapters.append(f"ç¬¬{chapter_num}ç« ä»…{para_count}æ®µï¼ˆåˆ†æ®µä¸è¶³ï¼‰")
            quality_score -= 5
        elif para_count > 25:
            abnormal_chapters.append(f"ç¬¬{chapter_num}ç« æœ‰{para_count}æ®µï¼ˆè¿‡åº¦åˆ†æ®µï¼‰")
            quality_score -= 3
    
    # 3. æ–‡æœ¬è¿˜åŸç‡æ£€æŸ¥
    restoration_issues = []
    for chapter_num, seg in segmentation_results.items():
        restoration_rate = seg.metadata.get("text_restoration_rate", 100)
        if restoration_rate < 95:
            restoration_issues.append(f"ç¬¬{chapter_num}ç« è¿˜åŸç‡{restoration_rate:.2f}%")
            quality_score -= 10
        elif restoration_rate < 99:
            warnings.append(f"ç¬¬{chapter_num}ç« è¿˜åŸç‡{restoration_rate:.2f}%")
            quality_score -= 2
    
    # ç¡®å®šç­‰çº§
    if quality_score >= 90:
        grade = "A ä¼˜ç§€"
    elif quality_score >= 80:
        grade = "B è‰¯å¥½"
    elif quality_score >= 70:
        grade = "C åŠæ ¼"
    elif quality_score >= 60:
        grade = "D å‹‰å¼º"
    else:
        grade = "F ä¸åˆæ ¼"
    
    # ç”ŸæˆæŠ¥å‘Š
    content = f"""# Step 4: ç« èŠ‚åˆ†æ®µè´¨é‡åˆ†æ â­

## ğŸ“Š è´¨é‡è¯„åˆ†

**{quality_score}/100 ({grade})**

---

## æ•´ä½“åˆ†æ®µç»Ÿè®¡

### æ•°é‡æŒ‡æ ‡
- **å¤„ç†ç« èŠ‚æ•°**: {len(segmentation_results)}
- **æ€»æ®µè½æ•°**: {total_paragraphs}
- **å¹³å‡æ®µè½/ç« **: {avg_para:.1f}

### ABCç±»å‹åˆ†å¸ƒ
- **Aç±»ï¼ˆè®¾å®šï¼‰**: {a_count}ä¸ª ({a_pct:.1f}%)
- **Bç±»ï¼ˆäº‹ä»¶ï¼‰**: {b_count}ä¸ª ({b_pct:.1f}%)
- **Cç±»ï¼ˆç³»ç»Ÿï¼‰**: {c_count}ä¸ª ({c_pct:.1f}%)

---

## ğŸ¯ åˆ†æ®µè´¨é‡åˆ†æ

### 1. ABCåˆ†å¸ƒåˆç†æ€§

"""
    
    if not issues and a_pct >= 3 and b_pct >= 50:
        content += "âœ… **é€šè¿‡**ï¼šABCåˆ†å¸ƒç¬¦åˆé¢„æœŸ\n"
    else:
        content += "âš ï¸ **å­˜åœ¨é—®é¢˜**ï¼š\n\n"
        for issue in issues:
            content += f"- ğŸ”´ {issue}\n"
        for warning in warnings:
            content += f"- ğŸŸ¡ {warning}\n"
    
    content += "\n### 2. å„ç« åˆ†æ®µè¯¦æƒ…\n\n| ç« èŠ‚å· | æ®µè½æ•° | Aç±» | Bç±» | Cç±» | è¯„ä»· |\n|-------|--------|-----|-----|-----|------|\n"
    
    for chapter_num in sorted(segmentation_results.keys()):
        seg = segmentation_results[chapter_num]
        para_count = len(seg.paragraphs)
        a = sum(1 for p in seg.paragraphs if p.type == "A")
        b = sum(1 for p in seg.paragraphs if p.type == "B")
        c = sum(1 for p in seg.paragraphs if p.type == "C")
        
        # è¯„ä»·
        if para_count < 3:
            eval_text = "âš ï¸ åˆ†æ®µä¸è¶³"
        elif para_count > 25:
            eval_text = "âš ï¸ è¿‡åº¦åˆ†æ®µ"
        elif a == 0 and chapter_num <= 5:
            eval_text = "âš ï¸ å¼€ç¯‡ç¼ºAç±»"
        else:
            eval_text = "âœ“"
        
        content += f"| {chapter_num} | {para_count} | {a} | {b} | {c} | {eval_text} |\n"
    
    content += f"""\n### 3. å¼‚å¸¸ç« èŠ‚\n\n"""
    
    if abnormal_chapters:
        for abnormal in abnormal_chapters:
            content += f"- ğŸ”´ {abnormal}\n"
    else:
        content += "âœ… æ— å¼‚å¸¸ç« èŠ‚\n"
    
    content += "\n### 4. æ–‡æœ¬è¿˜åŸç‡\n\n"
    
    if restoration_issues:
        content += "âš ï¸ **å­˜åœ¨è¿˜åŸé—®é¢˜**ï¼š\n\n"
        for issue in restoration_issues:
            content += f"- ğŸ”´ {issue}\n"
    else:
        content += "âœ… **æ— è¿˜åŸé—®é¢˜**ï¼ˆæ‰€æœ‰ç« èŠ‚è¿˜åŸç‡>99%ï¼‰\n"
    
    content += "\n---\n\n## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n### ä¼˜å…ˆçº§P0ï¼ˆå¿…é¡»æ”¹è¿›ï¼‰\n"
    
    p0_suggestions = []
    if restoration_issues:
        p0_suggestions.append("ä¿®æ­£æ–‡æœ¬è¿˜åŸç‡ä½çš„ç« èŠ‚")
    if a_pct > 40 or (a_pct < 3 and len(segmentation_results) <= 5):
        p0_suggestions.append(f"äººå·¥æŠ½æ£€Aç±»åˆ†ç±»å‡†ç¡®æ€§ï¼ˆå½“å‰{a_pct:.1f}%ï¼‰")
    
    if p0_suggestions:
        for i, sug in enumerate(p0_suggestions, 1):
            content += f"{i}. {sug}\n"
    else:
        content += "æ— \n"
    
    content += "\n### ä¼˜å…ˆçº§P1ï¼ˆå»ºè®®æ”¹è¿›ï¼‰\n"
    
    if abnormal_chapters:
        for i, abnormal in enumerate(abnormal_chapters[:3], 1):
            content += f"{i}. {abnormal}\n"
    else:
        content += "æ— \n"
    
    content += f"""\n---\n\n## âœ… æ€»ä½“è¯„ä»·\n\n**è´¨é‡ç­‰çº§ï¼š{grade}**\n\n"""
    
    if quality_score >= 90:
        content += "- åˆ†æ®µç²’åº¦ä¼˜ç§€\n- ABCåˆ†ç±»å‡†ç¡®\n- å¯ç›´æ¥ç”¨äºæ ‡æ³¨æ­¥éª¤\n"
    elif quality_score >= 80:
        content += "- åˆ†æ®µç²’åº¦è‰¯å¥½\n- å­˜åœ¨è½»å¾®é—®é¢˜\n- å»ºè®®ä¿®æ­£åè¿›å…¥æ ‡æ³¨æ­¥éª¤\n"
    elif quality_score >= 70:
        content += "- åˆ†æ®µç²’åº¦å¯æ¥å—\n- å­˜åœ¨æ˜æ˜¾é—®é¢˜\n- å¿…é¡»ä¿®æ­£å…³é”®é—®é¢˜åä½¿ç”¨\n"
    else:
        content += "- ğŸš¨ åˆ†æ®µè´¨é‡ä¸åˆæ ¼\n- å»ºè®®é‡æ–°å¤„ç†\n"
    
    content += f"""\n---\n*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*\n*è¯„åˆ†ä¾æ®: docs/workflows/QUALITY_STANDARDS.md*\n"""
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    logger.info(f"ğŸ“„ Step 4 è´¨é‡æŠ¥å‘Š: {report_path}")
    logger.info(f"   è´¨é‡è¯„åˆ†: {quality_score}/100 ({grade})")


def output_step5_report(
    annotation_results: Dict[int, AnnotatedChapter],
    processing_dir: str
):
    """è¾“å‡ºStep 5æŠ¥å‘Š"""
    report_path = Path(processing_dir) / "reports" / "step5_annotation_report.md"
    
    if not annotation_results:
        return
    
    total_events = sum(len(ann.event_timeline.events) for ann in annotation_results.values())
    total_settings = sum(len(ann.setting_library.settings) for ann in annotation_results.values())
    avg_events = total_events/len(annotation_results) if annotation_results else 0
    avg_settings = total_settings/len(annotation_results) if annotation_results else 0
    
    content = f"""# Step 5: ç« èŠ‚æ ‡æ³¨æŠ¥å‘Š

## æ¦‚è§ˆ
- **å¤„ç†ç« èŠ‚æ•°**: {len(annotation_results)}
- **æ€»äº‹ä»¶æ•°**: {total_events}
- **æ€»è®¾å®šæ•°**: {total_settings}
- **å¹³å‡äº‹ä»¶æ•°/ç« **: {avg_events:.1f}
- **å¹³å‡è®¾å®šæ•°/ç« **: {avg_settings:.1f}

## å„ç« è¯¦æƒ…

| ç« èŠ‚å· | äº‹ä»¶æ•° | è®¾å®šæ•° | æ—¶é—´çº¿èµ·ç‚¹ | æ—¶é—´çº¿ç»ˆç‚¹ |
|-------|--------|--------|-----------|-----------|
"""
    
    for chapter_num in sorted(annotation_results.keys()):
        ann = annotation_results[chapter_num]
        timeline = ann.event_timeline
        
        # è®¡ç®—æ—¶é—´çº¿èŒƒå›´ï¼ˆä»eventsä¸­æå–ï¼‰
        timeline_start = "N/A"
        timeline_end = "N/A"
        if timeline.events:
            # è·å–ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªäº‹ä»¶çš„æ—¶é—´ä¿¡æ¯
            first_event = timeline.events[0]
            last_event = timeline.events[-1]
            if hasattr(first_event, 'time_info') and first_event.time_info:
                timeline_start = first_event.time_info
            if hasattr(last_event, 'time_info') and last_event.time_info:
                timeline_end = last_event.time_info
        
        content += (f"| {chapter_num} | {len(timeline.events)} | "
                   f"{len(ann.setting_library.settings)} | "
                   f"{timeline_start} | "
                   f"{timeline_end} |\n")
    
    content += f"""
---
*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    logger.info(f"ğŸ“„ Step 5 æŠ¥å‘Š: {report_path}")


def output_step67_report(
    system_catalog: SystemCatalog,
    system_updates: Dict[int, SystemUpdateResult],
    system_tracking: Dict[int, SystemTrackingResult],
    processing_dir: str
):
    """è¾“å‡ºStep 6-7æŠ¥å‘Š"""
    report_path = Path(processing_dir) / "reports" / "step67_system_report.md"
    
    total_new_elements = sum(len(update.new_elements) for update in system_updates.values())
    total_changes = sum(len(tracking.tracking_entries) for tracking in system_tracking.values())
    
    content = f"""# Step 6-7: ç³»ç»Ÿåˆ†æä¸è¿½è¸ªæŠ¥å‘Š

## ç³»ç»Ÿç›®å½•æ¦‚è§ˆï¼ˆStep 6ï¼‰
- **å°è¯´ç±»å‹**: {system_catalog.novel_type}
- **ç³»ç»Ÿç±»åˆ«æ•°**: {len(system_catalog.categories)}

### ç³»ç»Ÿç±»åˆ«
"""
    
    for cat in system_catalog.categories:
        cat_id = cat.category_id
        cat_name = getattr(cat, 'category_name', 'æœªå‘½å')
        strategy = getattr(cat, 'tracking_strategy', 'state_change')
        elem_count = len(getattr(cat, 'elements', []))
        content += f"""
#### {cat_id}: {cat_name}
- **è¿½è¸ªç­–ç•¥**: {strategy}
- **å…ƒç´ æ•°é‡**: {elem_count}
"""
    
    content += f"""
## ç³»ç»Ÿè¿½è¸ªæ¦‚è§ˆï¼ˆStep 7ï¼‰
- **å¤„ç†ç« èŠ‚æ•°**: {len(system_tracking)}
- **æ–°å¢å…ƒç´ æ€»æ•°**: {total_new_elements}
- **å˜åŒ–è®°å½•æ€»æ•°**: {total_changes}

## å„ç« è¯¦æƒ…

| ç« èŠ‚å· | æ–°å¢å…ƒç´  | å˜åŒ–è®°å½• |
|-------|---------|---------|
"""
    
    for chapter_num in sorted(system_tracking.keys()):
        # å®‰å…¨è·å–new_elementsè®¡æ•°
        update_result = system_updates.get(chapter_num)
        new_count = len(update_result.new_elements) if update_result else 0
        change_count = len(system_tracking[chapter_num].tracking_entries)
        content += f"| {chapter_num} | {new_count} | {change_count} |\n"
    
    content += f"""
---
*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    logger.info(f"ğŸ“„ Step 6-7 æŠ¥å‘Š: {report_path}")


def output_step8_report(
    validation_report: NovelValidationReport,
    processing_dir: str
):
    """è¾“å‡ºStep 8æŠ¥å‘Š"""
    report_path = Path(processing_dir) / "reports" / "step8_validation_report.md"
    
    content = f"""# Step 8: è´¨é‡éªŒè¯æŠ¥å‘Š

## æ€»ä½“è¯„åˆ†
**{validation_report.quality_score}/100**

## é—®é¢˜åˆ—è¡¨
"""
    
    if validation_report.issues:
        for issue in validation_report.issues:
            content += f"""
### {issue.get('severity', 'info').upper()}: {issue.get('category', 'General')}
- **æè¿°**: {issue.get('description', '')}
- **ç« èŠ‚**: {issue.get('chapter', 'N/A')}
"""
    else:
        content += "\nâœ… æœªå‘ç°ä»»ä½•é—®é¢˜\n"
    
    content += f"""
## æ”¹è¿›å»ºè®®
"""
    
    if validation_report.recommendations:
        for recommendation in validation_report.recommendations:
            content += f"- {recommendation}\n"
    else:
        content += "\næ— æ”¹è¿›å»ºè®®\n"
    
    content += f"""
---
*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    logger.info(f"ğŸ“„ Step 8 æŠ¥å‘Š: {report_path}")
