<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session 92ea997c-8497-475b-9f99-f46e303e611b (2026-02-05 11:51Z) -->

# Agent prompt 或模型训练 (2026-02-05 11:51Z)

_**User (2026-02-04 12:20Z)**_

@docs/AI_TRAINING_TUTORIAL.md 

提问：
例如，我要实现的是一个agent，里面的核心是一段prompt，例如把novel改成解说稿

那我训练的是这段prompt还是模型？

---

_**Agent (model claude-4.5-sonnet-thinking, mode Ask)**_

<think><details><summary>Thought Process</summary>
用户在问一个关于AI训练的核心概念问题：当他想实现一个agent，核心是一段prompt（比如把小说改成解说稿），那么他训练的是prompt还是模型？

这是一个很好的问题，涉及到几个关键概念的区分：
1. Prompt Engineering（提示工程）
2. Fine-tuning（微调模型）
3. 两者的区别和适用场景

让我基于用户提供的 AI_TRAINING_TUTORIAL.md 文档来回答这个问题。

关键点：
- **Prompt Engineering**: 不训练任何东西，只是调整输入的指令文本，使用现成的模型
- **Fine-tuning**: 训练模型本身，让模型的参数发生变化，学会特定任务

用户的场景是：agent里核心是prompt，把novel改成解说稿

我需要解释：
1. 如果只是优化prompt，那不需要训练，只需要迭代改进prompt文本
2. 如果要微调模型，是在训练模型的参数，让模型更擅长这个任务
3. 两者可以结合使用
4. 何时选择哪种方式

这个问题很重要，因为很多人混淆了这两个概念。</details></think>

---

这是一个非常关键的概念问题！让我用清晰的对比来回答：

## 🎯 核心区别：Prompt vs 模型

### 情况1：优化 Prompt（**不需要训练**）

```python
# 你在做的是：调整输入文本
prompt = """
你是专业的小说解说词作者。
请将以下小说文本改写为抖音解说稿：
- 保留核心情节
- 增加悬念感
- 口语化表达

小说原文：{novel_text}
"""

# 使用现成的模型
response = client.chat.completions.create(
    model="deepseek-chat",  # 现成的模型，没有训练
    messages=[{"role": "user", "content": prompt}]
)
```

**特点**：
- ✅ 不需要训练数据
- ✅ 立即可用，快速迭代
- ✅ 成本极低（只有推理费用）
- ❌ 依赖模型的通用能力
- ❌ 可能不够精准

---

### 情况2：微调模型（**训练模型参数**）

```python
# 你在做的是：改变模型内部的数十亿个参数
training_data = [
    {
        "messages": [
            {"role": "system", "content": "你是专业的小说解说词作者"},
            {"role": "user", "content": f"将以下小说改为解说稿：{novel_1}"},
            {"role": "assistant", "content": f"{script_1}"}  # 你的标准答案
        ]
    },
    # ... 几百到几千个这样的例子
]

# 训练模型，让它"学会"你的风格和标准
fine_tune_job = client.fine_tuning.jobs.create(
    training_file=upload_training_data(training_data),
    model="deepseek-chat"
)

# 得到一个新模型：ft-your-custom-model
```

**特点**：
- ✅ 学会你的特定风格和标准
- ✅ 不需要复杂的prompt
- ❌ 需要大量标注数据
- ❌ 需要时间和成本

---

## 🤔 你的场景该选哪个？

### 如果你的Agent是这样的：

```python
class NovelToScriptAgent(BaseAgent):
    def run(self, novel_text: str) -> str:
        prompt = self.prompt_template.format(novel=novel_text)
        response = self.llm.generate(prompt)
        return response
```

那么你有**两个优化方向**：

### 方向A：优化 Prompt（推荐先做）

```python
# 迭代改进prompt本身
prompt_v1 = "把小说改成解说稿"  # 太简单
prompt_v2 = "把小说改成抖音解说稿，要口语化"  # 好一些
prompt_v3 = """
你是专业的小说解说词作者。请将以下小说改写为解说稿：
1. 保留核心情节和关键设定
2. 增加悬念钩子
3. 使用口语化表达
...
"""  # 更详细
```

**何时适用**：
- ✅ 刚开始做项目
- ✅ 数据量不够（<100个标注样本）
- ✅ 需要快速迭代测试
- ✅ 现有模型已经基本能完成任务

---

### 方向B：微调模型（有数据后做）

**前提条件**：
1. 你已经有了**稳定的prompt**
2. 你有**几百个高质量的"小说→解说稿"配对**
3. 现有模型效果不够好，或者prompt太复杂

**训练过程**：

```python
# 1. 准备训练数据（人工标注或审核）
training_examples = []
for novel_chapter, script in dataset:
    training_examples.append({
        "messages": [
            {"role": "system", "content": "你是专业的小说解说词作者"},
            {"role": "user", "content": f"将以下小说改为解说稿：\n\n{novel_chapter}"},
            {"role": "assistant", "content": script}  # 人工标注的高质量解说稿
        ]
    })

# 2. 微调模型
fine_tuned_model_id = fine_tune(training_examples)

# 3. 使用微调模型（prompt可以简化）
response = client.chat.completions.create(
    model=fine_tuned_model_id,
    messages=[
        {"role": "user", "content": f"将以下小说改为解说稿：\n\n{novel_text}"}
    ]
)
```

---

## 💡 实战建议：分阶段进行

### 阶段1：Prompt Engineering（1-2周）

```python
# 快速迭代，找到最佳prompt
for prompt_version in prompt_variations:
    results = test_prompt(prompt_version, test_cases)
    evaluate(results)
    
# 目标：找到一个"还不错"的prompt
```

### 阶段2：收集数据（持续）

```python
# 使用最佳prompt生成初步结果
# 人工审核和修正
for novel in novels:
    draft_script = agent.run(novel, best_prompt)
    final_script = human_review_and_edit(draft_script)
    
    # 保存为训练数据
    training_data.append({
        "input": novel,
        "output": final_script  # 人工修正后的高质量版本
    })
```

### 阶段3：模型微调（有100+数据后）

```python
# 当你有足够数据时，微调模型
if len(training_data) >= 100:
    fine_tuned_model = fine_tune(training_data)
    
    # A/B测试：对比原模型+复杂prompt vs 微调模型+简单prompt
    compare_performance(base_model, fine_tuned_model)
```

---

## 📊 决策流程图

```
你想让模型把小说改成解说稿
         ↓
    现有模型能做吗？
         ↓
    能 → 优化Prompt（迭代测试）
         ↓
    效果够好？ → 是 → 完成！
         ↓ 否
    有>=100个标注样本？
         ↓
    否 → 继续收集数据（人工标注）
         ↓
    是 → 微调模型
         ↓
    测试效果 → 好 → 部署使用
         ↓ 不好
    增加数据或调整参数 → 重新微调
```

---

## 🎯 直接回答你的问题

> 那我训练的是这段prompt还是模型？

**答案**：

1. **Prompt不需要"训练"**，只需要人工迭代优化
   - 就像写文章标题，试试不同的写法，看哪个效果好

2. **模型才需要"训练"（微调）**
   - 改变模型内部的参数，让它学会你的任务

3. **推荐路径**：
   ```
   先优化Prompt（几天）
      ↓ 效果不够或prompt太复杂
   收集训练数据（几周）
      ↓ 有100+高质量样本
   微调模型（几小时）
   ```

---

## 💼 对应到你的项目

根据你的文档结构，你应该：

1. **现阶段**：优化 `src/prompts/*.yaml` 中的prompt
   ```yaml
   # src/prompts/novel_to_script.yaml
   system: "你是专业的小说解说词作者..."
   user_template: "将以下小说改为解说稿：\n\n{novel_text}"
   ```

2. **未来**：如果效果不够好 + 有足够数据
   - 在 `data/alignment_optimization/annotations/` 收集训练数据
   - 使用微调脚本训练模型
   - 在 `src/core/config.py` 中配置微调模型ID

希望这样解释清楚了！有任何疑问随时问 😊

---

