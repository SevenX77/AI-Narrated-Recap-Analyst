# ç›®å½•ç»“æ„é‡æ„æ–¹æ¡ˆ

> âš ï¸ **æ³¨æ„**ï¼šæœ¬æ–‡æ¡£æè¿°çš„æ˜¯æ—§çš„ç›®å½•ç»“æ„è®¾è®¡æ–¹æ¡ˆã€‚
> 
> **æœ€æ–°æ–¹æ¡ˆè¯·å‚è€ƒ**ï¼š
> - [æ•°æ®æµé‡æ–°è®¾è®¡](./DATA_FLOW_REDESIGN.md) - è¯¦ç»†çš„æ•°æ®æµå’Œç›®å½•è®¾è®¡
> - [ä¼˜åŒ–æ–¹æ¡ˆæ‰§è¡Œæ‘˜è¦](../planning/OPTIMIZATION_SUMMARY.md) - æœ€æ–°çš„ä¼˜åŒ–æ–¹æ¡ˆï¼ˆ3åˆ†é’Ÿå¿«é€Ÿäº†è§£ï¼‰
> - [å®Œæ•´ä¼˜åŒ–æ–¹æ¡ˆ](../planning/FINAL_OPTIMIZATION_PLAN.md) - 6å¤©å®æ–½è®¡åˆ’
> 
> æœ¬æ–‡æ¡£ä¿ç•™ä»…ä¾›å‚è€ƒï¼Œäº†è§£è®¾è®¡æ¼”å˜å†å²ã€‚

**æœ€åæ›´æ–°**: 2026-02-12  
**çŠ¶æ€**: âš ï¸ å·²è¿‡æ—¶ï¼Œè¯·å‚è€ƒæœ€æ–°æ–‡æ¡£  
**ç›®çš„**: æ¸…ç†å†—ä½™ç›®å½•ï¼Œç»Ÿä¸€æ•°æ®å­˜å‚¨ç»“æ„

---

## ğŸ“Š å½“å‰é—®é¢˜

### é—®é¢˜1: ç›®å½•å†—ä½™
```
âŒ å½“å‰å­˜åœ¨3å±‚ç›®å½•ï¼š
â”œâ”€â”€ processed/      # é¢„å¤„ç†ç»“æœ
â”œâ”€â”€ processing/     # Workflowä¸­é—´ç»“æœï¼ˆâŒ ä¸analysisé‡å¤ï¼‰
â””â”€â”€ analysis/       # å·¥å…·è¾“å‡ºï¼ˆç‰ˆæœ¬åŒ–ï¼‰
```

**é—®é¢˜**ï¼š
- `processing/` å’Œ `analysis/` èŒè´£é‡å 
- å¼€å‘è€…å›°æƒ‘ï¼šä¸çŸ¥é“è¯¥å†™å…¥å“ªä¸ªç›®å½•
- æ•°æ®åˆ†æ•£ï¼šåŒä¸€ç»“æœå¯èƒ½åœ¨å¤šä¸ªåœ°æ–¹

### é—®é¢˜2: å‘½åä¸ç»Ÿä¸€
- æ–‡ä»¶åï¼š`ep01` vs `episode_01` vs `1`
- ç›®å½•åï¼š`novel` vs `novels`
- å˜é‡åï¼š`episode` vs `episode_id` vs `ep`

### é—®é¢˜3: çŠ¶æ€å†—ä½™
- `meta.json` åŒ…å«2å¥—çŠ¶æ€ï¼š`workflow_stages` å’Œ `phase_i_analyst`

---

## ğŸ¯ é‡æ„æ–¹æ¡ˆï¼ˆæ¨èï¼‰

### æ–°ç›®å½•ç»“æ„

```
data/projects/{project_id}/
â”‚
â”œâ”€â”€ meta.json                           # âœ… å”¯ä¸€çŠ¶æ€æ–‡ä»¶ï¼ˆåªä¿ç•™ phase_i_analystï¼‰
â”‚
â”œâ”€â”€ raw/                                # ğŸ”µ åŸå§‹æ–‡ä»¶ï¼ˆä¸å¯å˜ï¼‰
â”‚   â”œâ”€â”€ novel/
â”‚   â”‚   â””â”€â”€ {original_filename}.txt
â”‚   â””â”€â”€ srt/
â”‚       â”œâ”€â”€ ep01.srt                    # âœ… ç»Ÿä¸€æ ¼å¼ï¼šep{XX}.srt
â”‚       â”œâ”€â”€ ep02.srt
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ processed/                          # ğŸŸ¢ é¢„å¤„ç†ç»“æœï¼ˆStep 1è‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚   â”œâ”€â”€ novel/
â”‚   â”‚   â”œâ”€â”€ standardized.txt
â”‚   â”‚   â”œâ”€â”€ metadata.json
â”‚   â”‚   â””â”€â”€ chapters.json
â”‚   â””â”€â”€ script/
â”‚       â”œâ”€â”€ ep01.json                   # âœ… ç»Ÿä¸€æ ¼å¼ï¼šep{XX}.json
â”‚       â”œâ”€â”€ ep01-imported.md
â”‚       â”œâ”€â”€ ep02.json
â”‚       â”œâ”€â”€ ep02-imported.md
â”‚       â””â”€â”€ episodes.json
â”‚
â”œâ”€â”€ analysis/                           # ğŸŸ¡ æ·±åº¦åˆ†æç»“æœï¼ˆStep 2/3/4è¾“å‡ºï¼Œç‰ˆæœ¬åŒ–ï¼‰
â”‚   â”œâ”€â”€ novel/
â”‚   â”‚   â”œâ”€â”€ chapter_001_segmentation_latest.json
â”‚   â”‚   â”œâ”€â”€ chapter_001_annotation_latest.json
â”‚   â”‚   â”œâ”€â”€ chapter_002_segmentation_latest.json
â”‚   â”‚   â”œâ”€â”€ system_catalog_latest.json
â”‚   â”‚   â””â”€â”€ history/                    # ğŸ“¦ å†å²ç‰ˆæœ¬
â”‚   â”‚       â”œâ”€â”€ chapter_001_segmentation_v{timestamp}.json
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ script/
â”‚   â”‚   â”œâ”€â”€ ep01_segmentation_latest.json
â”‚   â”‚   â”œâ”€â”€ ep01_hook_latest.json
â”‚   â”‚   â”œâ”€â”€ ep01_validation_latest.json
â”‚   â”‚   â”œâ”€â”€ ep02_segmentation_latest.json
â”‚   â”‚   â””â”€â”€ history/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ alignment/
â”‚       â”œâ”€â”€ chapter_001_ep01_alignment_latest.json
â”‚       â””â”€â”€ history/
â”‚           â””â”€â”€ ...
â”‚
â””â”€â”€ reports/                            # ğŸ“ äººç±»å¯è¯»æŠ¥å‘Š
    â”œâ”€â”€ quality_report.html
    â”œâ”€â”€ alignment_report.md
    â””â”€â”€ ...
```

### å…³é”®å˜åŒ–

| å˜åŒ– | åŸå›  | å½±å“ |
|------|------|------|
| âŒ åˆ é™¤ `processing/` | ä¸ `analysis/` é‡å¤ | ç®€åŒ–ç»“æ„ |
| âœ… ç»Ÿä¸€ä½¿ç”¨ `analysis/` | æ‰€æœ‰Workflowè¾“å‡ºæ”¾åœ¨ä¸€èµ· | æ˜“äºæŸ¥æ‰¾ |
| âœ… æ·»åŠ  `history/` å­ç›®å½• | ç‰ˆæœ¬åŒ–ç®¡ç† | æ”¯æŒå›æ»š |
| âœ… ç»Ÿä¸€æ–‡ä»¶å‘½å | `ep01`, `chapter_001` | æ¶ˆé™¤æ··ä¹± |
| âŒ åˆ é™¤ `workflow_stages` | åªä¿ç•™ `phase_i_analyst` | ç®€åŒ–çŠ¶æ€ |

---

## ğŸ“‹ å®æ–½æ­¥éª¤

### Phase 1: æ•°æ®è¿ç§»ï¼ˆ1å¤©ï¼‰

#### æ­¥éª¤1.1: è¿ç§»ç°æœ‰æ•°æ®

```bash
# è¿ç§»è„šæœ¬ï¼šmigrate_to_new_structure.sh

#!/bin/bash

PROJECT_DIR="data/projects/project_001"

# 1. è¿ç§» processing/ æ•°æ®åˆ° analysis/
if [ -d "$PROJECT_DIR/processing" ]; then
    echo "Migrating processing/ to analysis/..."
    
    # è¿ç§» novel/ æ•°æ®
    if [ -d "$PROJECT_DIR/processing/novel" ]; then
        mkdir -p "$PROJECT_DIR/analysis/novel"
        cp -r $PROJECT_DIR/processing/novel/* $PROJECT_DIR/analysis/novel/
    fi
    
    # è¿ç§» script/ æ•°æ®
    if [ -d "$PROJECT_DIR/processing/script" ]; then
        mkdir -p "$PROJECT_DIR/analysis/script"
        cp -r $PROJECT_DIR/processing/script/* $PROJECT_DIR/analysis/script/
    fi
    
    # å¤‡ä»½ååˆ é™¤
    mv $PROJECT_DIR/processing $PROJECT_DIR/processing.backup
    echo "âœ… Migrated processing/ â†’ analysis/"
fi

# 2. ç»Ÿä¸€æ–‡ä»¶å‘½å
echo "Renaming files to standard format..."

# Novel: ç¡®ä¿ä½¿ç”¨ chapter_{XXX} æ ¼å¼
cd "$PROJECT_DIR/analysis/novel"
for file in chapter_*.json; do
    # å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œè·³è¿‡
    echo "Novel file: $file (OK)"
done

# Script: ç¡®ä¿ä½¿ç”¨ ep{XX} æ ¼å¼
cd "$PROJECT_DIR/analysis/script"
for file in *.json; do
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å‘½å
    if [[ $file =~ ^episode_([0-9]+)_ ]]; then
        new_name="ep$(printf "%02d" ${BASH_REMATCH[1]})_${file#episode_*_}"
        mv "$file" "$new_name"
        echo "Renamed: $file â†’ $new_name"
    fi
done

echo "âœ… File naming standardized"
```

#### æ­¥éª¤1.2: åˆ›å»ºå†å²ç‰ˆæœ¬ç›®å½•

```python
# scripts/create_history_dirs.py

import os
from pathlib import Path

def create_history_directories(project_dir: str):
    """ä¸ºæ‰€æœ‰analysiså­ç›®å½•åˆ›å»ºhistory/ç›®å½•"""
    
    analysis_dir = Path(project_dir) / "analysis"
    
    for subdir in ["novel", "script", "alignment"]:
        subdir_path = analysis_dir / subdir
        history_path = subdir_path / "history"
        
        if subdir_path.exists():
            history_path.mkdir(exist_ok=True)
            print(f"âœ… Created {history_path}")

if __name__ == "__main__":
    create_history_directories("data/projects/project_001")
```

---

### Phase 2: ä»£ç æ›´æ–°ï¼ˆ2å¤©ï¼‰

#### æ­¥éª¤2.1: æ›´æ–° ProjectManagerV2

```python
# src/core/project_manager_v2.py

def create_project(self, name: str, description: Optional[str] = None) -> ProjectMeta:
    """åˆ›å»ºæ–°é¡¹ç›®"""
    project_id = self._generate_project_id()
    project_dir = os.path.join(self.projects_dir, project_id)
    
    # âœ… æ–°ç›®å½•ç»“æ„
    directories = [
        "raw/novel",
        "raw/srt",
        "processed/novel",
        "processed/script",
        "analysis/novel",
        "analysis/novel/history",
        "analysis/script",
        "analysis/script/history",
        "analysis/alignment",
        "analysis/alignment/history",
        "reports"
    ]
    
    for dir_path in directories:
        os.makedirs(os.path.join(project_dir, dir_path), exist_ok=True)
    
    # âŒ åˆ é™¤ processing/ ç›®å½•åˆ›å»º
    # os.makedirs(os.path.join(project_dir, "processing"), exist_ok=True)  # åˆ é™¤è¿™è¡Œ
    
    # åˆ›å»ºå…ƒæ•°æ®ï¼ˆåªåŒ…å« phase_i_analystï¼‰
    meta = ProjectMeta(
        id=project_id,
        name=name,
        description=description,
        created_at=datetime.now().isoformat(),
        updated_at=datetime.now().isoformat()
    )
    
    # âœ… åˆå§‹åŒ– Phase I çŠ¶æ€
    meta.initialize_phase_i()
    
    # âŒ ä¸å†åˆå§‹åŒ– workflow_stages
    # meta.workflow_stages = ...  # åˆ é™¤è¿™è¡Œ
    
    self._save_meta(project_id, meta)
    return meta
```

#### æ­¥éª¤2.2: æ›´æ–° Workflow ä¿å­˜è·¯å¾„

```python
# src/workflows/novel_processing_workflow.py

def save_segmentation_result(self, chapter_id: str, result: SegmentationResult):
    """ä¿å­˜åˆ†æ®µç»“æœ"""
    
    # âŒ æ—§è·¯å¾„ï¼ˆåˆ é™¤ï¼‰
    # old_path = f"{self.project_dir}/processing/novel/step4_segmentation/{chapter_id}.json"
    
    # âœ… æ–°è·¯å¾„
    artifact_manager.save_artifact(
        content=result.model_dump(),
        artifact_type=f"{chapter_id}_segmentation",
        project_id=self.project_id,
        base_dir=f"{self.project_dir}/analysis/novel",
        extension="json"
    )
    # è‡ªåŠ¨ç”Ÿæˆ:
    # - analysis/novel/chapter_001_segmentation_latest.json
    # - analysis/novel/history/chapter_001_segmentation_v{timestamp}.json
```

```python
# src/workflows/script_processing_workflow.py

def save_hook_result(self, episode_id: str, result: HookDetectionResult):
    """ä¿å­˜Hookæ£€æµ‹ç»“æœ"""
    
    # âŒ æ—§è·¯å¾„ï¼ˆåˆ é™¤ï¼‰
    # old_path = f"{self.project_dir}/processing/script/{episode_id}_hook.json"
    
    # âœ… æ–°è·¯å¾„
    artifact_manager.save_artifact(
        content=result.model_dump(),
        artifact_type=f"{episode_id}_hook",
        project_id=self.project_id,
        base_dir=f"{self.project_dir}/analysis/script",
        extension="json"
    )
```

#### æ­¥éª¤2.3: æ›´æ–°å‘½åè§„èŒƒ

```python
# å…¨å±€æœç´¢æ›¿æ¢

# âŒ æ—§å‘½å
episode = "episode_01"
ep = "ep_01"

# âœ… æ–°å‘½å
episode_id = "ep01"  # ç»Ÿä¸€æ ¼å¼ï¼šep{XX}
chapter_id = "chapter_001"  # ç»Ÿä¸€æ ¼å¼ï¼šchapter_{XXX}
```

**æœç´¢æ›¿æ¢æ¸…å•**:
```bash
# 1. æ›¿æ¢å‡½æ•°å‚æ•°
grep -r "def.*episode:" src/ | wc -l
â†’ æ›¿æ¢ä¸º: def process(episode_id: str)

# 2. æ›¿æ¢æ–‡ä»¶è·¯å¾„
grep -r "processing/" src/ | wc -l
â†’ æ›¿æ¢ä¸º: analysis/

# 3. æ›¿æ¢episodeå˜é‡
grep -r "episode\s*=" src/ | wc -l
â†’ æ›¿æ¢ä¸º: episode_id =
```

---

### Phase 3: æ¸…ç†ä»£ç ï¼ˆ1å¤©ï¼‰

#### æ­¥éª¤3.1: åˆ é™¤ workflow_stages ç›¸å…³ä»£ç 

```python
# src/core/schemas_project.py

class ProjectMeta(BaseModel):
    id: str
    name: str
    description: Optional[str] = None
    created_at: str
    updated_at: str
    status: ProjectStatus = ProjectStatus.DRAFT
    
    sources: ProjectSources = Field(default_factory=ProjectSources)
    
    # âŒ åˆ é™¤ï¼ˆæ ‡è®°ä¸ºåºŸå¼ƒï¼‰
    workflow_stages: Optional[Dict] = Field(
        None,
        deprecated=True,
        description="å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ phase_i_analyst"
    )
    
    # âœ… ä¿ç•™ï¼ˆä¸»çŠ¶æ€ï¼‰
    phase_i_analyst: Optional[PhaseIAnalystState] = None
    
    stats: ProjectStats = Field(default_factory=ProjectStats)
```

#### æ­¥éª¤3.2: æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥

```bash
# è¿è¡Œä»£ç æ£€æŸ¥å·¥å…·
flake8 src/ --select=F401  # æ£€æŸ¥æœªä½¿ç”¨çš„å¯¼å…¥
pylint src/ --disable=all --enable=unused-import
```

#### æ­¥éª¤3.3: åˆ é™¤æ—§æµ‹è¯•æ–‡ä»¶

```bash
# åˆ é™¤ processing/ ç›¸å…³çš„æµ‹è¯•
rm scripts/test/test_processing_*.py

# æ›´æ–°æµ‹è¯•è·¯å¾„
grep -r "processing/" scripts/test/ | wc -l
â†’ æ›¿æ¢ä¸º: analysis/
```

---

### Phase 4: æ–‡æ¡£æ›´æ–°ï¼ˆ1å¤©ï¼‰

#### æ­¥éª¤4.1: æ›´æ–°æ ¸å¿ƒæ–‡æ¡£

- [ ] `docs/PROJECT_STRUCTURE.md` - æ›´æ–°ç›®å½•ç»“æ„è¯´æ˜
- [ ] `docs/DEV_STANDARDS.md` - è¡¥å……å‘½åè§„èŒƒ
- [ ] `docs/FILE_PATH_MAPPING.md` - æ›´æ–°è·¯å¾„æ˜ å°„
- [ ] `docs/workflows/ROADMAP.md` - æ›´æ–°å·¥ä½œæµè¯´æ˜

#### æ­¥éª¤4.2: åˆ›å»ºè¿ç§»æŒ‡å—

```markdown
# MIGRATION_GUIDE.md

## æ—§ä»£ç  â†’ æ–°ä»£ç 

### 1. è·¯å¾„å˜æ›´
| æ—§è·¯å¾„ | æ–°è·¯å¾„ |
|--------|--------|
| `processing/novel/` | `analysis/novel/` |
| `processing/script/` | `analysis/script/` |

### 2. å‘½åå˜æ›´
| æ—§å‘½å | æ–°å‘½å |
|--------|--------|
| `episode` | `episode_id` |
| `ep_01` | `ep01` |
| `episode_01` | `ep01` |

### 3. çŠ¶æ€å­—æ®µå˜æ›´
| æ—§å­—æ®µ | æ–°å­—æ®µ |
|--------|--------|
| `meta.workflow_stages` | `meta.phase_i_analyst` |
```

---

### Phase 5: æµ‹è¯•éªŒè¯ï¼ˆ1å¤©ï¼‰

#### æ­¥éª¤5.1: å•å…ƒæµ‹è¯•

```python
# tests/test_directory_structure.py

def test_new_directory_structure():
    """æµ‹è¯•æ–°ç›®å½•ç»“æ„æ˜¯å¦æ­£ç¡®åˆ›å»º"""
    project_id = "test_project_001"
    meta = project_manager_v2.create_project("Test Project")
    
    # éªŒè¯ç›®å½•å­˜åœ¨
    assert os.path.exists(f"data/projects/{project_id}/raw/novel")
    assert os.path.exists(f"data/projects/{project_id}/analysis/novel/history")
    
    # éªŒè¯æ—§ç›®å½•ä¸å­˜åœ¨
    assert not os.path.exists(f"data/projects/{project_id}/processing")

def test_artifact_save_location():
    """æµ‹è¯•artifactä¿å­˜åˆ°æ­£ç¡®ä½ç½®"""
    result = {"chapter_id": "chapter_001", "paragraphs": []}
    
    artifact_manager.save_artifact(
        content=result,
        artifact_type="chapter_001_segmentation",
        project_id="test_project_001",
        base_dir="data/projects/test_project_001/analysis/novel"
    )
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    assert os.path.exists("data/projects/test_project_001/analysis/novel/chapter_001_segmentation_latest.json")
    assert os.path.exists("data/projects/test_project_001/analysis/novel/history/chapter_001_segmentation_v*.json")
```

#### æ­¥éª¤5.2: é›†æˆæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµç¨‹æµ‹è¯•
python scripts/test/test_complete_workflow.py

# æµ‹è¯•æ­¥éª¤:
# 1. åˆ›å»ºé¡¹ç›® â†’ éªŒè¯ç›®å½•ç»“æ„
# 2. ä¸Šä¼ æ–‡ä»¶ â†’ éªŒè¯processed/è·¯å¾„
# 3. è¿è¡ŒWorkflow â†’ éªŒè¯analysis/è·¯å¾„
# 4. æ£€æŸ¥çŠ¶æ€ â†’ éªŒè¯phase_i_analystæ›´æ–°
```

---

## ğŸš¨ å›æ»šè®¡åˆ’

å¦‚æœé‡æ„å‡ºç°é—®é¢˜ï¼Œå¯ä»¥å¿«é€Ÿå›æ»šï¼š

```bash
#!/bin/bash
# rollback.sh

PROJECT_DIR="data/projects/project_001"

# 1. æ¢å¤ processing/ ç›®å½•
if [ -d "$PROJECT_DIR/processing.backup" ]; then
    mv $PROJECT_DIR/processing.backup $PROJECT_DIR/processing
    echo "âœ… Restored processing/ directory"
fi

# 2. æ¢å¤æ—§ç‰ˆæœ¬ä»£ç 
git checkout HEAD~1 src/core/project_manager_v2.py
git checkout HEAD~1 src/workflows/
echo "âœ… Restored old code"

# 3. é‡å¯æœåŠ¡
pkill -f "uvicorn src.api.main"
sleep 2
nohup uvicorn src.api.main:app --reload --port 8000 &
echo "âœ… Restarted API server"
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### é‡æ„å‰ vs é‡æ„å

| æŒ‡æ ‡ | é‡æ„å‰ | é‡æ„å | æ”¹å–„ |
|------|--------|--------|------|
| **ç›®å½•å±‚çº§** | 3å±‚ï¼ˆprocessed, processing, analysisï¼‰ | 2å±‚ï¼ˆprocessed, analysisï¼‰ | -33% |
| **æ–‡ä»¶å‘½åä¸€è‡´æ€§** | 60% | 100% | +67% |
| **çŠ¶æ€æ•°æ®å†—ä½™** | 2å¥—ï¼ˆworkflow_stages, phase_i_analystï¼‰ | 1å¥—ï¼ˆphase_i_analystï¼‰ | -50% |
| **å¼€å‘è€…ç†è§£éš¾åº¦** | é«˜ï¼ˆ7/10ï¼‰ | ä½ï¼ˆ3/10ï¼‰ | -57% |
| **æ•°æ®æŸ¥æ‰¾æ—¶é—´** | ~30ç§’ | ~5ç§’ | -83% |

---

## ğŸ“‹ æ‰§è¡Œæ£€æŸ¥æ¸…å•

### å‡†å¤‡é˜¶æ®µ
- [ ] å¤‡ä»½ç°æœ‰é¡¹ç›®æ•°æ®
- [ ] é€šçŸ¥å›¢é˜Ÿæˆå‘˜å³å°†é‡æ„
- [ ] åˆ›å»ºæ–°åˆ†æ”¯ `refactor/directory-restructure`

### å®æ–½é˜¶æ®µ
- [ ] Phase 1: æ•°æ®è¿ç§»ï¼ˆ1å¤©ï¼‰
  - [ ] è¿è¡Œè¿ç§»è„šæœ¬
  - [ ] éªŒè¯æ•°æ®å®Œæ•´æ€§
  - [ ] åˆ›å»ºhistoryç›®å½•
- [ ] Phase 2: ä»£ç æ›´æ–°ï¼ˆ2å¤©ï¼‰
  - [ ] æ›´æ–°ProjectManagerV2
  - [ ] æ›´æ–°æ‰€æœ‰Workflow
  - [ ] ç»Ÿä¸€å‘½åè§„èŒƒ
- [ ] Phase 3: æ¸…ç†ä»£ç ï¼ˆ1å¤©ï¼‰
  - [ ] åˆ é™¤workflow_stages
  - [ ] æ¸…ç†æœªä½¿ç”¨ä»£ç 
  - [ ] åˆ é™¤æ—§æµ‹è¯•
- [ ] Phase 4: æ–‡æ¡£æ›´æ–°ï¼ˆ1å¤©ï¼‰
  - [ ] æ›´æ–°æ ¸å¿ƒæ–‡æ¡£
  - [ ] åˆ›å»ºè¿ç§»æŒ‡å—
- [ ] Phase 5: æµ‹è¯•éªŒè¯ï¼ˆ1å¤©ï¼‰
  - [ ] è¿è¡Œå•å…ƒæµ‹è¯•
  - [ ] è¿è¡Œé›†æˆæµ‹è¯•
  - [ ] æ‰‹åŠ¨éªŒè¯å‰ç«¯åŠŸèƒ½

### å®Œæˆé˜¶æ®µ
- [ ] ä»£ç å®¡æŸ¥
- [ ] åˆå¹¶åˆ°ä¸»åˆ†æ”¯
- [ ] éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- [ ] ç›‘æ§é”™è¯¯æ—¥å¿—

---

## ğŸ¯ é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | é¢„è®¡å®Œæˆ | éªŒæ”¶æ ‡å‡† |
|--------|---------|---------|
| æ•°æ®è¿ç§»å®Œæˆ | Day 1 | æ‰€æœ‰æ•°æ®ä»processing/è¿ç§»åˆ°analysis/ |
| ä»£ç æ›´æ–°å®Œæˆ | Day 3 | æ‰€æœ‰è·¯å¾„å’Œå‘½åç»Ÿä¸€ |
| æµ‹è¯•é€šè¿‡ | Day 5 | å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•100%é€šè¿‡ |
| æ–‡æ¡£æ›´æ–°å®Œæˆ | Day 5 | æ‰€æœ‰æ–‡æ¡£åæ˜ æ–°ç»“æ„ |
| ä¸Šçº¿ç”Ÿäº§ | Day 6 | ç”Ÿäº§ç¯å¢ƒç¨³å®šè¿è¡Œ24å°æ—¶ |

---

**æœ€åæ›´æ–°**: 2026-02-12  
**é¢„è®¡å·¥æœŸ**: 5-6å¤©  
**é£é™©ç­‰çº§**: ä¸­ç­‰ï¼ˆæœ‰å›æ»šæ–¹æ¡ˆï¼‰  
**å»ºè®®æ‰§è¡Œæ—¶é—´**: æœ¬å‘¨æˆ–ä¸‹å‘¨
