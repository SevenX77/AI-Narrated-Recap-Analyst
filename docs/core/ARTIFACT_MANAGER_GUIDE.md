# ArtifactManager å·¥ä½œåŸç†è¯¦è§£

**æœ€åæ›´æ–°**: 2026-02-12  
**æ ¸å¿ƒç­–ç•¥**: Latest Pointer + Timestamped Versions  
**æ–‡ä»¶**: `src/core/artifact_manager.py`

---

## ğŸ¯ è®¾è®¡ç›®æ ‡

### ä¸ºä»€ä¹ˆéœ€è¦ ArtifactManagerï¼Ÿ

åœ¨ AI å·¥ä½œæµä¸­ï¼Œæˆ‘ä»¬ä¼šå¤šæ¬¡è¿è¡ŒåŒä¸€ä¸ªå·¥å…·ï¼ˆå¦‚ NovelSegmenterã€ScriptSegmenterï¼‰ï¼Œæ¯æ¬¡è¿è¡Œå¯èƒ½ï¼š
- ä½¿ç”¨ä¸åŒçš„å‚æ•°ï¼ˆå¦‚ä¸åŒçš„LLM providerï¼‰
- å¯¹ç»“æœä¸æ»¡æ„ï¼Œéœ€è¦é‡æ–°è¿è¡Œ
- éœ€è¦å¯¹æ¯”ä¸åŒç‰ˆæœ¬çš„ç»“æœ

**é—®é¢˜**ï¼š
- âŒ ç›´æ¥è¦†ç›–æ–‡ä»¶ â†’ ä¸¢å¤±å†å²ç‰ˆæœ¬ï¼Œæ— æ³•å›æ»š
- âŒ æ‰‹åŠ¨å‘½åç‰ˆæœ¬ â†’ å®¹æ˜“å‡ºé”™ï¼Œéš¾ä»¥ç®¡ç†
- âŒ æ¯æ¬¡éƒ½åˆ›å»ºæ–°æ–‡ä»¶ â†’ ä¸çŸ¥é“å“ªä¸ªæ˜¯æœ€æ–°çš„

**è§£å†³æ–¹æ¡ˆ**ï¼š
- âœ… è‡ªåŠ¨ç‰ˆæœ¬åŒ–ç®¡ç†
- âœ… å§‹ç»ˆæœ‰æ˜ç¡®çš„"æœ€æ–°ç‰ˆæœ¬"
- âœ… ä¿ç•™å†å²è®°å½•ï¼Œæ”¯æŒå›æ»š

---

## ğŸ“‹ æ ¸å¿ƒç­–ç•¥ï¼šLatest Pointer + Timestamped Versions

### ç­–ç•¥è¯´æ˜

```
ä¸»ç›®å½•ï¼ˆanalyst/novel_analysis/ï¼‰
â”œâ”€â”€ chapter_001_segmentation_latest.json    # â­ Latest Pointerï¼ˆå§‹ç»ˆæŒ‡å‘æœ€æ–°ç‰ˆæœ¬ï¼‰
â”‚
â””â”€â”€ history/                                # ğŸ“¦ ç‰ˆæœ¬å­˜æ¡£ç›®å½•
    â”œâ”€â”€ chapter_001_segmentation_v20260212_180530.json    # ç‰ˆæœ¬1
    â”œâ”€â”€ chapter_001_segmentation_v20260212_190000.json    # ç‰ˆæœ¬2
    â””â”€â”€ chapter_001_segmentation_v20260212_200000.json    # ç‰ˆæœ¬3ï¼ˆæœ€æ–°ï¼‰
```

**å…³é”®ç‚¹**ï¼š
1. **Latestæ–‡ä»¶**ï¼ˆ`*_latest.json`ï¼‰ï¼šå§‹ç»ˆæ˜¯æœ€æ–°ç‰ˆæœ¬çš„**å‰¯æœ¬**
2. **Historyç›®å½•**ï¼šä¿å­˜æ‰€æœ‰å†å²ç‰ˆæœ¬ï¼ˆåŒ…æ‹¬æœ€æ–°ç‰ˆæœ¬ï¼‰
3. **æ—¶é—´æˆ³å‘½å**ï¼š`v{YYYYMMDD}_{HHMMSS}` æ ¼å¼ï¼Œç¡®ä¿å”¯ä¸€æ€§å’Œå¯æ’åº

---

## ğŸ”„ ä¿å­˜æµç¨‹è¯¦è§£

### è°ƒç”¨æ–¹å¼

```python
from src.core.artifact_manager import artifact_manager

# ä¿å­˜åˆ†æ®µç»“æœ
segmentation_result = NovelSegmenter.execute(...)

artifact_manager.save_artifact(
    content=segmentation_result.model_dump(),
    artifact_type="chapter_001_segmentation",
    project_id="project_001",
    base_dir="data/projects/project_001/analyst/novel_analysis",
    extension="json"
)
```

### å†…éƒ¨æ‰§è¡Œæ­¥éª¤ï¼ˆ5æ­¥ï¼‰

#### Step 1: ç”Ÿæˆæ–‡ä»¶å

```python
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")  # "20260212_180530"

version_filename = f"{artifact_type}_v{timestamp}.{extension}"
# â†’ "chapter_001_segmentation_v20260212_180530.json"

latest_filename = f"{artifact_type}_latest.{extension}"
# â†’ "chapter_001_segmentation_latest.json"
```

**è·¯å¾„ç”Ÿæˆ**ï¼š
```python
latest_path = os.path.join(base_dir, latest_filename)
# â†’ "data/projects/project_001/analyst/novel_analysis/chapter_001_segmentation_latest.json"

history_dir = os.path.join(base_dir, "history")
# â†’ "data/projects/project_001/analyst/novel_analysis/history"

version_path = os.path.join(history_dir, version_filename)
# â†’ "data/projects/project_001/analyst/novel_analysis/history/chapter_001_segmentation_v20260212_180530.json"
```

---

#### Step 2: ç¡®ä¿ history/ ç›®å½•å­˜åœ¨

```python
os.makedirs(history_dir, exist_ok=True)
# å¦‚æœ history/ ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
# å¦‚æœå·²å­˜åœ¨ï¼Œä¸æŠ¥é”™
```

**ç›®å½•ç»“æ„**ï¼š
```
data/projects/project_001/analyst/novel_analysis/
â””â”€â”€ history/                              # âœ… ç¡®ä¿å­˜åœ¨
```

---

#### Step 3: æ¸…ç†ä¸»ç›®å½•ä¸­çš„æ—§ç‰ˆæœ¬æ–‡ä»¶

**é—®é¢˜**ï¼šä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸€æ­¥ï¼Ÿ

å¦‚æœä¹‹å‰æœ‰ä»£ç ç›´æ¥åœ¨ä¸»ç›®å½•ä¿å­˜ç‰ˆæœ¬æ–‡ä»¶ï¼ˆå¦‚ `chapter_001_segmentation_v20260211_100000.json`ï¼‰ï¼Œè¿™äº›æ–‡ä»¶ä¼šå’Œ `_latest.json` æ··åœ¨ä¸€èµ·ï¼Œé€ æˆæ··ä¹±ã€‚

**è§£å†³**ï¼šè‡ªåŠ¨å°†ä¸»ç›®å½•ä¸­çš„æ—§ç‰ˆæœ¬æ–‡ä»¶ç§»åŠ¨åˆ° `history/`

```python
import glob

# æŸ¥æ‰¾ä¸»ç›®å½•ä¸­çš„æ—§ç‰ˆæœ¬æ–‡ä»¶ï¼ˆåŒ¹é… *_v*.json æ¨¡å¼ï¼‰
pattern = os.path.join(base_dir, f"{artifact_type}_v*.{extension}")
# â†’ "data/projects/project_001/analysis/novel/chapter_001_segmentation_v*.json"

existing_versions_in_root = glob.glob(pattern)
# â†’ ["data/.../chapter_001_segmentation_v20260211_100000.json", ...]

moved_count = 0
for old_version in existing_versions_in_root:
    # åªç§»åŠ¨ä¸»ç›®å½•ä¸­çš„ç‰ˆæœ¬æ–‡ä»¶ï¼ˆä¸ç§»åŠ¨ history/ ä¸­çš„ï¼‰
    if os.path.dirname(old_version) == base_dir:
        dest_path = os.path.join(history_dir, os.path.basename(old_version))
        shutil.move(old_version, dest_path)
        moved_count += 1

logger.debug(f"Moved {moved_count} old version(s) to history/")
```

**æ•ˆæœ**ï¼š
```
æ‰§è¡Œå‰:
analyst/novel_analysis/
â”œâ”€â”€ chapter_001_segmentation_latest.json
â”œâ”€â”€ chapter_001_segmentation_v20260211_100000.json    # âš ï¸ æ—§ç‰ˆæœ¬æ–‡ä»¶ï¼ˆæ··ä¹±ï¼‰
â””â”€â”€ history/

æ‰§è¡Œå:
analyst/novel_analysis/
â”œâ”€â”€ chapter_001_segmentation_latest.json
â””â”€â”€ history/
    â””â”€â”€ chapter_001_segmentation_v20260211_100000.json    # âœ… ç§»åŠ¨åˆ°history/
```

---

#### Step 4: ä¿å­˜æ–°ç‰ˆæœ¬åˆ° history/

```python
with open(version_path, 'w', encoding='utf-8') as f:
    if extension == "json":
        json.dump(content, f, ensure_ascii=False, indent=2)
    else:
        f.write(str(content))
```

**å†™å…¥å†…å®¹**ï¼ˆç¤ºä¾‹ï¼‰ï¼š
```json
// history/chapter_001_segmentation_v20260212_180530.json
{
  "chapter_id": "chapter_001",
  "total_paragraphs": 50,
  "paragraphs": [
    {
      "paragraph_id": "p001",
      "content": "æœ«æ—¥é™ä¸´çš„é‚£ä¸€å¤©ï¼Œè‹çƒˆæ­£é©¾é©¶ç€å¡è½¦...",
      "category": "narrative"
    },
    ...
  ],
  "metadata": {
    "segmented_at": "2026-02-12T18:05:30",
    "tool": "NovelSegmenter",
    "llm_provider": "claude",
    "total_cost": 0.15
  }
}
```

---

#### Step 5: æ›´æ–°ä¸»ç›®å½•çš„ latest æ–‡ä»¶

```python
shutil.copy2(version_path, latest_path)
# å°† history/chapter_001_segmentation_v20260212_180530.json
# å¤åˆ¶åˆ° chapter_001_segmentation_latest.json
```

**ä¸ºä»€ä¹ˆç”¨ copy2 è€Œä¸æ˜¯ moveï¼Ÿ**
- `copy2` ä¿ç•™æ–‡ä»¶å…ƒæ•°æ®ï¼ˆä¿®æ”¹æ—¶é—´ã€æƒé™ç­‰ï¼‰
- ä¿ç•™ history/ ä¸­çš„ç‰ˆæœ¬æ–‡ä»¶ï¼ŒåŒæ—¶æ›´æ–° latest æ–‡ä»¶

**æœ€ç»ˆç»“æœ**ï¼š
```
analyst/novel_analysis/
â”œâ”€â”€ chapter_001_segmentation_latest.json              # â­ æœ€æ–°ç‰ˆæœ¬ï¼ˆå‰¯æœ¬ï¼‰
â”‚   å†…å®¹ä¸ history/chapter_001_segmentation_v20260212_180530.json å®Œå…¨ç›¸åŒ
â”‚
â””â”€â”€ history/
    â”œâ”€â”€ chapter_001_segmentation_v20260211_100000.json
    â”œâ”€â”€ chapter_001_segmentation_v20260212_180530.json    # â­ æœ€æ–°ç‰ˆæœ¬ï¼ˆåŸä»¶ï¼‰
    â””â”€â”€ ...
```

---

#### Step 6: è®°å½•æ—¥å¿—å¹¶è¿”å›

```python
logger.info(f"Saved artifact [{project_id}]: {version_filename} (updated latest)")
return version_path
# è¿”å›ç‰ˆæœ¬æ–‡ä»¶çš„è·¯å¾„ï¼ˆhistory/ ä¸­çš„è·¯å¾„ï¼‰
```

**æ—¥å¿—è¾“å‡º**ï¼š
```
INFO: Saved artifact [project_001]: chapter_001_segmentation_v20260212_180530.json (updated latest)
```

---

## ğŸ“– è¯»å–æµç¨‹è¯¦è§£

### è°ƒç”¨æ–¹å¼

```python
# è¯»å–æœ€æ–°ç‰ˆæœ¬
result = artifact_manager.load_latest_artifact(
    artifact_type="chapter_001_segmentation",
    base_dir="data/projects/project_001/analyst/novel_analysis",
    extension="json"
)
```

### å†…éƒ¨æ‰§è¡Œæ­¥éª¤

```python
def load_latest_artifact(artifact_type: str, base_dir: str, extension: str = "json"):
    # 1. æ„å»º latest æ–‡ä»¶è·¯å¾„
    latest_path = os.path.join(base_dir, f"{artifact_type}_latest.{extension}")
    # â†’ "data/.../analysis/novel/chapter_001_segmentation_latest.json"
    
    # 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(latest_path):
        return None  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å› None
    
    # 3. è¯»å–æ–‡ä»¶
    with open(latest_path, 'r', encoding='utf-8') as f:
        if extension == "json":
            return json.load(f)  # è¿”å› dict
        return f.read()          # è¿”å› str
```

**æ³¨æ„**ï¼š
- âœ… å§‹ç»ˆè¯»å– `*_latest.json`ï¼ˆä¸è¯»å– history/ ä¸­çš„æ–‡ä»¶ï¼‰
- âœ… å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å› `None`ï¼ˆä¸æŠ›å¼‚å¸¸ï¼‰

---

## ğŸ¨ å®Œæ•´ç¤ºä¾‹

### åœºæ™¯ï¼šå¤„ç†å°è¯´ç¬¬1ç« ï¼Œè¿è¡Œ3æ¬¡

#### ç¬¬1æ¬¡è¿è¡Œï¼ˆ2026-02-12 18:00:00ï¼‰

```python
# è¿è¡Œ NovelSegmenter
result_1 = NovelSegmenter.execute(
    chapter_text="...",
    provider="claude"
)

# ä¿å­˜ç»“æœ
artifact_manager.save_artifact(
    content=result_1.model_dump(),
    artifact_type="chapter_001_segmentation",
    project_id="project_001",
    base_dir="data/projects/project_001/analyst/novel_analysis"
)
```

**ç”Ÿæˆçš„æ–‡ä»¶**ï¼š
```
analyst/novel_analysis/
â”œâ”€â”€ chapter_001_segmentation_latest.json              # â­ ç‰ˆæœ¬1
â””â”€â”€ history/
    â””â”€â”€ chapter_001_segmentation_v20260212_180000.json    # ç‰ˆæœ¬1ï¼ˆåŸä»¶ï¼‰
```

---

#### ç¬¬2æ¬¡è¿è¡Œï¼ˆ2026-02-12 19:00:00ï¼‰- å‚æ•°è°ƒæ•´

```python
# ä½¿ç”¨ä¸åŒçš„ LLM provider é‡æ–°è¿è¡Œ
result_2 = NovelSegmenter.execute(
    chapter_text="...",
    provider="deepseek"  # æ¢äº† provider
)

# ä¿å­˜ç»“æœ
artifact_manager.save_artifact(
    content=result_2.model_dump(),
    artifact_type="chapter_001_segmentation",
    project_id="project_001",
    base_dir="data/projects/project_001/analyst/novel_analysis"
)
```

**ç”Ÿæˆçš„æ–‡ä»¶**ï¼š
```
analyst/novel_analysis/
â”œâ”€â”€ chapter_001_segmentation_latest.json              # â­ ç‰ˆæœ¬2ï¼ˆè¦†ç›–ï¼‰
â””â”€â”€ history/
    â”œâ”€â”€ chapter_001_segmentation_v20260212_180000.json    # ç‰ˆæœ¬1ï¼ˆä¿ç•™ï¼‰
    â””â”€â”€ chapter_001_segmentation_v20260212_190000.json    # ç‰ˆæœ¬2ï¼ˆæ–°å¢ï¼‰
```

**å…³é”®å˜åŒ–**ï¼š
- `latest.json` è¢«è¦†ç›–ä¸ºç‰ˆæœ¬2
- ç‰ˆæœ¬1ä¿ç•™åœ¨ history/ ä¸­

---

#### ç¬¬3æ¬¡è¿è¡Œï¼ˆ2026-02-12 20:00:00ï¼‰- æœ€ç»ˆä¼˜åŒ–

```python
# è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œæœ€ç»ˆç‰ˆæœ¬
result_3 = NovelSegmenter.execute(
    chapter_text="...",
    provider="claude",  # æ¢å› claude
    temperature=0.3     # è°ƒæ•´å‚æ•°
)

# ä¿å­˜ç»“æœ
artifact_manager.save_artifact(
    content=result_3.model_dump(),
    artifact_type="chapter_001_segmentation",
    project_id="project_001",
    base_dir="data/projects/project_001/analyst/novel_analysis"
)
```

**æœ€ç»ˆæ–‡ä»¶ç»“æ„**ï¼š
```
analyst/novel_analysis/
â”œâ”€â”€ chapter_001_segmentation_latest.json              # â­ ç‰ˆæœ¬3ï¼ˆå½“å‰ä½¿ç”¨ï¼‰
â””â”€â”€ history/
    â”œâ”€â”€ chapter_001_segmentation_v20260212_180000.json    # ç‰ˆæœ¬1ï¼ˆclaudeï¼‰
    â”œâ”€â”€ chapter_001_segmentation_v20260212_190000.json    # ç‰ˆæœ¬2ï¼ˆdeepseekï¼‰
    â””â”€â”€ chapter_001_segmentation_v20260212_200000.json    # ç‰ˆæœ¬3ï¼ˆclaudeä¼˜åŒ–ï¼‰
```

---

### è¯»å–å’Œå¯¹æ¯”

#### è¯»å–æœ€æ–°ç‰ˆæœ¬ï¼ˆç‰ˆæœ¬3ï¼‰

```python
latest = artifact_manager.load_latest_artifact(
    artifact_type="chapter_001_segmentation",
    base_dir="data/projects/project_001/analyst/novel_analysis"
)

print(latest["metadata"]["llm_provider"])  # "claude"
print(latest["metadata"]["segmented_at"])  # "2026-02-12T20:00:00"
```

#### å›æ»šåˆ°ç‰ˆæœ¬1ï¼ˆæ‰‹åŠ¨ï¼‰

```python
import json

# è¯»å–å†å²ç‰ˆæœ¬
with open("data/.../history/chapter_001_segmentation_v20260212_180000.json", 'r') as f:
    version_1 = json.load(f)

# å¯¹æ¯”
print(f"ç‰ˆæœ¬1 æ®µè½æ•°: {version_1['total_paragraphs']}")
print(f"ç‰ˆæœ¬3 æ®µè½æ•°: {latest['total_paragraphs']}")

# å¦‚æœç‰ˆæœ¬1æ›´å¥½ï¼Œå¯ä»¥æ‰‹åŠ¨å¤åˆ¶å›å»
shutil.copy2(
    "data/.../history/chapter_001_segmentation_v20260212_180000.json",
    "data/.../analysis/novel/chapter_001_segmentation_latest.json"
)
```

---

## ğŸ” æ–‡ä»¶å‘½åè§„èŒƒ

### artifact_type çš„å‘½å

**æ ¼å¼**ï¼š`{chapter_id}_{operation}` æˆ– `{episode_id}_{operation}`

**ç¤ºä¾‹**ï¼š

| artifact_type | è¯´æ˜ | ç”Ÿæˆçš„æ–‡ä»¶ |
|--------------|------|----------|
| `chapter_001_segmentation` | ç¬¬1ç« åˆ†æ®µ | `chapter_001_segmentation_latest.json` |
| `chapter_001_annotation` | ç¬¬1ç« æ ‡æ³¨ | `chapter_001_annotation_latest.json` |
| `ep01_segmentation` | ç¬¬1é›†åˆ†æ®µ | `ep01_segmentation_latest.json` |
| `ep01_hook` | ç¬¬1é›†Hookæ£€æµ‹ | `ep01_hook_latest.json` |
| `system_catalog` | ç³»ç»Ÿç›®å½• | `system_catalog_latest.json` |
| `chapter_001_ep01_alignment` | ç¬¬1ç« -ç¬¬1é›†å¯¹é½ | `chapter_001_ep01_alignment_latest.json` |

**è§„åˆ™**ï¼š
- âœ… ä½¿ç”¨ä¸‹åˆ’çº¿ `_` è¿æ¥
- âœ… ä½¿ç”¨å°å†™å­—æ¯
- âœ… ä½¿ç”¨æ ‡å‡†IDæ ¼å¼ï¼ˆ`chapter_001`, `ep01`ï¼‰
- âŒ ä¸ä½¿ç”¨ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦

---

## ğŸš¨ å¸¸è§é”™è¯¯å’Œè§£å†³

### é”™è¯¯1: ç›´æ¥å†™å…¥ä¸»ç›®å½•ï¼ˆä¸ä½¿ç”¨ ArtifactManagerï¼‰

```python
# âŒ é”™è¯¯ï¼šç›´æ¥ä¿å­˜æ–‡ä»¶
with open("data/.../analyst/novel_analysis/chapter_001_segmentation.json", 'w') as f:
    json.dump(result, f)
```

**é—®é¢˜**ï¼š
- æ²¡æœ‰ç‰ˆæœ¬åŒ–ç®¡ç†
- è¦†ç›–å†å²æ•°æ®
- æ— æ³•å›æ»š

**è§£å†³**ï¼š
```python
# âœ… æ­£ç¡®ï¼šä½¿ç”¨ ArtifactManager
artifact_manager.save_artifact(
    content=result,
    artifact_type="chapter_001_segmentation",
    project_id=project_id,
    base_dir=f"{project_dir}/analysis/novel"
)
```

---

### é”™è¯¯2: æ‰‹åŠ¨åˆ›å»ºç‰ˆæœ¬æ–‡ä»¶å

```python
# âŒ é”™è¯¯ï¼šæ‰‹åŠ¨å‘½åç‰ˆæœ¬
timestamp = datetime.now().isoformat()
filename = f"chapter_001_segmentation_{timestamp}.json"
# é—®é¢˜ï¼šæ—¶é—´æˆ³æ ¼å¼ä¸ç»Ÿä¸€ï¼Œæ–‡ä»¶ååŒ…å«å†’å·ï¼ˆWindowsä¸æ”¯æŒï¼‰
```

**é—®é¢˜**ï¼š
- æ—¶é—´æˆ³æ ¼å¼ä¸ä¸€è‡´
- æ–‡ä»¶åå¯èƒ½åŒ…å«éæ³•å­—ç¬¦
- æ²¡æœ‰ç»Ÿä¸€çš„ latest æŒ‡é’ˆ

**è§£å†³**ï¼š
```python
# âœ… æ­£ç¡®ï¼šè®© ArtifactManager è‡ªåŠ¨å¤„ç†
artifact_manager.save_artifact(...)
# è‡ªåŠ¨ç”Ÿæˆæ ‡å‡†æ ¼å¼: chapter_001_segmentation_v20260212_180000.json
```

---

### é”™è¯¯3: è¯»å– history/ ä¸­çš„æ–‡ä»¶

```python
# âŒ é”™è¯¯ï¼šç›´æ¥è¯»å–ç‰ˆæœ¬æ–‡ä»¶
with open("data/.../history/chapter_001_segmentation_v20260212_180000.json", 'r') as f:
    result = json.load(f)
```

**é—®é¢˜**ï¼š
- ä¸çŸ¥é“å“ªä¸ªæ˜¯æœ€æ–°ç‰ˆæœ¬
- éœ€è¦æ‰‹åŠ¨æŸ¥æ‰¾æ—¶é—´æˆ³

**è§£å†³**ï¼š
```python
# âœ… æ­£ç¡®ï¼šè¯»å– latest æ–‡ä»¶
result = artifact_manager.load_latest_artifact(
    artifact_type="chapter_001_segmentation",
    base_dir=f"{project_dir}/analyst/novel_analysis"
)
```

**ä¾‹å¤–æƒ…å†µ**ï¼ˆéœ€è¦ç‰¹å®šç‰ˆæœ¬ï¼‰ï¼š
```python
# å¦‚æœæ˜ç¡®éœ€è¦è¯»å–å†å²ç‰ˆæœ¬ï¼Œå¯ä»¥æ‰‹åŠ¨è¯»å–
import glob
import json

# åˆ—å‡ºæ‰€æœ‰ç‰ˆæœ¬
versions = glob.glob("data/.../history/chapter_001_segmentation_v*.json")
versions.sort()  # æŒ‰æ—¶é—´æˆ³æ’åº

# è¯»å–ç¬¬1ä¸ªç‰ˆæœ¬
with open(versions[0], 'r') as f:
    first_version = json.load(f)
```

---

## ğŸ”§ é«˜çº§ç”¨æ³•

### 1. å¯¹æ¯”å¤šä¸ªç‰ˆæœ¬

```python
import glob
import json

def compare_versions(artifact_type: str, base_dir: str):
    """å¯¹æ¯”artifactçš„æ‰€æœ‰ç‰ˆæœ¬"""
    
    history_dir = os.path.join(base_dir, "history")
    pattern = os.path.join(history_dir, f"{artifact_type}_v*.json")
    versions = sorted(glob.glob(pattern))
    
    for version_path in versions:
        with open(version_path, 'r') as f:
            data = json.load(f)
        
        timestamp = os.path.basename(version_path).split('_v')[1].split('.')[0]
        provider = data.get("metadata", {}).get("llm_provider", "unknown")
        paragraphs = data.get("total_paragraphs", 0)
        cost = data.get("metadata", {}).get("total_cost", 0)
        
        print(f"{timestamp} | {provider:10s} | {paragraphs:3d} paragraphs | ${cost:.2f}")

# ä½¿ç”¨
compare_versions(
    artifact_type="chapter_001_segmentation",
    base_dir="data/projects/project_001/analyst/novel_analysis"
)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
20260212_180000 | claude     | 50 paragraphs | $0.15
20260212_190000 | deepseek   | 48 paragraphs | $0.05
20260212_200000 | claude     | 52 paragraphs | $0.16
```

---

### 2. è‡ªåŠ¨æ¸…ç†æ—§ç‰ˆæœ¬ï¼ˆå¾…å®ç°ï¼‰

```python
def cleanup_old_versions(base_dir: str, keep_days: int = 30):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ—§ç‰ˆæœ¬"""
    
    import time
    from datetime import datetime, timedelta
    
    history_dir = os.path.join(base_dir, "history")
    cutoff_date = datetime.now() - timedelta(days=keep_days)
    
    for filename in os.listdir(history_dir):
        if not filename.endswith(".json"):
            continue
        
        # æå–æ—¶é—´æˆ³
        # æ ¼å¼: chapter_001_segmentation_v20260212_180000.json
        try:
            timestamp_str = filename.split('_v')[1].split('.')[0]
            file_date = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")
            
            if file_date < cutoff_date:
                file_path = os.path.join(history_dir, filename)
                os.remove(file_path)
                print(f"Deleted old version: {filename}")
        except Exception as e:
            print(f"Failed to process {filename}: {e}")

# ä½¿ç”¨
cleanup_old_versions(
    base_dir="data/projects/project_001/analyst/novel_analysis",
    keep_days=30
)
```

---

### 3. å¯¼å‡ºç‰ˆæœ¬å†å²

```python
def export_version_history(artifact_type: str, base_dir: str, output_path: str):
    """å¯¼å‡ºartifactçš„ç‰ˆæœ¬å†å²ä¸ºCSV"""
    
    import csv
    import glob
    import json
    
    history_dir = os.path.join(base_dir, "history")
    pattern = os.path.join(history_dir, f"{artifact_type}_v*.json")
    versions = sorted(glob.glob(pattern))
    
    with open(output_path, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['Timestamp', 'Provider', 'Paragraphs', 'Cost', 'File'])
        
        for version_path in versions:
            with open(version_path, 'r') as f:
                data = json.load(f)
            
            timestamp = os.path.basename(version_path).split('_v')[1].split('.')[0]
            metadata = data.get("metadata", {})
            
            writer.writerow([
                timestamp,
                metadata.get("llm_provider", "unknown"),
                data.get("total_paragraphs", 0),
                metadata.get("total_cost", 0),
                os.path.basename(version_path)
            ])

# ä½¿ç”¨
export_version_history(
    artifact_type="chapter_001_segmentation",
    base_dir="data/projects/project_001/analyst/novel_analysis",
    output_path="version_history.csv"
)
```

---

## ğŸ“Š æ€§èƒ½è€ƒè™‘

### ç£ç›˜ç©ºé—´

**ä¼°ç®—**ï¼š
- å•ä¸ªåˆ†æ®µç»“æœï¼š~50KB
- å•ä¸ªæ ‡æ³¨ç»“æœï¼š~200KB
- å•ç« 10ä¸ªç‰ˆæœ¬ï¼š~2.5MB
- 100ç« 10ä¸ªç‰ˆæœ¬ï¼š~250MB

**ä¼˜åŒ–å»ºè®®**ï¼š
1. å®šæœŸæ¸…ç†æ—§ç‰ˆæœ¬ï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
2. å‹ç¼©å†å²ç‰ˆæœ¬ï¼ˆä½¿ç”¨ gzipï¼‰
3. å½’æ¡£è¶…è¿‡3ä¸ªæœˆçš„ç‰ˆæœ¬åˆ°å¤‡ä»½å­˜å‚¨

---

### æ–‡ä»¶I/Oæ€§èƒ½

**å½“å‰å®ç°**ï¼š
- ä¿å­˜æ—¶é—´ï¼š~10msï¼ˆ50KB JSONï¼‰
- è¯»å–æ—¶é—´ï¼š~5ms

**ä¼˜åŒ–å»ºè®®**ï¼š
1. ä½¿ç”¨å†…å­˜ç¼“å­˜ï¼ˆRedisï¼‰å­˜å‚¨ latest ç‰ˆæœ¬
2. å¼‚æ­¥ä¿å­˜ history ç‰ˆæœ¬
3. æ‰¹é‡ä¿å­˜å¤šä¸ªartifact

---

## ğŸ“‹ æ€»ç»“

### ArtifactManager çš„æ ¸å¿ƒä»·å€¼

| é—®é¢˜ | ArtifactManager çš„è§£å†³æ–¹æ¡ˆ |
|------|--------------------------|
| **ä¸çŸ¥é“å“ªä¸ªæ˜¯æœ€æ–°ç‰ˆæœ¬** | âœ… `*_latest.json` å§‹ç»ˆæŒ‡å‘æœ€æ–° |
| **è¦†ç›–å†å²æ•°æ®** | âœ… æ‰€æœ‰ç‰ˆæœ¬ä¿ç•™åœ¨ `history/` |
| **ç‰ˆæœ¬å‘½åæ··ä¹±** | âœ… ç»Ÿä¸€çš„æ—¶é—´æˆ³æ ¼å¼ `v{YYYYMMDD}_{HHMMSS}` |
| **æ— æ³•å›æ»š** | âœ… å¯ä»¥ä» history/ æ¢å¤ä»»æ„ç‰ˆæœ¬ |
| **å¯¹æ¯”ç‰ˆæœ¬å›°éš¾** | âœ… å¯ä»¥è½»æ¾è¯»å–å’Œå¯¹æ¯”å¤šä¸ªç‰ˆæœ¬ |

### ä½¿ç”¨å»ºè®®

1. **å§‹ç»ˆä½¿ç”¨ ArtifactManager**ï¼šä¸è¦æ‰‹åŠ¨åˆ›å»ºç‰ˆæœ¬æ–‡ä»¶
2. **è¯»å– latest æ–‡ä»¶**ï¼šä¸è¦ç›´æ¥è¯»å– history/ ä¸­çš„æ–‡ä»¶ï¼ˆé™¤éæ˜ç¡®éœ€è¦ç‰¹å®šç‰ˆæœ¬ï¼‰
3. **ç»Ÿä¸€å‘½åè§„èŒƒ**ï¼šä½¿ç”¨ `{id}_{operation}` æ ¼å¼
4. **å®šæœŸæ¸…ç†**ï¼šæ¸…ç†è¶…è¿‡30å¤©çš„æ—§ç‰ˆæœ¬
5. **è®°å½•å…ƒæ•°æ®**ï¼šåœ¨ä¿å­˜çš„æ•°æ®ä¸­åŒ…å« `metadata` å­—æ®µï¼ˆtoolã€providerã€costç­‰ï¼‰

---

**æœ€åæ›´æ–°**: 2026-02-12  
**ç»´æŠ¤è€…**: Project Team
