# SRT字幕处理系统设计文档

## 概述

SRT字幕处理系统负责将碎片化的SRT字幕文件转换为可读、连贯、符合小说设定的脚本文本。系统支持两种处理模式：有小说参考和无小说参考。

## 设计目标

1. **可读性**: 将断句的字幕合并为自然段落，添加标点符号
2. **准确性**: 修正语音识别导致的错别字、同音错字
3. **一致性**: 统一实体名称（人物、地点、道具）
4. **智能性**: 根据上下文修复缺字、推断正确的实体名称

## 系统架构

### 核心工具

**`SrtScriptProcessor`** (`src/tools/srt_processor.py`)
- 继承: `BaseTool`
- 功能: SRT解析、文本处理、段落划分
- 支持两种处理模式

### 处理流程

```
┌─────────────────────────────────────────────────────────────┐
│                    SRT文件输入                               │
│                  (raw/ep01.srt)                              │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────────────┐
│               步骤1: 解析SRT格式                             │
│  - 提取序号、时间戳、文本                                    │
│  - 规范化换行符                                              │
│  - 生成 SrtEntry 列表                                        │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────────────┐
│            步骤2: 提取连续文本                               │
│  - 按时间顺序合并所有字幕文本                                │
│  - 保留原始顺序                                              │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ↓
         ┌───────────┴───────────┐
         │                       │
         ↓                       ↓
┌─────────────────┐    ┌─────────────────────┐
│  有小说参考模式  │    │  无小说参考模式      │
│  (with_novel)   │    │  (without_novel)    │
└────────┬────────┘    └────────┬────────────┘
         │                       │
         ↓                       ↓
┌─────────────────┐    ┌─────────────────────┐
│ 从小说提取实体   │    │ LLM智能实体识别      │
│ - 人物名称      │    │ - 扫描全文          │
│ - 地点名称      │    │ - 检测变体          │
│ - 道具名称      │    │ - 推断标准形式      │
└────────┬────────┘    └────────┬────────────┘
         │                       │
         ↓                       ↓
┌─────────────────┐    ┌─────────────────────┐
│ LLM处理         │    │ LLM处理             │
│ - 添加标点      │    │ - 添加标点          │
│ - 修正错别字    │    │ - 修正错别字        │
│ - 对齐实体名称  │    │ - 统一实体名称      │
│ - 修复缺字      │    │ - 上下文补全        │
└────────┬────────┘    └────────┬────────────┘
         │                       │
         └───────────┬───────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────────────┐
│               步骤3: 段落划分                                │
│  - 按句号分割句子                                            │
│  - 根据长度合并为段落                                        │
│  - 段内连续，段间双换行                                      │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ↓
┌─────────────────────────────────────────────────────────────┐
│               步骤4: 输出与报告                              │
│  - 写入 script/ep01.txt                                      │
│  - 生成处理报告 (JSON)                                       │
│  - 记录实体标准化信息                                        │
└─────────────────────────────────────────────────────────────┘
```

## 处理模式详解

### 模式1: 有小说参考 (with_novel)

**适用场景**: 项目有对应的小说原文

**处理步骤**:
1. 从小说前3章提取标准实体列表
2. 使用LLM将字幕中的实体对齐到标准列表
3. 修复缺字时参考小说中的实体名称

**示例**:
```
输入字幕: "林一萧抬眸"
小说实体: ["宗文帝", "淑妃", "小公主"]
输出: "宗文帝抬眸"  # 修正同音错字
```

**Prompt**: `src/prompts/srt_script_processing_with_novel.yaml`

### 模式2: 无小说参考 (without_novel)

**适用场景**: 项目没有小说原文

**核心创新**: 智能实体识别与标准化

**处理步骤**:
1. **实体识别**: LLM扫描全文，识别所有人物、地点、道具
2. **变体检测**: 识别同一实体的不同写法
   - 同音错字: "上沪" vs "上户"
   - 缺字: "到达上" (缺失后半部分)
   - 错误识别: "商户" (在地名上下文中应为"上沪")
3. **标准形式推断**: 基于语义和常识选择最合理的形式
   - 示例: "上沪"更合理，因为沪是上海简称
4. **全文统一**: 使用标准实体表修正所有变体

**示例**:
```
输入字幕:
"主角跟着车队一路到达上"
"在上户这座繁华的城市里"
"车队在商户停留了三天"

LLM分析:
{
  "locations": {
    "上沪": {
      "variants": ["上", "上户", "商户（line 3）"],
      "standard_form": "上沪",
      "reasoning": "指代上海，沪是上海简称"
    }
  }
}

输出:
"主角跟着车队一路到达上沪。在上沪这座繁华的城市里，..."
"车队在上沪停留了三天，..."
```

**Prompt**: `src/prompts/srt_script_processing_without_novel.yaml`

## 技术细节

### 实体提取算法 (with_novel模式)

```python
def _extract_entities_from_novel(novel_text: str) -> Dict[str, List[str]]:
    """
    从小说中提取标准实体名称
    
    使用正则表达式匹配常见模式：
    - 人物: 姓氏+名字+称谓 (如"林逸潇", "淑妃")
    - 地点: 地名+后缀 (如"皇宫", "苦寒之地")
    - 道具: 物品名称 (如"胎记", "夜明珠")
    """
```

### 智能实体标准化 (without_novel模式)

**LLM输出格式**:
```json
{
  "locations": {
    "上沪": {
      "variants": ["上沪", "上户", "上", "商户"],
      "standard_form": "上沪",
      "reasoning": "指代上海，沪是上海简称",
      "confidence": 0.92
    }
  },
  "characters": {...},
  "items": {...}
}
```

### 段落划分策略

**参数**:
- `min_paragraph_length`: 最小段落长度 (默认50字符)
- `max_paragraph_length`: 最大段落长度 (默认300字符)

**算法**:
1. 按句号分割句子
2. 逐句累加到当前段落
3. 当段落长度达到最小值且下一句会超过最大值时，开始新段落
4. 段落间用双换行分隔

## 输出格式

### 处理后的脚本文件

**位置**: `data/projects/{category}/{project_name}/script/ep01.txt`

**格式**:
```
段落1内容，连续的句子。句子之间没有换行。

段落2内容，另一个语义单元。

段落3内容...
```

### 处理报告

**位置**: `data/projects/{category}/{project_name}/script/ep01_processing_report.json`

**内容**:
```json
{
  "episode": "ep01",
  "processing_mode": "without_novel",
  "output_file": "path/to/ep01.txt",
  "stats": {
    "original_chars": 3908,
    "processed_chars": 3887,
    "paragraphs": 14,
    "srt_entries": 358,
    "processing_time_seconds": 102.39
  },
  "entity_standardization": {
    "locations": {
      "上沪": {
        "variants": ["上沪", "上户", "上"],
        "standard_form": "上沪",
        "reasoning": "..."
      }
    },
    "characters": {...},
    "items": {...}
  }
}
```

## 集成到迁移工作流

### Migration Workflow 集成

**位置**: `src/workflows/migration_workflow.py`

**集成点**:
1. **with_novel项目**: 在复制SRT文件后，读取小说参考，调用SRT处理器
2. **without_novel项目**: 在复制SRT文件后，直接调用SRT处理器（无参考模式）

**代码示例**:
```python
# with_novel模式
novel_reference = self._load_novel_reference(novel_dir, chapters=3)
srt_report = self.srt_processor.execute(
    srt_file_path=srt_file,
    output_dir=script_dir,
    novel_reference=novel_reference,
    episode_name="ep01"
)

# without_novel模式
srt_report = self.srt_processor.execute(
    srt_file_path=srt_file,
    output_dir=script_dir,
    novel_reference=None,  # 无小说参考
    episode_name="ep01"
)
```

## 质量保证

### 降级策略

| 场景 | 降级方案 |
|------|----------|
| LLM API不可用 | 基于规则的标点添加和简单合并 |
| 无小说参考 | 自动切换到智能实体识别模式 |
| SRT格式损坏 | 记录错误，跳过该文件 |

### 测试覆盖

**测试脚本**: `scripts/test_srt_processing.py`

**测试场景**:
1. 有小说参考模式 (天命桃花/ep01)
2. 无小说参考模式 (超前崛起/ep01)

**验证点**:
- 输出文件生成
- 段落数量合理
- 实体标准化正确
- 处理时间可接受

## 性能指标

**实测数据** (基于测试):
- **with_novel模式**: 489条字幕 → 15段落，耗时79秒
- **without_novel模式**: 358条字幕 → 14段落，耗时102秒

**瓶颈**: LLM API调用（单次调用包含全文处理）

**优化方向**:
- 批量处理多个集数
- 缓存实体标准化结果
- 使用更快的模型（如deepseek-chat）

## 未来改进

1. **实体提取增强**: 使用LLM替代正则表达式提取小说实体
2. **上下文窗口优化**: 对超长字幕分段处理
3. **多语言支持**: 扩展到英文字幕处理
4. **质量评分**: 自动评估处理质量并标记需要人工审核的部分

---

**最后更新**: 2026-02-05  
**版本**: v1.0  
**作者**: AI Assistant
